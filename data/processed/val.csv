text,label
"Large language models (LLMs) are increasingly deployed locally for privacy and accessibility, yet users lack tools to measure their resource usage, environmental impact, and efficiency metrics. This paper presents EnviroLLM, an open-source toolkit for tracking, benchmarking, and optimizing performance and energy consumption when running LLMs on personal devices. The system provides real-time process monitoring, benchmarking across multiple platforms (Ollama, LM Studio, vLLM, and OpenAI-compatible APIs), persistent storage with visualizations for longitudinal analysis, and personalized model and optimization recommendations. The system includes LLM-as-judge evaluations alongside energy and speed metrics, enabling users to assess quality-efficiency tradeoffs when testing models with custom prompts.",human
"Text-to-Image (TTI) models generate images based on text prompts, which often leave certain aspects of the desired image ambiguous. When faced with these ambiguities, TTI models have been shown to exhibit biases in their interpretations. These biases can have societal impacts, e.g., when showing only a certain race for a stated occupation. They can also affect user experience when creating redundancy within a set of generated images instead of spanning diverse possibilities. Here, we introduce MineTheGap - a method for automatically mining prompts that cause a TTI model to generate biased outputs. Our method goes beyond merely detecting bias for a given prompt. Rather, it leverages a genetic algorithm to iteratively refine a pool of prompts, seeking for those that expose biases. This optimization process is driven by a novel bias score, which ranks biases according to their severity, as we validate on a dataset with known biases. For a given prompt, this score is obtained by comparing the distribution of generated images to the distribution of LLM-generated texts that constitute variations on the prompt. Code and examples are available on the project's webpage.",human
"We address the challenge of training machine learning models robust to adversarial perturbations of input data. Specifically, we investigate robust optimization techniques applied to deep neural networks, where the objective is to minimize the worst-case loss over a bounded adversarial set around each data point. Traditional robust optimization methods often suffer from high computational cost due to the inner maximization problem required to find the worst-case perturbation. This work proposes a novel, efficient iterative algorithm leveraging a relaxed constraint formulation coupled with proximal gradient descent. Our method, which we term Relaxed Proximal Robust Optimization (RPRO), approximates the robust objective by iteratively tightening a relaxation of the adversarial constraint set. This allows for faster convergence compared to directly solving the inner maximization. Empirically, we demonstrate the effectiveness of RPRO on standard image classification benchmarks (CIFAR-10 and CIFAR-100) under various -norm bounded perturbations. Compared to state-of-the-art robust optimization techniques such as Projected Gradient Descent (PGD) training and TRADES, RPRO achieves comparable or improved robust accuracy with significantly reduced training time, particularly for larger perturbation budgets. Our results highlight the potential of relaxed constraint optimization for training robust deep learning models at scale.",ai
"Stochastic disruptions such as flash events arising from benign traffic bursts and switch thermal fluctuations are major contributors to intermittent service degradation in software-defined industrial networks. These events violate IEC~61850-derived quality-of-service requirements and user-defined service-level agreements, hindering the reliable and timely delivery of control, monitoring, and best-effort traffic in IEC~61400-25-compliant wind power plants. Failure to maintain these requirements often results in delayed or lost control signals, reduced operational efficiency, and increased risk of wind turbine generator downtime. To address these challenges, this study proposes a threshold-triggered Deep Q-Network self-healing agent that autonomically detects, analyzes, and mitigates network disruptions while adapting routing behavior and resource allocation in real time. The proposed agent was trained, validated, and tested on an emulated tri-clustered switch network deployed in a cloud-based proof-of-concept testbed. Simulation results show that the proposed agent improves disruption recovery performance by 53.84% compared to a baseline shortest-path and load-balanced routing approach and outperforms state-of-the-art methods, including the Adaptive Network-based Fuzzy Inference System by 13.1% and the Deep Q-Network and traffic prediction-based routing optimization method by 21.5%, in a super-spine leaf data-plane architecture. Additionally, the agent maintains switch thermal stability by proactively initiating external rack cooling when required. These findings highlight the potential of deep reinforcement learning in building resilience in software-defined industrial networks deployed in mission-critical, time-sensitive application scenarios.",human
"We address the problem of learning causal relationships from observational data in settings where latent confounders are suspected but not explicitly identified. Current methods often rely on strong assumptions about the functional form of relationships or the completeness of the observed variable set, limiting their applicability in complex, real-world scenarios. We introduce a novel approach, Conditional Independence Guided Structure Learning (CIGSL), which leverages conditional independence tests to infer a causal structure that is robust to the presence of unobserved confounders. CIGSL integrates constraint-based structure learning with a modified version of the PC algorithm. The modification incorporates a novel heuristic that intelligently relaxes conditional independence constraints based on local graph properties and the stability of the tests across various data subsets. This heuristic allows the algorithm to more accurately represent uncertainty arising from potential confounders. We demonstrate, through simulations and experiments on benchmark datasets, that CIGSL achieves superior accuracy in causal structure recovery compared to existing methods like FCI and PC-stable, especially when the data are generated by non-linear causal models with significant confounding. Specifically, CIGSL exhibits a substantial improvement in SHD (Structural Hamming Distance) score, indicating a more accurate identification of causal edges and their orientations. The improved robustness of CIGSL makes it a viable tool for causal discovery in domains where latent confounding is a significant concern.",ai
"We address the problem of reliably estimating causal effects in observational data with high-dimensional confounders and potential non-linear relationships, a scenario prevalent in many scientific disciplines. Traditional methods often suffer from bias due to unobserved confounding or model misspecification. To mitigate these issues, we propose a novel framework that combines representation learning with instrumental variable (IV) regression. Specifically, we employ a deep neural network to learn a low-dimensional representation of the observed covariates that effectively balances confounder adjustment and noise reduction. We then leverage a robust IV approach, employing a novel instrument selection strategy based on conditional independence tests, to address potential unobserved confounding within the learned representation space. The effectiveness of the proposed method is evaluated on both synthetic datasets with varying degrees of non-linearity and unobserved confounding, as well as a real-world medical dataset concerning the effect of a specific treatment on patient outcomes. Our experimental results demonstrate that the proposed framework significantly outperforms existing methods, including propensity score matching and traditional IV regression, in terms of bias reduction and estimation accuracy, especially in the presence of strong non-linearities and high-dimensional confounding. The methodâ€™s robustness to instrument validity violations is also empirically investigated.",ai
"Financial time series forecasting is fundamentally an information fusion challenge, yet most existing models rely on static architectures that struggle to integrate heterogeneous knowledge sources or adjust to rapid regime shifts. Conventional approaches, relying exclusively on historical price sequences, often neglect the semantic drivers of volatility such as policy uncertainty and market narratives. To address these limitations, we propose the ASTIF (Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting), a hybrid intelligent system that adapts its forecasting strategy in real time through confidence-based meta-learning. The framework integrates three complementary components. A dual-channel Small Language Model using MirrorPrompt extracts semantic market cues alongside numerical trends. A hybrid LSTM Random Forest model captures sequential temporal dependencies. A confidence-aware meta-learner functions as an adaptive inference layer, modulating each predictor's contribution based on its real-time uncertainty. Experimental evaluation on a diverse dataset of AI-focused cryptocurrencies and major technology stocks from 2020 to 2024 shows that ASTIF outperforms leading deep learning and Transformer baselines (e.g., Informer, TFT). The ablation studies further confirm the critical role of the adaptive meta-learning mechanism, which successfully mitigates risk by shifting reliance between semantic and temporal channels during market turbulence. The research contributes a scalable, knowledge-based solution for fusing quantitative and qualitative data in non-stationary environments.",human
"Real-time sequential control agents are often bottlenecked by inference latency. Even modest per-step planning delays can destabilize control and degrade overall performance. We propose a speculation-and-correction framework that adapts the predict-then-verify philosophy of speculative execution to model-based control with TD-MPC2. At each step, a pretrained world model and latent-space MPC planner generate a short-horizon action queue together with predicted latent rollouts, allowing the agent to execute multiple planned actions without immediate replanning. When a new observation arrives, the system measures the mismatch between the encoded real latent state and the queued predicted latent. For small to moderate mismatch, a lightweight learned corrector applies a residual update to the speculative action, distilled offline from a replanning teacher. For large mismatch, the agent safely falls back to full replanning and clears stale action queues. We study both a gated two-tower MLP corrector and a temporal Transformer corrector to address local errors and systematic drift. Experiments on the DMC Humanoid-Walk task show that our method reduces the number of planning inferences from 500 to 282, improves end-to-end step latency by 25 percent, and maintains strong control performance with only a 7.1 percent return reduction. Ablation results demonstrate that speculative execution without correction is unreliable over longer horizons, highlighting the necessity of mismatch-aware correction for robust latency reduction.",human
"We address the challenge of enhancing the efficiency and robustness of automated theorem proving within complex logical systems. Existing methods often struggle with combinatorial explosion and sensitivity to proof structure, particularly in domains requiring nuanced reasoning. To mitigate these limitations, we introduce a novel reinforcement learning (RL) framework, termed ""Guided Logic Exploration"" (GLE), that leverages a transformer-based policy network to predict promising proof strategies. GLE is trained using a curated dataset of successful proofs augmented with heuristically generated counterexamples, incentivizing the policy to prioritize logical inferences that minimize proof length and complexity. The reward function incorporates both the success rate of proof attempts and a penalty for excessive search depth, promoting efficient exploration of the proof space. We evaluated GLE on a benchmark suite of theorems from propositional logic and first-order logic, comparing its performance to state-of-the-art automated theorem provers, including resolution-based and tableaux-based systems. Empirical results demonstrate that GLE achieves a significant improvement in the number of theorems proven within a fixed time budget and exhibits superior generalization capabilities across different logical domains. Specifically, GLE achieved a 25% higher success rate on unseen theorems compared to the strongest baseline, showcasing the potential of RL-guided automated reasoning.",ai
"### Abstract Deep learning techniques have shown promise in automating the analysis of medical images, potentially improving diagnostic accuracy and efficiency. However, the performance of these methods is often limited by the scarcity of labeled data and the inherent complexity of medical imaging modalities. This work addresses the challenge of robust and efficient medical image analysis by introducing a novel semi-supervised learning framework that leverages both labeled and unlabeled data. The proposed approach combines a contrastive learning pre-training strategy with a task-specific fine-tuning phase utilizing a convolutional neural network architecture optimized for feature extraction from high-dimensional medical images. Specifically, contrastive learning is employed to learn robust feature representations from a large corpus of unlabeled medical images, capturing underlying data distributions and mitigating the impact of limited labeled examples. This pre-trained model is then fine-tuned on a smaller, labeled dataset to perform a specific diagnostic task, such as detecting abnormalities in chest X-rays. Experimental results on publicly available datasets demonstrate that our approach significantly improves performance compared to supervised learning methods trained solely on labeled data, achieving a substantial increase in area under the ROC curve (AUC) and F1-score. Furthermore, the proposed framework exhibits improved generalization capabilities when evaluated on unseen datasets, suggesting its potential for real-world clinical applications.",ai
"We address the challenge of representing and reasoning with complex relational knowledge extracted from unstructured text, specifically focusing on scenarios involving implicit relationships and contextual dependencies. Existing knowledge representation formalisms often struggle to capture the nuances of such information, leading to incomplete or inaccurate inference. To mitigate this, we propose a novel hybrid approach combining distributional semantics with a symbolic knowledge graph. Our method, termed Contextualized Relational Embedding and Graph Augmentation (CREGA), leverages pre-trained language models to generate contextualized embeddings for entities and relations extracted from text. These embeddings are then utilized to augment an initial knowledge graph, enriching it with implicit relations and inferring missing links based on semantic similarity. Crucially, CREGA incorporates a mechanism for weighting edges based on the confidence scores derived from the contextualized embeddings and the source text. Evaluation on benchmark knowledge graph completion datasets and a novel dataset constructed from scientific literature demonstrates that CREGA significantly outperforms state-of-the-art methods in link prediction and relation classification. Specifically, we observe a 15% improvement in Mean Reciprocal Rank (MRR) on the scientific literature dataset compared to traditional knowledge graph embedding approaches. This highlights the efficacy of our approach in capturing and reasoning with complex relational knowledge derived from unstructured text sources.",ai
"Large Language Model (LLM) agents are increasingly deployed in complex, multi-step workflows involving planning, tool use, reflection, and interaction with external knowledge systems. These workflows generate rapidly expanding contexts that must be curated, transformed, and compressed to maintain fidelity, avoid attention dilution, and reduce inference cost. Prior work on summarization and query-aware compression largely ignores the multi-step, plan-aware nature of agentic reasoning. In this work, we introduce PAACE (Plan-Aware Automated Context Engineering), a unified framework for optimizing the evolving state of LLM agents through next-k-task relevance modeling, plan-structure analysis, instruction co-refinement, and function-preserving compression. PAACE comprises (1) PAACE-Syn, a large-scale generator of synthetic agent workflows annotated with stepwise compression supervision, and (2) PAACE-FT, a family of distilled, plan-aware compressors trained from successful teacher demonstrations. Experiments on long-horizon benchmarks (AppWorld, OfficeBench, and 8-Objective QA) demonstrate that PAACE consistently improves agent correctness while substantially reducing context load. On AppWorld, PAACE achieves higher accuracy than all baselines while lowering peak context and cumulative dependency. On OfficeBench and multi-hop QA, PAACE improves both accuracy and F1, achieving fewer steps, lower peak tokens, and reduced attention dependency. Distilled PAACE-FT retains 97 percent of the teacher's performance while reducing inference cost by over an order of magnitude, enabling practical deployment of plan-aware compression with compact models.",human
"Multi-task learning (MTL) aims to leverage shared knowledge across tasks to improve generalization and parameter efficiency, yet balancing resources and mitigating interference remain open challenges. Architectural solutions often introduce elaborate task-specific modules or routing schemes, increasing complexity and overhead. In this work, we show that normalization layers alone are sufficient to address many of these challenges. Simply replacing shared normalization with task-specific variants already yields competitive performance, questioning the need for complex designs. Building on this insight, we propose Task-Specific Sigmoid Batch Normalization (TSBN), a lightweight mechanism that enables tasks to softly allocate network capacity while fully sharing feature extractors. TSBN improves stability across CNNs and Transformers, matching or exceeding performance on NYUv2, Cityscapes, CelebA, and PascalContext, while remaining highly parameter-efficient. Moreover, its learned gates provide a natural framework for analyzing MTL dynamics, offering interpretable insights into capacity allocation, filter specialization, and task relationships. Our findings suggest that complex MTL architectures may be unnecessary and that task-specific normalization offers a simple, interpretable, and efficient alternative.",human
"We investigate the problem of decentralized task allocation in multi-agent systems where agents possess heterogeneous capabilities and partial observability of the environment. Traditional approaches often rely on centralized planners or require extensive communication, which become computationally prohibitive or impractical in large-scale, dynamic environments. We propose a novel approach, Cooperative Task Allocation with Recurrent Evolutionary Strategies (CTAR-ES), that combines recurrent neural networks for individual agent decision-making with a distributed evolutionary strategy for optimizing cooperative policies. Each agent utilizes a recurrent policy network, trained to predict optimal task selections based on local observations and a limited communication channel. The global policy parameters are optimized via a decentralized variant of the Evolution Strategy, where agents collectively estimate the gradient of a shared reward function based on their individual performance and limited peer communication. We evaluate CTAR-ES in a simulated resource gathering environment with varying levels of agent heterogeneity and communication constraints. Empirical results demonstrate that CTAR-ES achieves superior performance compared to benchmark algorithms, including independent Q-learning and centralized policy optimization, particularly in scenarios with limited communication bandwidth and high agent heterogeneity. Furthermore, we analyze the emergent communication strategies learned by the agents, revealing efficient information sharing patterns that enhance overall team performance and robustness.",ai
"We address the problem of distributional robustness in sequence-to-sequence models for natural language generation (NLG). Real-world NLG systems often encounter data shifts between training and deployment, leading to performance degradation. We propose a novel adversarial training framework, Robust Sequence Optimization (RSO), which directly optimizes for worst-case performance under data perturbations in the latent space. RSO leverages a differentiable approximation of the Gumbel-Softmax trick to efficiently explore a set of plausible perturbations during training. Specifically, we introduce a perturbation generator that operates on the hidden states of the encoder, aiming to maximize the loss of the decoder. We then minimize the worst-case loss induced by these adversarial perturbations, effectively training a model robust to distributional shifts. Experiments on machine translation (WMT14 En-De) and text summarization (CNN/DailyMail) datasets demonstrate that RSO significantly improves the robustness of sequence-to-sequence models against various types of input noise, including adversarial attacks and common corruption benchmarks. Furthermore, RSO achieves comparable or better performance than standard training on clean data, indicating that robustness can be enhanced without sacrificing accuracy. Our analysis reveals that RSO encourages the model to learn more disentangled and invariant latent representations.",ai
"Recent advancements in machine learning (ML) have been accompanied by growing concerns regarding data privacy. Sensitive information, often integral to model training, is vulnerable to various privacy attacks. This work addresses the problem of training high-utility ML models while minimizing the risk of exposing private training data. We introduce a novel approach that combines differential privacy (DP) with federated learning (FL) in a multi-stage training paradigm. Specifically, we partition the training process into an initial global FL phase, followed by client-side DP-SGD fine-tuning, and a final aggregation step designed to minimize utility degradation incurred during the DP phase. The initial FL phase allows the model to learn a coarse approximation of the data distribution, thereby reducing the noise requirements for DP. We evaluate our method on benchmark datasets for image classification and natural language processing, demonstrating significant improvements in model accuracy compared to standard DP-SGD training, particularly under stringent privacy budgets. Our experimental results show that our multi-stage approach achieves a substantial reduction in the privacy-utility trade-off, enabling the training of more accurate models with enhanced privacy guarantees. Furthermore, we provide a theoretical analysis of the privacy amplification achieved through the combination of FL and DP-SGD.",ai
"We investigate the problem of effectively encoding structural information within graph-structured data for enhanced node classification. Existing Graph Neural Networks (GNNs) often struggle to capture long-range dependencies and nuanced relationships between nodes, limiting their performance on complex graph datasets. To address this, we propose a novel GNN architecture, the Attentive Relational Graph Network (ARGN), that incorporates a multi-head attention mechanism operating on node-specific relational feature embeddings. These embeddings are learned through a relation-aware message passing scheme, allowing the network to dynamically weigh the importance of different neighbor relations during aggregation. Furthermore, ARGN employs a graph pooling strategy based on spectral clustering to preserve global structural information across multiple scales. We evaluate ARGN on a range of benchmark graph datasets, including citation networks (Cora, Citeseer, PubMed) and social networks (Reddit, ogbn-products). Experimental results demonstrate that ARGN consistently outperforms state-of-the-art GNNs, achieving significant improvements in node classification accuracy. Specifically, ARGN achieves a relative improvement of 3.2% on the ogbn-products dataset compared to the best performing baseline, highlighting its ability to effectively model complex relational dependencies. These findings suggest that ARGN offers a promising approach for leveraging graph structure in various downstream tasks.",ai
"The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection. High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.",human
"We address the problem of sample-efficient reinforcement learning in environments with sparse and delayed rewards. Standard reinforcement learning algorithms often struggle in such settings due to the difficulty in exploring the state-action space and attributing credit to the actions that led to the delayed reward. To mitigate these challenges, we introduce a novel algorithm, Reward-Informed State Abstraction (RISA), which learns a compact, reward-relevant state representation using a variational autoencoder (VAE) conditioned on future reward predictions. Specifically, the VAE is trained to reconstruct the current state while simultaneously encoding information relevant for predicting future cumulative rewards. This reward-conditioned representation effectively filters out irrelevant state features, allowing for faster policy learning in the abstract state space. We evaluate RISA on a suite of challenging benchmark environments with sparse and delayed rewards, including the MountainCar-v0, Acrobot-v1, and a custom navigation task. Our results demonstrate that RISA significantly outperforms existing state-of-the-art reinforcement learning algorithms, achieving higher cumulative rewards and faster convergence rates. Furthermore, we analyze the learned state representations and demonstrate that they capture meaningful features related to long-term reward maximization, thereby improving the efficiency of both exploration and credit assignment. These findings highlight the potential of reward-informed state abstraction as a powerful technique for addressing the challenges of sparse reward reinforcement learning.",ai
"We address the challenge of identifying causal relationships within natural language processing (NLP) models, specifically focusing on attribution methods. While attribution techniques aim to highlight input features that contribute most to a model's prediction, they often conflate correlation with causation, leading to potentially misleading interpretations. We propose a novel framework leveraging intervention-based causal inference to disentangle causal effects from spurious correlations in attribution maps. Our method, Causal Attribution via Intervention (CAI), involves systematically intervening on input features and observing the resulting changes in model predictions. Specifically, we utilize a do-calculus based approach to estimate the average causal effect (ACE) of individual word tokens on the predicted outcome. We apply CAI to various NLP tasks including sentiment analysis and text classification, comparing its performance against existing attribution methods such as LIME and SHAP. Our results demonstrate that CAI provides more robust and accurate causal explanations, exhibiting higher fidelity to ground-truth causal relationships when available. Furthermore, we show that attribution maps generated by CAI are less susceptible to adversarial attacks designed to manipulate model explanations. The proposed approach offers a valuable tool for understanding and improving the reliability of NLP models.",ai
"## Emergent Coordination via Differentiable Communication Channels and Decentralized Policy Optimization We address the problem of achieving efficient and robust emergent coordination in complex multi-agent systems (MAS) operating in partially observable environments. Many existing approaches rely on centralized training schemes or require explicit communication protocols, limiting scalability and adaptability to novel scenarios. To mitigate these limitations, we propose a novel framework that combines differentiable communication channels with decentralized policy optimization. Our method, named Comm-Decent, allows agents to learn communication strategies end-to-end, without pre-defined message structures or explicit coordination mechanisms. Each agent learns a policy conditioned on its local observations and messages received from other agents, optimized using a decentralized proximal policy optimization (DPPO) variant. We introduce a differentiable communication module based on gated recurrent units (GRUs) that enables continuous message passing. The communication gradients are propagated through the network, encouraging agents to develop informative and contextualized communication strategies. We evaluate Comm-Decent on a set of challenging cooperative navigation and resource allocation tasks. Experimental results demonstrate that our approach significantly outperforms state-of-the-art decentralized reinforcement learning algorithms, achieving superior coordination, higher task completion rates, and improved robustness to communication noise. Furthermore, visualization of the learned communication patterns reveals the emergence of structured and task-specific communication protocols.",ai
"Graph Neural Networks (GNNs) have emerged as a powerful paradigm for learning representations of graph-structured data, enabling effective solutions across diverse application domains. However, existing GNN architectures often struggle with capturing long-range dependencies and complex relational reasoning due to limitations in message passing mechanisms and the potential for over-smoothing. This work addresses these limitations by introducing a novel Graph Transformer architecture, named Relational Reasoning Graph Transformer (RRGT), which leverages attention mechanisms augmented with explicit relational encoding. RRGT incorporates learnable relational embeddings that capture the specific relationships between node pairs, allowing the model to effectively discriminate between different types of connections and enhance the expressiveness of attention weights. Furthermore, we introduce a multi-head attention mechanism that allows the model to attend to different aspects of the relational information. We evaluate RRGT on a suite of graph benchmark datasets, including node classification tasks on citation networks and graph classification tasks on molecular property prediction datasets. The experimental results demonstrate that RRGT consistently outperforms state-of-the-art GNNs and Graph Transformer baselines, achieving significant improvements in accuracy and F1-score. These findings highlight the effectiveness of incorporating explicit relational reasoning into Graph Transformer architectures for enhancing graph representation learning.",ai
"Modern intrusion detection systems (IDS) leverage graph neural networks (GNNs) to detect malicious activity in system provenance data, but their decisions often remain a black box to analysts. This paper presents a comprehensive XAI framework designed to bridge the trust gap in Security Operations Centers (SOCs) by making graph-based detection transparent. We implement this framework on top of KAIROS, a state-of-the-art temporal graph-based IDS, though our design is applicable to any temporal graph-based detector with minimal adaptation. The complete codebase is available at https://github.com/devang1304/provex.git. We augment the detection pipeline with post-hoc explanations that highlight why an alert was triggered, identifying key causal subgraphs and events. We adapt three GNN explanation methods - GraphMask, GNNExplainer, and a variational temporal GNN explainer (VA-TGExplainer) - to the temporal provenance context. These tools output human-interpretable representations of anomalous behavior, including important edges and uncertainty estimates. Our contributions focus on the practical integration of these explainers, addressing challenges in memory management and reproducibility. We demonstrate our framework on the DARPA CADETS Engagement 3 dataset and show that it produces concise window-level explanations for detected attacks. Our evaluation reveals that the explainers preserve the TGNN's decisions with high fidelity, surfacing critical edges such as malicious file interactions and anomalous netflows. The average explanation overhead is 3-5 seconds per event. By providing insight into the model's reasoning, our framework aims to improve analyst trust and triage speed.",human
"Deep neural networks have demonstrated remarkable performance across various domains, yet their decision-making processes remain opaque. Although many explanation methods are dedicated to bringing the obscurity of DNNs to light, they exhibit significant limitations: post-hoc explanation methods often struggle to faithfully reflect model behaviors, while self-explaining neural networks sacrifice performance and compatibility due to their specialized architectural designs. To address these challenges, we propose a novel self-explaining framework that integrates Shapley value estimation as an auxiliary task during training, which achieves two key advancements: 1) a fair allocation of the model prediction scores to image patches, ensuring explanations inherently align with the model's decision logic, and 2) enhanced interpretability with minor structural modifications, preserving model performance and compatibility. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art interpretability.",human
"We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.",human
"Large Language Models are increasingly used in conversational systems such as digital personal assistants, shaping how people interact with technology through language. While their responses often sound fluent and natural, they can also carry subtle tone biases such as sounding overly polite, cheerful, or cautious even when neutrality is expected. These tendencies can influence how users perceive trust, empathy, and fairness in dialogue. In this study, we explore tone bias as a hidden behavioral trait of large language models. The novelty of this research lies in the integration of controllable large language model based dialogue synthesis with tone classification models, enabling robust and ethical emotion recognition in personal assistant interactions. We created two synthetic dialogue datasets, one generated from neutral prompts and another explicitly guided to produce positive or negative tones. Surprisingly, even the neutral set showed consistent tonal skew, suggesting that bias may stem from the model's underlying conversational style. Using weak supervision through a pretrained DistilBERT model, we labeled tones and trained several classifiers to detect these patterns. Ensemble models achieved macro F1 scores up to 0.92, showing that tone bias is systematic, measurable, and relevant to designing fair and trustworthy conversational AI.",human
"We investigate the application of transformer-based architectures to the problem of natural language inference (NLI), focusing on strategies to improve generalization performance on out-of-distribution datasets. While transformers have demonstrated impressive results on benchmark NLI datasets, their robustness to variations in linguistic style and reasoning patterns remains a significant challenge. This paper introduces a novel regularization technique, termed Adversarial Attribute Perturbation (AAP), which augments training data by generating adversarial examples that subtly modify sentence attributes such as sentiment and formality. AAP leverages gradient information to identify and perturb the input embeddings in a direction that maximizes the discrepancy between the transformer's prediction and the original label. We evaluate the effectiveness of AAP on a suite of benchmark NLI datasets, including SNLI, MNLI, and HANS, as well as out-of-distribution evaluation sets specifically designed to assess robustness. Empirical results demonstrate that AAP significantly improves generalization performance, achieving an average accuracy increase of 3.2% on out-of-distribution datasets compared to standard transformer training. Furthermore, we conduct ablation studies to analyze the impact of different perturbation strategies and demonstrate the robustness of AAP across various transformer architectures, including BERT and RoBERTa. The findings highlight the potential of adversarial regularization techniques to enhance the robustness of transformer-based models for NLI and other NLP tasks.",ai
"**Automated Detection of Pulmonary Nodules via Multi-Scale Convolutional Neural Networks with Attention Mechanisms** Early and accurate detection of pulmonary nodules in computed tomography (CT) scans is crucial for improving lung cancer survival rates. Manual review of CT images is, however, a time-consuming and subjective process, prone to inter-observer variability. This work presents a novel automated framework for pulmonary nodule detection leveraging a multi-scale convolutional neural network (CNN) architecture enhanced with attention mechanisms. The proposed method incorporates residual blocks to facilitate the training of deep networks and employs a cascade structure to progressively refine nodule candidates. Crucially, spatial attention modules are integrated at various stages to highlight salient features indicative of nodules and suppress irrelevant background noise. The model was trained and evaluated on the publicly available Lung Image Database Consortium image collection (LIDC-IDRI). Experimental results demonstrate a significant improvement in nodule detection sensitivity at various false positive rates, surpassing several existing state-of-the-art algorithms. Specifically, we achieved a sensitivity of 88.2% at 4 false positives per scan. The incorporation of multi-scale processing and attention mechanisms significantly improved the model's ability to distinguish subtle nodules from other anatomical structures, thus showcasing the potential of the proposed framework for computer-aided diagnosis of lung cancer.",ai
"We introduce SynGP500, a clinician-curated collection of 500 synthetic Australian general practice medical notes. The dataset integrates curriculum-based clinical breadth (RACGP 2022 Curriculum), epidemiologically-calibrated prevalence (BEACH study), and diverse consultation contexts. This approach systematically includes both common presentations and less-common curriculum-specified conditions that GPs must recognize but appear infrequently in single practice populations, potentially supporting more generalizable model training than datasets constrained by naturally occurring case distributions. SynGP500 is messy by design, reflecting the authentic complexity of healthcare delivery: telegraphic documentation, typos, patient non-adherence, socioeconomic barriers, and clinician-patient disagreements, unlike sanitized synthetic datasets that obscure clinical realities. Multi-faceted validation demonstrates dataset quality through epidemiological alignment with real Australian GP consultation patterns (BEACH study), stylometric analysis confirming high linguistic variation, semantic diversity analysis demonstrating broad coverage, and exploratory downstream evaluation using self-supervised medical concept extraction, showing F1 improvements. SynGP500 addresses a critical national gap, providing researchers and educators with a resource for developing and evaluating clinical NLP methods for Australian general practice while inherently protecting patient privacy.",human
"This paper investigates the problem of distributional robustness in natural language processing (NLP) models, specifically focusing on sentiment classification. Real-world NLP applications often encounter data drawn from distributions that deviate from the training distribution, leading to a significant performance degradation. We propose a novel min-max adversarial training framework leveraging a Wasserstein distance-based uncertainty set to improve out-of-distribution (OOD) generalization. This framework explicitly minimizes the worst-case risk over distributions within a Wasserstein ball centered around the empirical training distribution. We develop an efficient optimization algorithm to solve the inner maximization problem, which involves identifying the most adversarial distribution within the ball. Our method incorporates a gradient-based search within the probability simplex, guided by the observed performance of the model on perturbed data. We empirically evaluate our approach on a benchmark dataset consisting of multiple sentiment classification datasets with varying domain shifts. Results demonstrate that our Wasserstein robust optimization framework significantly improves OOD performance compared to empirical risk minimization and other existing robust training methods. Specifically, we observe an average increase of 5-10% in accuracy on unseen target domains, highlighting the effectiveness of our approach in enhancing the robustness of NLP models to distributional shifts. The findings suggest that Wasserstein robust optimization provides a promising avenue for developing more reliable and generalizable NLP systems.",ai
"### Abstract The accurate and efficient segmentation of anatomical structures in medical images is crucial for diagnosis, treatment planning, and disease monitoring. However, manual segmentation is a time-consuming and labor-intensive process prone to inter-observer variability. This work addresses the problem of automated liver segmentation in abdominal CT scans using a novel deep learning architecture. We propose a cascaded framework leveraging a 3D U-Net for initial coarse segmentation, followed by a refined segmentation stage employing a boundary-aware convolutional neural network. The boundary-aware network incorporates a novel loss function that penalizes errors near the organ boundaries, encouraging more precise segmentation. We evaluated our method on a publicly available dataset of abdominal CT scans, comparing its performance against state-of-the-art segmentation algorithms. Experimental results demonstrate that our approach achieves superior segmentation accuracy, yielding a Dice Similarity Coefficient (DSC) of 96.2% and an Average Symmetric Surface Distance (ASSD) of 0.87 mm. These results indicate a significant improvement in segmentation precision compared to existing methods, showcasing the potential of our cascaded boundary-aware approach for reliable and automated liver segmentation in clinical settings. The improved accuracy contributes to a reduction in manual intervention and supports enhanced clinical workflows.",ai
"In this study, we address the problem of open-vocabulary mobile manipulation, where a robot is required to carry a wide range of objects to receptacles based on free-form natural language instructions. This task is challenging, as it involves understanding visual semantics and the affordance of manipulation actions. To tackle these challenges, we propose Affordance RAG, a zero-shot hierarchical multimodal retrieval framework that constructs Affordance-Aware Embodied Memory from pre-explored images. The model retrieves candidate targets based on regional and visual semantics and reranks them with affordance scores, allowing the robot to identify manipulation options that are likely to be executable in real-world environments. Our method outperformed existing approaches in retrieval performance for mobile manipulation instruction in large-scale indoor environments. Furthermore, in real-world experiments where the robot performed mobile manipulation in indoor environments based on free-form instructions, the proposed method achieved a task success rate of 85%, outperforming existing methods in both retrieval performance and overall task success.",human
"Atrial fibrillation (AF) is the most prevalent sustained cardiac arrhythmia, and its clinical assessment requires accurate characterization of atrial electrical activity. Noninvasive electrocardiographic imaging (ECGI) combined with deep learning (DL) approaches for estimating intracardiac electrograms (EGMs) from body surface potentials (BSPMs) has shown promise, but progress is hindered by the limited availability of paired BSPM-EGM datasets. To address this limitation, we investigate variational autoencoders (VAEs) for the generation of synthetic multichannel atrial EGMs. Two models are proposed: a sinus rhythm-specific VAE (VAE-S) and a class-conditioned VAE (VAE-C) trained on both sinus rhythm and AF signals. Generated EGMs are evaluated using morphological, spectral, and distributional similarity metrics. VAE-S achieves higher fidelity with respect to in silico EGMs, while VAE-C enables rhythm-specific generation at the expense of reduced sinus reconstruction quality. As a proof of concept, the generated EGMs are used for data augmentation in a downstream noninvasive EGM reconstruction task, where moderate augmentation improves estimation performance. These results demonstrate the potential of VAE-based generative modeling to alleviate data scarcity and enhance deep learning-based ECGI pipelines.",human
"In this paper, we consider a class of finite-horizon, linear-quadratic stochastic control problems, where the probability distribution governing the noise process is unknown but assumed to belong to an ambiguity set consisting of all distributions whose mean and covariance lie within norm balls centered at given nominal values. To address the distributional ambiguity, we explore the design of causal affine control policies to minimize the worst-case expected regret over all distributions in the given ambiguity set. The resulting minimax optimal control problem is shown to admit an equivalent reformulation as a tractable convex program that corresponds to a regularized version of the nominal linear-quadratic stochastic control problem. While this convex program can be recast as a semidefinite program, semidefinite programs are typically solved using primal-dual interior point methods that scale poorly with the problem size in practice. To address this limitation, we propose a scalable dual projected subgradient method to compute optimal controllers to an arbitrary accuracy. Numerical experiments are presented to benchmark the proposed method against state-of-the-art data-driven and distributionally robust control design approaches.",human
"This paper introduces a new probabilistic framework for supervised learning in neural systems. It is designed to model complex, uncertain systems whose random outputs are strongly non-Gaussian given deterministic inputs. The architecture itself is a random object stochastically generated by a latent anisotropic Gaussian random field defined on a compact, boundaryless, multiply-connected manifold. The goal is to establish a novel conceptual and mathematical framework in which neural architectures are realizations of a geometry-aware, field-driven generative process. Both the neural topology and synaptic weights emerge jointly from a latent random field. A reduced-order parameterization governs the spatial intensity of an inhomogeneous Poisson process on the manifold, from which neuron locations are sampled. Input and output neurons are identified via extremal evaluations of the latent field, while connectivity is established through geodesic proximity and local field affinity. Synaptic weights are conditionally sampled from the field realization, inducing stochastic output responses even for deterministic inputs. To ensure scalability, the architecture is sparsified via percentile-based diffusion masking, yielding geometry-aware sparse connectivity without ad hoc structural assumptions. Supervised learning is formulated as inference on the generative hyperparameters of the latent field, using a negative log-likelihood loss estimated through Monte Carlo sampling from single-observation-per-input datasets. The paper initiates a mathematical analysis of the model, establishing foundational properties such as well-posedness, measurability, and a preliminary analysis of the expressive variability of the induced stochastic mappings, which support its internal coherence and lay the groundwork for a broader theory of geometry-driven stochastic learning.",human
"We address the problem of efficiently solving quantified Boolean formulas (QBFs) with alternating quantifiers and complex dependencies. Traditional QBF solvers often struggle with instances exhibiting intricate quantifier dependencies, leading to exponential search space explosion. To mitigate this, we introduce a novel approach leveraging a hybrid reasoning framework that integrates counterexample guided abstraction refinement (CEGAR) with dependency scheme learning. Our method dynamically identifies and exploits implicit dependencies between quantifiers, constructing a reduced abstraction of the original formula. This abstracted formula is then efficiently solved, and the solution is refined using counterexamples generated by the original, more complete formula. Dependency scheme learning is incorporated to iteratively improve the abstraction, focusing on relevant variable dependencies while avoiding unnecessary state exploration. We evaluated our approach on a benchmark suite of challenging QBF instances from the QBF Gallery. Experimental results demonstrate a significant improvement in both runtime and the number of solved instances compared to state-of-the-art QBF solvers, particularly those employing purely search-based or purely abstraction-based techniques. These findings suggest that the integration of CEGAR with dependency learning offers a promising direction for advancing the state of the art in QBF solving and automated reasoning with complex dependencies.",ai
"We investigate the problem of sample inefficiency in reinforcement learning (RL) for continuous control tasks with sparse rewards. Traditional RL algorithms often require extensive interaction with the environment to learn effective policies, particularly when reward signals are infrequent and delayed. To address this challenge, we propose a novel framework incorporating a learned intrinsic reward signal based on a predictive model of the environment's state dynamics. This predictive model is trained online, concurrently with policy learning, and provides an estimate of the expected future state given the current state and action. The intrinsic reward is then defined as the prediction error of this model, incentivizing the agent to explore regions of the state space where its understanding of the environment is limited. We evaluate our approach on a suite of challenging continuous control benchmark tasks with sparse reward functions. Empirical results demonstrate that our method significantly improves sample efficiency compared to state-of-the-art RL algorithms, achieving comparable or superior performance with substantially fewer environment interactions. Furthermore, we analyze the properties of the learned intrinsic reward function and demonstrate its effectiveness in guiding exploration towards informative regions of the state space, facilitating faster policy convergence.",ai
"We address the challenge of robust causal effect estimation in the presence of unobserved confounding and selection bias. Traditional methods often rely on strong assumptions about the causal structure or the availability of high-quality proxy variables. This work proposes a novel instrumental variable (IV) approach, leveraging observed auxiliary variables correlated with the confounders but not directly affecting the outcome, to construct synthetic instruments. We introduce a two-stage moment matching procedure. In the first stage, we estimate the conditional moments of the unobserved confounders given the auxiliary variables using a neural network architecture trained via adversarial learning to minimize distributional discrepancy between the predicted and true conditional distributions. The second stage then uses these estimated moments to construct instruments satisfying the IV exclusion restriction. We theoretically establish the consistency and asymptotic normality of our estimator under mild regularity conditions. Empirically, we evaluate our method on both synthetic and real-world datasets, including simulations with varying degrees of confounding and selection bias. Results demonstrate that our approach consistently outperforms existing IV methods and adjustment techniques, particularly when the instrument strength is weak and the auxiliary variables provide informative signals about the unobserved confounders. This framework offers a practical and robust solution for causal inference in complex observational settings.",ai
"Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely ""think with images"" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.",human
"We address the problem of efficiently representing and reasoning with complex, hierarchical knowledge structures common in domains such as biological taxonomies and organizational hierarchies. Existing knowledge representation formalisms often struggle with balancing expressiveness and computational tractability when dealing with such structures, leading to either limited representational power or intractably complex reasoning procedures. We introduce a novel hybrid approach, Hierarchical Concept Logic (HCL), that integrates Description Logic (DL) with hierarchical constraint networks. HCL leverages DL's expressive power for defining concept relationships and uses hierarchical constraint networks to model contextual dependencies and exceptions within the hierarchy. This approach enables a more nuanced and flexible representation of hierarchical knowledge compared to traditional DL-based approaches. We develop a sound and complete reasoning algorithm for HCL based on a combination of DL tableau reasoning and constraint propagation techniques. Through empirical evaluation on benchmark knowledge bases derived from biological ontologies and organizational charts, we demonstrate that HCL achieves a significant improvement in reasoning efficiency compared to standard DL reasoners while maintaining comparable expressiveness. Furthermore, our results show that HCL effectively captures contextual dependencies and exceptions, leading to more accurate and robust knowledge representation in hierarchical domains.",ai
"Dimensionless learning is a data-driven framework for discovering dimensionless numbers and scaling laws from experimental measurements. This tutorial introduces the method, explaining how it transforms experimental data into compact physical laws that reveal compact dimensional invariance between variables. The approach combines classical dimensional analysis with modern machine learning techniques. Starting from measurements of physical quantities, the method identifies the fundamental ways to combine variables into dimensionless groups, then uses neural networks to discover which combinations best predict the experimental output. A key innovation is a regularization technique that encourages the learned coefficients to take simple, interpretable values like integers or half-integers, making the discovered laws both accurate and physically meaningful. We systematically investigate how measurement noise and discrete sampling affect the discovery process, demonstrating that the regularization approach provides robustness to experimental uncertainties. The method successfully handles cases with single or multiple dimensionless numbers, revealing how different but equivalent representations can capture the same underlying physics. Despite recent progress, key challenges remain, including managing the computational cost of identifying multiple dimensionless groups, understanding the influence of data characteristics, automating the selection of relevant input variables, and developing user-friendly tools for experimentalists. This tutorial serves as both an educational resource and a practical guide for researchers seeking to apply dimensionless learning to their experimental data.",human
"Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the Nexus, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Nexus dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Nexus outperforms standard Transformers on multiple benchmarks.",human
"We address the problem of robust causal effect estimation in the presence of unobserved confounding and selection bias, situations frequently encountered in observational studies. Traditional methods often rely on strong, untestable assumptions, such as ignorability or the absence of selection. We propose a novel instrumental variable (IV) approach utilizing a deep latent variable model (DLVM) to simultaneously infer the causal effect and identify potential instruments from high-dimensional observational data. The DLVM learns a disentangled representation of the observed variables, separating the variation attributable to latent confounders, selection mechanisms, and independent causal drivers. Instrument candidates are identified based on their statistical independence from the inferred confounders and their strong association with the treatment variable, conditional on observed covariates. A two-stage least squares (2SLS) procedure is then applied using the selected instruments to estimate the average treatment effect (ATE). We evaluate our method on both synthetic datasets, where the ground truth is known, and semi-synthetic datasets derived from real-world electronic health records (EHR). Results demonstrate that our approach significantly reduces bias compared to conventional regression and propensity score methods when unobserved confounding and selection bias are present. Furthermore, the learned disentangled representations provide valuable insights into the underlying causal structure of the data.",ai
"We investigate the challenge of robust optimization under distribution shifts, specifically focusing on scenarios where the true data distribution deviates adversarially from a nominal, known distribution. This problem is critical in machine learning applications where model performance must be reliable despite variations in the operational environment. We propose a novel distributionally robust optimization (DRO) framework incorporating kernel density estimation (KDE) to estimate the ambiguity set surrounding the nominal distribution. This KDE-DRO approach leverages the non-parametric nature of KDE to adapt to complex and unknown distributional perturbations, offering increased robustness compared to traditional DRO methods that rely on parametric assumptions about the uncertainty set. The ambiguity set is constructed based on a data-driven divergence metric derived from KDE, allowing for tighter control over the level of conservatism. We provide theoretical guarantees on the out-of-sample performance of solutions obtained using our KDE-DRO framework, demonstrating a bound on the expected loss under adversarial distribution shifts. Empirical results on benchmark datasets demonstrate that our KDE-DRO method achieves superior robustness compared to existing DRO techniques and empirical risk minimization, particularly in scenarios with significant and non-parametric distribution shifts, while maintaining competitive performance under the nominal distribution.",ai
"Graph Neural Networks (GNNs) have demonstrated considerable efficacy in learning representations for graph-structured data across diverse application domains. However, the inherent reliance of many GNN architectures on message passing mechanisms can lead to over-smoothing, hindering their ability to capture long-range dependencies and distinguish between nodes with similar neighborhood structures. This paper addresses the problem of mitigating over-smoothing in GNNs while simultaneously enhancing their expressive power. We propose a novel graph neural network architecture, termed Differentiated Edge and Node Attention Network (DENAN), which incorporates learnable, differentiable edge weights in conjunction with node-level attention mechanisms. Specifically, DENAN dynamically modulates the influence of each edge based on its contextual importance, allowing for adaptive filtering of information propagation. Furthermore, the node-level attention mechanism allows each node to selectively aggregate information from its neighbors, enabling the model to focus on the most relevant features. We conduct extensive experiments on benchmark graph datasets, including node classification and graph classification tasks. The results demonstrate that DENAN consistently outperforms existing GNN architectures, achieving significant improvements in accuracy and robustness to over-smoothing. Ablation studies validate the individual contributions of the differentiable edge weights and node attention mechanisms, highlighting their synergistic effect on the overall performance of the proposed model.",ai
"Contour location$$is a well-studied active learning problem. Here, we tackle a related but distinct problem: identifying the input configuration that returns pre-specified values of multiple independent computer experiments simultaneously. Motivated by computer experiments of the rotational torques acting upon a vehicle in flight, we aim to identify stable flight conditions which result in zero torque forces. We propose a ""joint contour location"" (jCL) scheme that strikes a strategic balance between exploring the multiple response surfaces while exploiting learning of the intersecting contours. We employ both shallow and deep Gaussian process surrogates, but our jCL procedure is applicable to any surrogate that can provide posterior predictive distributions. Our jCL designs significantly outperform existing (single response) CL strategies, enabling us to efficiently locate the joint contour of our motivating computer experiments.",human
"Agentic reinforcement learning increasingly relies on experience-driven scaling, yet real-world environments remain non-adaptive, limited in coverage, and difficult to scale. World models offer a potential way to improve learning efficiency through simulated experience, but it remains unclear whether large language models can reliably serve this role and under what conditions they meaningfully benefit agents. We study these questions in text-based environments, which provide a controlled setting to reinterpret language modeling as next-state prediction under interaction. We introduce a three-level framework for evaluating LLM-based world models: (i) fidelity and consistency, (ii) scalability and robustness, and (iii) agent utility. Across five representative environments, we find that sufficiently trained world models maintain coherent latent state, scale predictably with data and model size, and improve agent performance via action verification, synthetic trajectory generation, and warm-starting reinforcement learning. Meanwhile, these gains depend critically on behavioral coverage and environment complexity, delineating clear boundry on when world modeling effectively supports agent learning.",human
"We address the exploration-exploitation dilemma in sparse reward reinforcement learning environments, where delayed and infrequent rewards hinder effective policy learning. Traditional methods often struggle due to the difficulty in attributing value to actions that only indirectly lead to reward. We introduce a novel hierarchical reinforcement learning framework, Hierarchical Exploration with Intrinsic Motivation (HEIM), that combines a high-level manager policy with low-level worker policies. The manager learns to set intrinsic goals for the workers, which are incentivized to reach these goals using an intrinsic reward signal proportional to their success. This hierarchical decomposition allows for more structured exploration and facilitates temporal credit assignment. Furthermore, HEIM employs a curiosity-driven mechanism to dynamically adjust the intrinsic goals, prioritizing exploration in regions of state space with high learning potential. We evaluate HEIM on a suite of challenging sparse reward benchmark environments, including sparse versions of the OpenAI Gymâ€™s Ant and HalfCheetah locomotion tasks. Our experimental results demonstrate that HEIM significantly outperforms state-of-the-art exploration methods, achieving substantial improvements in sample efficiency and final performance. Specifically, HEIM achieves a 2-3x performance gain compared to baseline methods in terms of cumulative reward, showcasing its efficacy in addressing the exploration challenges inherent in sparse reward settings.",ai
"We address the challenge of efficiently representing and reasoning with complex, structured knowledge, specifically focusing on scenarios involving incomplete or uncertain information. Existing knowledge representation formalisms often struggle to balance expressiveness with computational tractability, leading to scalability issues in real-world applications. We propose a novel knowledge representation framework, termed Probabilistic Attributed Concept Graphs (PACGs), which extends attributed concept graphs with probabilistic semantics. PACGs represent concepts and relationships as nodes and edges, respectively, augmenting them with attributes describing various properties. Crucially, we introduce probabilistic distributions over these attributes and relations, allowing for the encoding of uncertainty and ambiguity. We further develop a sound and complete inference algorithm based on Bayesian network reasoning principles tailored to PACGs. Empirical evaluation on benchmark knowledge graphs and synthetic datasets demonstrates that PACGs achieve significant improvements in both reasoning accuracy and efficiency compared to traditional logic-based and purely statistical approaches. Specifically, our method demonstrates a 20% increase in link prediction accuracy and a 35% reduction in inference time when handling noisy or incomplete knowledge bases. The PACG framework provides a robust and scalable solution for knowledge representation and reasoning in complex and uncertain domains.",ai
"We investigate the problem of sparse reward environments in reinforcement learning (RL), where agents struggle to discover successful policies due to infrequent feedback signals. Traditional RL algorithms often exhibit poor performance in such scenarios, requiring extensive exploration or sophisticated reward shaping techniques. To address this challenge, we propose a novel approach incorporating a hierarchical reinforcement learning framework augmented with intrinsic motivation derived from predictive surprise. Our method divides the learning process into two levels: a higher-level manager that sets abstract goals for a lower-level worker, and the worker which aims to achieve these goals. The manager receives intrinsic rewards based on the prediction error of a forward model predicting the next state given the current state and the worker's goal. This encourages the manager to explore states that lead to unpredictable outcomes, thereby facilitating the discovery of novel and potentially rewarding states. Experiments conducted on a suite of sparse reward navigation tasks demonstrate that our approach significantly outperforms baseline RL algorithms and existing exploration methods. Specifically, we observe a 2x-5x improvement in sample efficiency and a higher success rate in reaching the target location compared to conventional deep reinforcement learning techniques. The results suggest that incorporating predictive surprise as an intrinsic motivation signal within a hierarchical RL architecture can effectively mitigate the exploration challenges inherent in sparse reward environments.",ai
"We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.",human
"Recent developments in large language models have shown advantages in reallocating a notable share of computational resource from training time to inference time. However, the principles behind inference time scaling are not well understood. In this paper, we introduce an analytically tractable model of inference-time scaling: Bayesian linear regression with a reward-weighted sampler, where the reward is determined from a linear model, modeling LLM-as-a-judge scenario. We study this problem in the high-dimensional regime, where the deterministic equivalents dictate a closed-form expression for the posterior predictive mean and variance. We analyze the generalization error when training data are sampled from a teacher model. We draw inference-time samples and select via softmax at a temperature applied to a quadratic reward. When the reward is not too different from the teacher, the generalization error decreases monotonically with increasing inference time samples . However, the specific reward that optimizes inference-time selection generally differs from the teacher. In contrast, substantial reward misspecification induces a finite optimal beyond which more sampling can increase the generalization error. For fixed , there exists an optimal sampling temperature. We experimentally verify these facts in large language model inference with an additional large language model as a judge. In the ""best-of-"" limit with the teacher as reward, we theoretically show that the generalization error decays as and determine the leading coefficient via extreme value theory. These formulas delineate domains where scaling inference-time computation is provably preferable to collecting more data. Finally, we demonstrate that when task difficulty increases, the previously mentioned advantage of inference-time compute degrades.",human
"Music Emotion Recogniser (MER) research faces challenges due to limited high-quality annotated datasets and difficulties in addressing cross-track feature drift. This work presents two primary contributions to address these issues. Memo2496, a large-scale dataset, offers 2496 instrumental music tracks with continuous valence arousal labels, annotated by 30 certified music specialists. Annotation quality is ensured through calibration with extreme emotion exemplars and a consistency threshold of 0.25, measured by Euclidean distance in the valence arousal space. Furthermore, the Dual-view Adaptive Music Emotion Recogniser (DAMER) is introduced. DAMER integrates three synergistic modules: Dual Stream Attention Fusion (DSAF) facilitates token-level bidirectional interaction between Mel spectrograms and cochleagrams via cross attention mechanisms; Progressive Confidence Labelling (PCL) generates reliable pseudo labels employing curriculum-based temperature scheduling and consistency quantification using Jensen Shannon divergence; and Style Anchored Memory Learning (SAML) maintains a contrastive memory queue to mitigate cross-track feature drift. Extensive experiments on the Memo2496, 1000songs, and PMEmo datasets demonstrate DAMER's state-of-the-art performance, improving arousal dimension accuracy by 3.43%, 2.25%, and 0.17%, respectively. Ablation studies and visualisation analyses validate each module's contribution. Both the dataset and source code are publicly available.",human
"We investigate the short-context dominance hypothesis: that for most sequences, a small local prefix suffices to predict their next tokens. Using large language models as statistical oracles, we measure the minimum context length (MCL) needed to reproduce accurate full-context predictions across datasets with sequences of varying lengths. For sequences with 1-7k tokens from long-context documents, we consistently find that 75-80% require only the last 96 tokens at most. Given the dominance of short-context tokens, we then ask whether it is possible to detect challenging long-context sequences for which a short local prefix does not suffice for prediction. We introduce a practical proxy to MCL, called Distributionally Aware MCL (DaMCL), that does not require knowledge of the actual next-token and is compatible with sampling strategies beyond greedy decoding. Our experiments validate that simple thresholding of the metric defining DaMCL achieves high performance in detecting long vs. short context sequences. Finally, to counter the bias that short-context dominance induces in LLM output distributions, we develop an intuitive decoding algorithm that leverages our detector to identify and boost tokens that are long-range-relevant. Across Q&A tasks and model architectures, we confirm that mitigating the bias improves performance.",human
"We investigate the problem of spurious correlations confounding causal effect estimation in natural language processing (NLP) tasks. Observed performance gains in NLP models are often attributed to genuine understanding, but may instead stem from the model exploiting easily-detectable, non-causal statistical associations between input features and target labels. To address this, we propose a novel intervention-based causal inference framework tailored for NLP. Our approach, termed Causal Intervention via Feature Masking (CIFM), systematically masks specific input features during training and inference, simulating targeted interventions on the underlying causal graph. CIFM leverages counterfactual reasoning to evaluate the sensitivity of model predictions to these interventions, thereby identifying and mitigating reliance on spurious correlations. We evaluate CIFM on sentiment analysis and natural language inference datasets, demonstrating that it significantly reduces the impact of known biases, such as lexical cues and shortcut reasoning patterns. Specifically, models trained with CIFM exhibit improved robustness against adversarial examples designed to exploit spurious correlations, while maintaining competitive performance on standard benchmarks. Our findings suggest that CIFM provides a practical and effective methodology for enhancing the causal validity and generalization capabilities of NLP models.",ai
"This study analyzes the impact of heterogeneity (""Variety"") in Big Data by comparing classification strategies across structured (Epsilon) and unstructured (Rest-Mex, IMDB) domains. A dual methodology was implemented: evolutionary and Bayesian hyperparameter optimization (Genetic Algorithms, Optuna) in Python for numerical data, and distributed processing in Apache Spark for massive textual corpora. The results reveal a ""complexity paradox"": in high-dimensional spaces, optimized linear models (SVM, Logistic Regression) outperformed deep architectures and Gradient Boosting. Conversely, in text-based domains, the constraints of distributed fine-tuning led to overfitting in complex models, whereas robust feature engineering -- specifically Transformer-based embeddings (ROBERTa) and Bayesian Target Encoding -- enabled simpler models to generalize effectively. This work provides a unified framework for algorithm selection based on data nature and infrastructure constraints.",human
"Generative artificial intelligence tools, like ChatGPT, are an increasingly utilized resource among computational social scientists. Nevertheless, there remains space for improved understanding of the performance of ChatGPT in complex tasks such as classifying and annotating datasets containing nuanced language. Method. In this paper, we measure the performance of GPT-4 on one such task and compare results to human annotators. We investigate ChatGPT versions 3.5, 4, and 4o to examine performance given rapid changes in technological advancement of large language models. We craft four prompt styles as input and evaluate precision, recall, and F1 scores. Both quantitative and qualitative evaluations of results demonstrate that while including label definitions in prompts may help performance, overall GPT-4 has difficulty classifying nuanced language. Qualitative analysis reveals four specific findings. Our results suggest the use of ChatGPT in classification tasks involving nuanced language should be conducted with prudence.",human
"We address the challenge of sparse reward environments in reinforcement learning, specifically in the context of natural language generation. While sequence-to-sequence models have demonstrated success, training with reinforcement learning often suffers from the difficulty of attributing credit to specific actions within a long sequence when rewards are infrequent or delayed. We propose a novel approach, ""Hierarchical Reward Shaping with Imitation Learning Pretraining"" (HRS-IL), that combines imitation learning pretraining with a hierarchical reward structure designed to alleviate reward sparsity. HRS-IL utilizes a two-level hierarchy: a high-level module that receives a delayed extrinsic reward based on overall task performance, and a low-level module that receives immediate intrinsic rewards based on the similarity between the current action and actions from a pre-trained imitation learning policy. This intrinsic reward provides dense feedback to the low-level module, guiding exploration and accelerating learning. Empirical evaluation on a text summarization task demonstrates that HRS-IL significantly outperforms baseline reinforcement learning methods, achieving a 15% improvement in ROUGE-L score and converging to a superior policy with greater sample efficiency. Ablation studies confirm the individual contributions of both imitation learning pretraining and the hierarchical reward shaping component. The findings suggest that structured reward mechanisms can effectively mitigate reward sparsity and enable more efficient reinforcement learning for complex sequence generation tasks.",ai
"Widespread Pb (lead) contamination of urban soil significantly impacts food safety and public health and hinders city greening efforts. However, most existing technologies for measuring Pb are labor-intensive and costly. In this study, we propose SoilScanner, a radio frequency-based wireless system that can detect Pb in soils. This is based on our discovery that the propagation of different frequency band radio signals is affected differently by different salts such as NaCl and Pb(NO3)2 in the soil. In a controlled experiment, manually adding NaCl and Pb(NO3)2 in clean soil, we demonstrated that different salts reflected signals at different frequencies in distinct patterns. In addition, we confirmed the finding using uncontrolled field samples with a machine learning model. Our experiment results show that SoilScanner can classify soil samples into low-Pb and high-Pb categories (threshold at 200 ppm) with an accuracy of 72%, with no sample with > 500 ppm of Pb being misclassified. The results of this study show that it is feasible to build portable and affordable Pb detection and screening devices based on wireless technology.",human
"Despite extensive focus on techniques for evaluating the performance of two learning algorithms on a single dataset, the critical challenge of developing statistical tests to compare multiple algorithms across various datasets has been largely overlooked in most machine learning research. Additionally, in the realm of Online Learning, ensuring statistical significance is essential to validate continuous learning processes, particularly for achieving rapid convergence and effectively managing concept drifts in a timely manner. Robust statistical methods are needed to assess the significance of performance differences as data evolves over time. This article examines the state-of-the-art online regression models and empirically evaluates several suitable tests. To compare multiple online regression models across various datasets, we employed the Friedman test along with corresponding post-hoc tests. For thorough evaluations, utilizing both real and synthetic datasets with 5-fold cross-validation and seed averaging ensures comprehensive assessment across various data subsets. Our tests generally confirmed the performance of competitive baselines as consistent with their individual reports. However, some statistical test results also indicate that there is still room for improvement in certain aspects of state-of-the-art methods.",human
"This work addresses the critical challenge of privacy leakage in machine learning (ML) models deployed in sensitive domains, where training data contains personally identifiable information (PII). Specifically, we investigate the vulnerability of large language models (LLMs) to membership inference attacks (MIAs), which aim to determine if a given data point was used to train the model. We propose a novel defense mechanism, Differentially Private Federated Averaging with Knowledge Distillation (DP-FedAvg-KD), that combines the strengths of federated learning, differential privacy, and knowledge distillation. DP-FedAvg-KD trains local LLMs on distributed, privacy-sensitive data under differential privacy constraints, mitigating the risk of individual data exposure. Subsequently, knowledge distillation is employed to transfer the learned knowledge from these private local models to a public, non-private student model, thereby preserving utility while further obfuscating training data membership. Empirical evaluation on benchmark datasets demonstrates that DP-FedAvg-KD significantly reduces the success rate of MIAs compared to baseline models trained with differential privacy alone. Furthermore, the student model achieves comparable performance to a centrally trained non-private model, suggesting that DP-FedAvg-KD offers a promising approach to balance privacy preservation and model utility in LLM training.",ai
"Online support groups for smoking cessation are economical and accessible, yet they often face challenges with low user engagement and stigma. The use of an automatic conversational agent would improve engagement by ensuring that all user comments receive a timely response.). We address the challenge of insufficient high-quality data by employing a two-level data augmentation strategy: synthetic data augmentation and real data augmentation. First, we fine-tuned an open source LLM to classify posts from our existing smoking cessation support groups and identify intents with low F1 (precision+recall) scores. Then, for these intents, we generate additional synthetic data using prompt engineering with the GPT model, with an average of 87\% of the generated synthetic posts deemed high quality by human annotators. Overall, the synthetic augmentation process resulted in 43\% of the original posts being selected for augmentation, followed by 140\% synthetic expansion of these posts. Additionally, we scraped more than 10,000 real posts from a related online support context, of which 73\% were validated as good quality by human annotators. Each synthetic or scraped post underwent rigorous validation involving human reviewers to ensure quality and relevance. The validated new data, combined with the original support group posts, formed an augmented dataset used to retrain the intent classifier. Performance evaluation of the retrained model demonstrated a 32\% improvement in F1, confirming the effectiveness of our data augmentation approach. Synthetic and real post augmentation led to similar performance improvements. This study provides a replicable framework for enhancing conversational agent performance in domains where data scarcity is a critical issue.",human
"Artificial Intelligence (AI) has revolutionized software development, particularly by automating repetitive tasks and improving developer productivity. While these advancements are well-documented, the use of AI-powered tools for Software Vulnerability Management (SVM), such as vulnerability detection and repair, remains underexplored in industry settings. To bridge this gap, our study aims to determine the extent of the adoption of AI-powered tools for SVM, identify barriers and facilitators to the use, and gather insights to help improve the tools to meet industry needs better. We conducted a survey study involving 60 practitioners from diverse industry sectors across 27 countries. The survey incorporates both quantitative and qualitative questions to analyze the adoption trends, assess tool strengths, identify practical challenges, and uncover opportunities for improvement. Our findings indicate that AI-powered tools are used throughout the SVM life cycle, with 69% of users reporting satisfaction with their current use. Practitioners value these tools for their speed, coverage, and accessibility. However, concerns about false positives, missing context, and trust issues remain prevalent. We observe a socio-technical adoption pattern in which AI outputs are filtered through human oversight and organizational governance. To support safe and effective use of AI for SVM, we recommend improvements in explainability, contextual awareness, integration workflows, and validation practices. We assert that these findings can offer practical guidance for practitioners, tool developers, and researchers seeking to enhance secure software development through the use of AI.",human
"We address the challenge of enhancing automated reasoning capabilities in complex logical domains, focusing on scenarios where explicit knowledge representations are incomplete or noisy. Existing methods often struggle with efficient exploration of the solution space and adaptation to unforeseen domain variations. Our approach introduces a novel framework leveraging reinforcement learning to guide proof search, specifically utilizing a hybrid architecture that integrates a deep neural network-based policy function with a symbolic reasoning engine. The policy function learns to prioritize inference rules and select relevant axioms based on the current proof state, while the symbolic engine ensures logical consistency and completeness within the chosen inference path. We evaluate our system on benchmark theorem proving problems from the TPTP library, including challenging domains such as group theory and set theory. Empirical results demonstrate a significant improvement in theorem proving success rates and a reduction in proof lengths compared to state-of-the-art automated theorem provers. Furthermore, we analyze the learned policy function to uncover insights into effective proof strategies within these domains, suggesting potential for generalizable reasoning principles. The proposed method offers a promising avenue for bridging the gap between data-driven learning and symbolic reasoning in complex problem-solving environments.",ai
"Art is widely recognized as a reflection of civilization and mosaics represent an important part of cultural heritage. Mosaics are an ancient art form created by arranging small pieces, called tesserae, on a surface using adhesive. Due to their age and fragility, they are prone to damage, highlighting the need for digital preservation. This paper addresses the problem of digitizing mosaics by segmenting the tesserae to separate them from the background within the broader field of Image Segmentation in Computer Vision. We propose a method leveraging Segment Anything Model 2 (SAM 2) by Meta AI, a foundation model that outperforms most conventional segmentation models, to automatically segment mosaics. Due to the limited open datasets in the field, we also create an annotated dataset of mosaic images to fine-tune and evaluate the model. Quantitative evaluation on our testing dataset shows notable improvements compared to the baseline SAM 2 model, with Intersection over Union increasing from 89.00% to 91.02% and Recall from 92.12% to 95.89%. Additionally, on a benchmark proposed by a prior approach, our model achieves an F-measure 3% higher than previous methods and reduces the error in the absolute difference between predicted and actual tesserae from 0.20 to just 0.02. The notable performance of the fine-tuned SAM 2 model together with the newly annotated dataset can pave the way for real-time segmentation of mosaic images.",human
"Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply-demand conditions. Adaptive delayed matching creates a trade-off between matching and pickup delays by deciding whether to assign drivers immediately or batch requests. Since outcomes accumulate over long horizons with stochastic dynamics, reinforcement learning (RL) is a suitable framework. However, existing approaches often oversimplify traffic dynamics or use shallow encoders that miss complex spatiotemporal patterns. We introduce the Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE), which formalizes adaptive delayed matching as a regime-aware MDP equipped with a self-attention MoE encoder. Unlike monolithic networks, our experts specialize automatically, improving representation capacity while maintaining computational efficiency. A physics-informed congestion surrogate preserves realistic density-speed feedback, enabling millions of efficient rollouts, while an adaptive reward scheme guards against pathological strategies. With only 12M parameters, our framework outperforms strong baselines. On real-world Uber trajectory data (San Francisco), it improves total reward by over 13%, reducing average matching and pickup delays by 10% and 15% respectively. It demonstrates robustness across unseen demand regimes and stable training. These findings highlight the potential of MoE-enhanced RL for large-scale decision-making with complex spatiotemporal dynamics.",human
"This study applies Brookes' Measure of Categorical Dispersion (Î”) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Î” = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.",human
"We address the challenge of sample inefficiency in reinforcement learning, particularly in environments with sparse rewards and high-dimensional state spaces. Many existing algorithms struggle to efficiently explore such environments, often requiring an impractically large number of interactions to achieve acceptable performance. To mitigate this limitation, we propose a novel approach, termed the ""Curiosity-Driven Hierarchical Exploration (CDHE)"" framework, which combines intrinsic motivation with hierarchical reinforcement learning. CDHE learns a hierarchical policy structure wherein higher-level policies set abstract goals for lower-level policies, thereby promoting temporally extended exploration. The intrinsic motivation component leverages prediction error as a reward signal, encouraging the agent to explore regions of the state space where its understanding is limited. Crucially, CDHE employs a variational autoencoder to learn a latent representation of the state space, facilitating the discovery and parameterization of effective goals for the hierarchical policy. We evaluate CDHE across a suite of challenging benchmark environments, demonstrating significant improvements in sample efficiency compared to several state-of-the-art reinforcement learning algorithms, including PPO, SAC, and HER. Specifically, CDHE achieves comparable or superior performance with an order of magnitude fewer environment interactions in sparse reward settings, suggesting that the proposed framework effectively addresses the limitations of existing methods in challenging exploration domains.",ai
"Distributionally robust optimization (DRO) has emerged as a powerful paradigm for reliable decision-making under uncertainty. This paper focuses on DRO with ambiguity sets defined via the Sinkhorn discrepancy: an entropy-regularized Wasserstein distance, referred to as Sinkhorn DRO. Existing work primarily addresses Sinkhorn DRO from a dual perspective, leveraging its formulation as a conditional stochastic optimization problem, for which many stochastic gradient methods are applicable. However, the theoretical analyses of such methods often rely on the boundedness of the loss function, and it is indirect to obtain the worst-case distribution associated with Sinkhorn DRO. In contrast, we study Sinkhorn DRO from the primal perspective, by reformulating it as a bilevel program with several infinite-dimensional lower-level subproblems over probability space. This formulation enables us to simultaneously obtain the optimal robust decision and the worst-case distribution, which is valuable in practical settings, such as generating stress-test scenarios or designing robust learning algorithms. We propose both double-loop and single-loop sampling-based algorithms with theoretical guarantees to solve this bilevel program. Finally, we demonstrate the effectiveness of our approach through a numerical study on adversarial classification.",human
"--- **Privacy-Preserving Federated Learning with Differential Privacy and Knowledge Distillation** Federated learning (FL) enables collaborative model training without direct data sharing, offering a degree of privacy. However, recent studies have demonstrated the vulnerability of FL systems to various inference attacks that can compromise participant data privacy. This paper addresses the challenge of enhancing privacy in FL by combining differential privacy (DP) with knowledge distillation (KD). Our proposed method, FedDistillDP, integrates a differentially private aggregation mechanism within the federated averaging process to protect against membership inference attacks. Simultaneously, it employs KD to transfer knowledge from multiple locally trained models to a single, more robust, global model, mitigating the impact of noise introduced by DP. We analyze the privacy-utility trade-off of FedDistillDP theoretically, deriving bounds on the privacy loss. Empirical evaluations on benchmark image classification datasets (CIFAR-10, MNIST) demonstrate that FedDistillDP achieves a significant improvement in privacy protection compared to standard differentially private FL approaches. Specifically, we observe a reduction in membership inference accuracy while maintaining comparable or superior model accuracy. The results highlight the efficacy of FedDistillDP in creating a more secure and privacy-preserving federated learning paradigm.",ai
"The fast growth of digital health systems has led to a need to better comprehend how they interpret and represent patient-reported symptoms. Chatbots have been used in healthcare to provide clinical support and enhance the user experience, making it possible to provide meaningful clinical patterns from text-based data through chatbots. The proposed research utilises several different natural language processing methods to study the occurrences of symptom descriptions in medicine as well as analyse the patterns that emerge through these conversations within medical bots. Through the use of the Medical Conversations to Disease Dataset which contains 960 multi-turn dialogues divided into 24 Clinical Conditions, a standardised representation of conversations between patient and bot is created for further analysis by computational means. The multi-method approach uses a variety of tools, including Latent Dirichlet Allocation (LDA) to identify latent symptom themes, K-Means to group symptom descriptions by similarity, Transformer-based Named Entity Recognition (NER) to extract medical concepts, and the Apriori algorithm to discover frequent symptom pairs. Findings from the analysis indicate a coherent structure of clinically relevant topics, moderate levels of clustering cohesiveness and several high confidence rates on the relationships between symptoms like fever headache and rash itchiness. The results support the notion that conversational medical data can be a valuable diagnostic signal for early symptom interpretation, assist in strengthening decision support and improve how users interact with tele-health technology. By demonstrating a method for converting unstructured free-flowing dialogue into actionable knowledge regarding symptoms this work provides an extensible framework to further enhance future performance, dependability and clinical utility of selecting medical chatbots.",human
"AI-for-Code (AI4Code) systems are reshaping software engineering, with tools like GitHub Copilot accelerating code generation, translation, and vulnerability detection. Alongside these advances, however, security risks remain pervasive: insecure outputs, biased benchmarks, and susceptibility to adversarial manipulation undermine their reliability. This SoK surveys the landscape of AI4Code security across three core applications, identifying recurring gaps: benchmark dominance by Python and toy problems, lack of standardized security datasets, data leakage in evaluation, and fragile adversarial robustness. A comparative study of six state-of-the-art models illustrates these challenges: insecure patterns persist in code generation, vulnerability detection is brittle to semantic-preserving attacks, fine-tuning often misaligns security objectives, and code translation yields uneven security benefits. From this analysis, we distill three forward paths: embedding secure-by-default practices in code generation, building robust and comprehensive detection benchmarks, and leveraging translation as a route to security-enhanced languages. We call for a shift toward security-first AI4Code, where vulnerability mitigation and robustness are embedded throughout the development life cycle.",human
"Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.",human
"Programmable Logic Controllers (PLCs) are critical components in Industrial Control Systems (ICSs). Their potential exposure to external world makes them susceptible to cyber-attacks. Existing detection methods against controller logic attacks use either specification-based or learnt models. However, specification-based models require experts' manual efforts or access to PLC's source code, while machine learning-based models often fall short of providing explanation for their decisions. We design SRLR -- a it Symbolic Regression based Logic Recovery} solution to identify the logic of a PLC based only on its inputs and outputs. The recovered logic is used to generate explainable rules for detecting controller logic attacks. SRLR enhances the latest deep symbolic regression methods using the following ICS-specific properties: (1) some important ICS control logic is best represented in frequency domain rather than time domain; (2) an ICS controller can operate in multiple modes, each using different logic, where mode switches usually do not happen frequently; (3) a robust controller usually filters out outlier inputs as ICS sensor data can be noisy; and (4) with the above factors captured, the degree of complexity of the formulas is reduced, making effective search possible. Thanks to these enhancements, SRLR consistently outperforms all existing methods in a variety of ICS settings that we evaluate. In terms of the recovery accuracy, SRLR's gain can be as high as 39% in some challenging environment. We also evaluate SRLR on a distribution grid containing hundreds of voltage regulators, demonstrating its stability in handling large-scale, complex systems with varied configurations.",human
"Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.",human
"Imitation learning (IL) has emerged as a central paradigm in autonomous driving. While IL excels in matching expert behavior in open-loop settings by minimizing per-step prediction errors, its performance degrades unexpectedly in closed-loop due to the gradual accumulation of small, often imperceptible errors over time.Over successive planning cycles, these errors compound, potentially resulting in severe failures.Current research efforts predominantly rely on increasingly sophisticated network architectures or high-fidelity training datasets to enhance the robustness of IL planners against error accumulation, focusing on the state-level robustness at a single time point. However, autonomous driving is inherently a continuous-time process, and leveraging the temporal scale to enhance robustness may provide a new perspective for addressing this issue.To this end, we propose a method termed Sequence of Experts (SoE), a temporal alternation policy that enhances closed-loop performance without increasing model size or data requirements. Our experiments on large-scale autonomous driving benchmarks nuPlan demonstrate that SoE method consistently and significantly improves the performance of all the evaluated models, and achieves state-of-the-art performance.This module may provide a key and widely applicable support for improving the training efficiency of autonomous driving models.",human
"Cloud Security Operations Center (SOC) enable cloud governance, risk and compliance by providing insights visibility and control. Cloud SOC triages high-volume, heterogeneous telemetry from elastic, short-lived resources while staying within tight budgets. In this research, we implement an AI-Augmented Security Operations Center (AISOC) on AWS that combines cloud-native instrumentation with ML-based detection. The architecture uses three Amazon EC2 instances: Attacker, Defender, and Monitoring. We simulate a reverse-shell intrusion with Metasploit, and Filebeat forwards Defender logs to an Elasticsearch and Kibana stack for analysis. We train two classifiers, a malware detector built on a public dataset and a log-anomaly detector trained on synthetically augmented logs that include adversarial variants. We calibrate and fuse the scores to produce multi-modal threat intelligence and triage activity into NORMAL, SUSPICIOUS, and HIGH\_CONFIDENCE\_ATTACK. On held-out tests the fusion achieves strong macro-F1 (up to 1.00) under controlled conditions, though performance will vary in noisier and more diverse environments. These results indicate that simple, calibrated fusion can enhance cloud SOC capabilities in constrained, cost-sensitive setups.",human
"We address the problem of spurious correlations in natural language inference (NLI) datasets, specifically focusing on lexical overlap bias and its detrimental impact on model generalization. Existing methods often rely on heuristics or adversarial training, which can be computationally expensive and lack theoretical guarantees. We propose a novel causal inference framework for NLI, leveraging the backdoor adjustment to deconfound the relationship between premise-hypothesis overlap and the inference outcome. Our method involves explicitly estimating the causal effect of relevant premise tokens on the probability of entailment, disentangling it from the spurious influence of lexical overlap. This is achieved by learning intervention distributions via a variational autoencoder, allowing us to analytically compute the adjusted causal effect. We evaluate our approach on several benchmark NLI datasets exhibiting varying degrees of lexical overlap bias, including HANS and MNLI-adversarial. Empirical results demonstrate that our method significantly improves out-of-distribution generalization performance compared to standard training and existing debiasing techniques. Notably, the learned causal embeddings exhibit enhanced interpretability, highlighting the tokens most causally relevant to the inference decision. We further provide theoretical analysis establishing the consistency of our causal effect estimation.",ai
"End-to-end paradigms have demonstrated great potential for autonomous driving. Additionally, most existing methods are built upon Transformer architectures. However, transformers incur a quadratic attention cost, limiting their ability to model long spatial and temporal sequences-particularly on resource-constrained edge platforms. As autonomous driving inherently demands efficient temporal modeling, this challenge severely limits their deployment and real-time performance. Recently, linear attention mechanisms have gained increasing attention due to their superior spatiotemporal complexity. However, existing linear attention architectures are limited to self-attention, lacking support for cross-modal and cross-temporal interactions-both crucial for autonomous driving. In this work, we propose LADY, the first fully linear attention-based generative model for end-to-end autonomous driving. LADY enables fusion of long-range temporal context at inference with constant computational and memory costs, regardless of the history length of camera and LiDAR features. Additionally, we introduce a lightweight linear cross-attention mechanism that enables effective cross-modal information exchange. Experiments on the NAVSIM and Bench2Drive benchmarks demonstrate that LADY achieves state-of-the-art performance with constant-time and memory complexity, offering improved planning performance and significantly reduced computational cost. Additionally, the model has been deployed and validated on edge devices, demonstrating its practicality in resource-limited scenarios.",human
"Graph Neural Networks (GNNs) have emerged as a powerful paradigm for learning representations from graph-structured data, yet scalability remains a significant challenge, particularly for large, densely connected graphs. Many existing GNN architectures rely on iterative message passing between nodes, leading to computational bottlenecks as graph size and node degree increase. This work addresses the scalability problem by proposing a novel subgraph sampling strategy coupled with a graph convolutional network (GCN) variant. Specifically, we introduce a biased random walk-based subgraph sampler that prioritizes the selection of subgraphs exhibiting high structural diversity, thereby capturing a more comprehensive representation of the global graph structure within smaller, more manageable subgraphs. The sampled subgraphs are then processed by a modified GCN layer that incorporates adaptive aggregation weights, allowing the model to dynamically adjust the influence of neighboring nodes during the message passing phase. Empirical evaluation on benchmark graph classification and node classification datasets demonstrates that our proposed method achieves comparable or superior performance to existing full-graph GNNs, while significantly reducing computational cost and memory footprint. Specifically, our approach achieves up to a 3x speedup in training time and a 2x reduction in memory usage on large-scale graph datasets.",ai
"Test-time scaling has emerged as a promising direction for enhancing the reasoning capabilities of Large Language Models in last few years. In this work, we propose Population-Evolve, a training-free method inspired by Genetic Algorithms to optimize LLM reasoning. Our approach maintains a dynamic population of candidate solutions for each problem via parallel reasoning. By incorporating an evolve prompt, the LLM self-evolves its population in all iterations. Upon convergence, the final answer is derived via majority voting. Furthermore, we establish a unification framework that interprets existing test-time scaling strategies through the lens of genetic algorithms. Empirical results demonstrate that Population-Evolve achieves superior accuracy with low performance variance and computational efficiency. Our findings highlight the potential of evolutionary strategies to unlock the reasoning power of LLMs during inference.",human
"Graph Neural Networks (GNNs) have demonstrated efficacy in various node and graph-level prediction tasks. However, many real-world graphs exhibit significant homophily, where connected nodes tend to share similar attributes. This prevalence of homophily can lead to oversmoothing in deep GNNs, diminishing the expressiveness of node embeddings and hindering performance on downstream tasks, particularly when dealing with heterophilous graphs. We propose a novel adaptive spectral filtering approach to mitigate the oversmoothing problem. Our method, Adaptive Spectral Graph Neural Network (ASGNN), dynamically learns a spectral filter for each node based on the local graph structure and node feature distribution. This adaptive filtering allows ASGNN to selectively smooth node features, preserving valuable information from distant neighbors while minimizing the homogenization caused by excessive smoothing. Empirically, ASGNN achieves state-of-the-art performance on several benchmark datasets encompassing both homophilous and heterophilous graphs. Specifically, we observe significant improvements in node classification accuracy on datasets such as Chameleon and Squirrel, demonstrating the effectiveness of our adaptive filtering mechanism in capturing relevant information from diverse graph topologies. Furthermore, ablation studies confirm the importance of the adaptive spectral filter in preventing oversmoothing and enhancing node representation quality.",ai
"Graph Neural Networks (GNNs) have demonstrated considerable efficacy in various node- and graph-level prediction tasks. However, performance often degrades when applied to large, sparse graphs characterized by extreme class imbalance, a common scenario in real-world knowledge graphs and social networks. This paper addresses the challenge of learning robust node embeddings in such settings. We propose a novel GNN architecture, the Class-Aware Graph Convolutional Network (CAGCN), which incorporates a learned class-aware weighting scheme into the aggregation step. Specifically, CAGCN learns to emphasize contributions from nodes belonging to minority classes during message passing, effectively mitigating the bias induced by imbalanced class distributions. Furthermore, CAGCN integrates a regularization term that encourages feature diversity among nodes of different classes, preventing embedding collapse and promoting discriminative representation learning. We evaluate CAGCN on several benchmark datasets exhibiting varying degrees of class imbalance. Experimental results demonstrate that CAGCN consistently outperforms state-of-the-art GNN models, including standard GCNs, GraphSAGE, and GAT, achieving significant improvements in minority class precision and overall classification accuracy. Ablation studies confirm the effectiveness of both the class-aware weighting and the feature diversity regularization components of CAGCN. The findings suggest that CAGCN offers a more robust and reliable approach to learning node embeddings in imbalanced graph datasets.",ai
"Unmanned surface vehicles can encounter a number of varied visual circumstances during operation, some of which can be very difficult to interpret. While most cases can be solved only using color camera images, some weather and lighting conditions require additional information. To expand the available maritime data, we present a novel multimodal maritime dataset MULTIAQUA (Multimodal Aquatic Dataset). Our dataset contains synchronized, calibrated and annotated data captured by sensors of different modalities, such as RGB, thermal, IR, LIDAR, etc. The dataset is aimed at developing supervised methods that can extract useful information from these modalities in order to provide a high quality of scene interpretation regardless of potentially poor visibility conditions. To illustrate the benefits of the proposed dataset, we evaluate several multimodal methods on our difficult nighttime test set. We present training approaches that enable multimodal methods to be trained in a more robust way, thus enabling them to retain reliable performance even in near-complete darkness. Our approach allows for training a robust deep neural network only using daytime images, thus significantly simplifying data acquisition, annotation, and the training process.",human
"Vehicle-centric perception plays a crucial role in many intelligent systems, including large-scale surveillance systems, intelligent transportation, and autonomous driving. Existing approaches lack effective learning of vehicle-related knowledge during pre-training, resulting in poor capability for modeling general vehicle perception representations. To handle this problem, we propose VehicleMAE-V2, a novel vehicle-centric pre-trained large model. By exploring and exploiting vehicle-related multimodal structured priors to guide the masked token reconstruction process, our approach can significantly enhance the model's capability to learn generalizable representations for vehicle-centric perception. Specifically, we design the Symmetry-guided Mask Module (SMM), Contour-guided Representation Module (CRM) and Semantics-guided Representation Module (SRM) to incorporate three kinds of structured priors into token reconstruction including symmetry, contour and semantics of vehicles respectively. SMM utilizes the vehicle symmetry constraints to avoid retaining symmetric patches and can thus select high-quality masked image patches and reduce information redundancy. CRM minimizes the probability distribution divergence between contour features and reconstructed features and can thus preserve holistic vehicle structure information during pixel-level reconstruction. SRM aligns image-text features through contrastive learning and cross-modal distillation to address the feature confusion caused by insufficient semantic understanding during masked reconstruction. To support the pre-training of VehicleMAE-V2, we construct Autobot4M, a large-scale dataset comprising approximately 4 million vehicle images and 12,693 text descriptions. Extensive experiments on five downstream tasks demonstrate the superior performance of VehicleMAE-V2.",human
"We introduce MotionEdit, a novel dataset for motion-centric image editing-the task of modifying subject actions and interactions while preserving identity, structure, and physical plausibility. Unlike existing image editing datasets that focus on static appearance changes or contain only sparse, low-quality motion edits, MotionEdit provides high-fidelity image pairs depicting realistic motion transformations extracted and verified from continuous videos. This new task is not only scientifically challenging but also practically significant, powering downstream applications such as frame-controlled video synthesis and animation. To evaluate model performance on the novel task, we introduce MotionEdit-Bench, a benchmark that challenges models on motion-centric edits and measures model performance with generative, discriminative, and preference-based metrics. Benchmark results reveal that motion editing remains highly challenging for existing state-of-the-art diffusion-based editing models. To address this gap, we propose MotionNFT (Motion-guided Negative-aware Fine Tuning), a post-training framework that computes motion alignment rewards based on how well the motion flow between input and model-edited images matches the ground-truth motion, guiding models toward accurate motion transformations. Extensive experiments on FLUX.1 Kontext and Qwen-Image-Edit show that MotionNFT consistently improves editing quality and motion fidelity of both base models on the motion editing task without sacrificing general editing ability, demonstrating its effectiveness. Our code is at https://github.com/elainew728/motion-edit/.",human
"Student engagement is a critical factor influencing academic success and learning outcomes. Accurately predicting student engagement is essential for optimizing teaching strategies and providing personalized interventions. However, most approaches focus on single-dimensional feature analysis and assessing engagement based on individual student factors. In this work, we propose a dual-stream multi-feature fusion model based on hypergraph convolutional networks (DS-HGCN), incorporating social contagion of student engagement. DS-HGCN enables accurate prediction of student engagement states by modeling multi-dimensional features and their propagation mechanisms between students. The framework constructs a hypergraph structure to encode engagement contagion among students and captures the emotional and behavioral differences and commonalities by multi-frequency signals. Furthermore, we introduce a hypergraph attention mechanism to dynamically weigh the influence of each student, accounting for individual differences in the propagation process. Extensive experiments on public benchmark datasets demonstrate that our proposed method achieves superior performance and significantly outperforms existing state-of-the-art approaches.",human
"We address the challenge of sample-efficient exploration in reinforcement learning for environments with sparse rewards and complex state spaces. Traditional reinforcement learning algorithms often struggle to efficiently discover rewarding trajectories in such settings, leading to protracted training times and suboptimal policies. To mitigate this, we propose a novel approach integrating intrinsic motivation based on variational information maximization with an off-policy actor-critic framework. Our method, termed Variational Intrinsic Curiosity Actor-Critic (VIC-AC), learns a latent representation of the environmentâ€™s dynamics and maximizes the mutual information between consecutive states within this latent space. This induces an intrinsic reward signal that encourages exploration of novel state transitions. We evaluate VIC-AC on a suite of challenging continuous control tasks with sparse rewards, including locomotion and manipulation benchmarks. Experimental results demonstrate that VIC-AC significantly outperforms existing exploration methods, achieving substantially higher returns and faster convergence rates. Furthermore, we provide an ablation study that validates the effectiveness of each component of our proposed approach. Our findings suggest that variational information maximization is a promising avenue for enhancing exploration in complex reinforcement learning environments.",ai
"Vehicle Routing Problems (VRPs) with diverse real-world attributes have driven recent interest in cross-problem learning approaches that efficiently generalize across problem variants. We propose ARC (Attribute Representation via Compositional Learning), a cross-problem learning framework that learns disentangled attribute representations by decomposing them into two complementary components: an Intrinsic Attribute Embedding (IAE) for invariant attribute semantics and a Contextual Interaction Embedding (CIE) for attribute-combination effects. This disentanglement is achieved by enforcing analogical consistency in the embedding space to ensure the semantic transformation of adding an attribute (e.g., a length constraint) remains invariant across different problem contexts. This enables our model to reuse invariant semantics across trained variants and construct representations for unseen combinations. ARC achieves state-of-the-art performance across in-distribution, zero-shot generalization, few-shot adaptation, and real-world benchmarks.",human
"Perception research is increasingly modelled using streetscapes, yet many approaches still rely on pixel features or object co-occurrence statistics, overlooking the explicit relations that shape human perception. This study proposes a three stage pipeline that transforms street view imagery (SVI) into structured representations for predicting six perceptual indicators. In the first stage, each image is parsed using an open-set Panoptic Scene Graph model (OpenPSG) to extract object predicate object triplets. In the second stage, compact scene-level embeddings are learned through a heterogeneous graph autoencoder (GraphMAE). In the third stage, a neural network predicts perception scores from these embeddings. We evaluate the proposed approach against image-only baselines in terms of accuracy, precision, and cross-city generalization. Results indicate that (i) our approach improves perception prediction accuracy by an average of 26% over baseline models, and (ii) maintains strong generalization performance in cross-city prediction tasks. Additionally, the structured representation clarifies which relational patterns contribute to lower perception scores in urban scenes, such as graffiti on wall and car parked on sidewalk. Overall, this study demonstrates that graph-based structure provides expressive, generalizable, and interpretable signals for modelling urban perception, advancing human-centric and context-aware urban analytics.",human
"We address the challenge of efficiently representing and reasoning with complex relational knowledge, a persistent bottleneck in machine learning applications requiring structured understanding. Existing knowledge representation formalisms often struggle with scalability and expressiveness, leading to high computational costs during inference and limited capacity to capture nuanced relationships. We propose a novel graph-based representation termed ""Attributed Relational Hypergraphs with Embeddings"" (ARHE). ARHE extends conventional knowledge graphs by incorporating hyperedges to model n-ary relations and associating vector embeddings with both nodes and hyperedges. These embeddings are learned jointly with a graph neural network (GNN) architecture optimized for relational reasoning. Specifically, our GNN leverages attention mechanisms to selectively aggregate information from relevant neighbors and hyperedges, facilitating context-aware inference. We evaluate ARHE on a suite of knowledge graph completion and reasoning tasks, including link prediction and path finding. Our experiments demonstrate that ARHE achieves state-of-the-art performance on benchmark datasets, surpassing existing approaches in terms of accuracy and efficiency. Furthermore, ablation studies highlight the importance of both hyperedges and learned embeddings in enhancing the representation's ability to capture complex relational dependencies.",ai
"This study examines the distribution and linguistic characteristics of generic masculines (GM) in contemporary German press texts. The use of masculine personal nouns to refer to mixed-gender groups or unspecified individuals has been widely debated in academia and the public, with con-flicting perspectives on its gender-neutrality. While psycholinguistic studies suggest that GM is more readily associated with male referents, corpus-based analyses of its actual use remain scarce. We investigate GM in a large corpus of press texts, focusing on lexeme-specific differences across dif-ferent types of personal nouns. We conducted manual annotations of the whole inflectional para-digm of 21 personal nouns, resulting in 6,195 annotated tokens. Our findings reveal considerable differences between lexical items, especially between passive role nouns and prestige-related per-sonal nouns. On a grammatical level, we find that GM occurs predominantly in the plural and in indefinite noun phrases. Furthermore, our data shows that GM is not primarily used to denote entire classes of people, as has been previously claimed. By providing an empirical insight into the use of GM in authentic written language, we contribute to a more nuanced understanding of its forms and manifestations. These findings provide a solid basis for aligning linguistic stimuli in psy-cholinguistic studies more closely with real-world language use.",human
"Large Language Models (LLMs) demonstrate impressive capabilities in natural language understanding and generation, but incur high communication overhead and privacy risks in cloud deployments, while facing compute and memory constraints when confined to edge devices. Cloud-edge inference has emerged as a promising paradigm for improving privacy in LLM services by retaining sensitive computations on local devices. However, existing cloud-edge inference approaches apply uniform privacy protection without considering input sensitivity, resulting in unnecessary perturbation and degraded utility even for non-sensitive tokens. To address this limitation, we propose Privacy-aware Routing for Inference with Semantic Modulation (PRISM), a context-aware framework that dynamically balances privacy and inference quality. PRISM executes in four stages: (1) the edge device profiles entity-level sensitivity; (2) a soft gating module on the edge selects an execution mode - cloud, edge, or collaboration; (3) for collaborative paths, the edge applies adaptive two-layer local differential privacy based on entity risks; and (4) the cloud LLM generates a semantic sketch from the perturbed prompt, which is then refined by the edge-side small language model (SLM) using local context. Our results show that PRISM consistently achieves superior privacy-utility trade-offs across various scenarios, reducing energy consumption and latency to 40-50% of baseline methods such as Uniform and Selective LDP, while maintaining high output quality under strong privacy constraints. These findings are validated through comprehensive evaluations involving realistic prompts, actual energy measurements, and heterogeneous cloud-edge model deployments.",human
"Machine learning (ML) has been increasingly applied in concrete research to optimize performance and mixture design. However, one major challenge in applying ML to cementitious materials is the limited size and diversity of available databases. A promising solution is the development of multi-modal databases that integrate both numerical and graphical data. Conventional ML frameworks in cement research are typically restricted to a single data modality. Graph neural network (GNN) represents a new generation of neural architectures capable of learning from data structured as graphs, capturing relationships through irregular or topology-dependent connections rather than fixed spatial coordinates. While GNN is inherently designed for graphical data, they can be adapted to extract correlations from numerical datasets and potentially embed physical laws directly into their architecture, enabling explainable and physics-informed predictions. This work is among the first few studies to implement GNNs to design concrete, with a particular emphasis on establishing a clear and reproducible pathway for converting tabular data into graph representations using the k-nearest neighbor (K-NN) approach. Model hyperparameters and feature selection are systematically optimized to enhance prediction performance. The GNN shows performance comparable to the benchmark random forest, which has been demonstrated by many studies to yield reliable predictions for cementitious materials. Overall, this study provides a foundational roadmap for transitioning from traditional ML to advanced AI architectures. The proposed framework establishes a strong foundation for future multi-modal and physics-informed GNN models capable of capturing complex material behaviors and accelerating the design and optimization of cementitious materials.",human
"The real-time deployment of cascaded generative AI pipelines for applications like video translation is constrained by significant system-level challenges. These include the cumulative latency of sequential model inference and the quadratic () computational complexity that renders multi-user video conferencing applications unscalable. This paper proposes and evaluates a practical system-level framework designed to mitigate these critical bottlenecks. The proposed architecture incorporates a turn-taking mechanism to reduce computational complexity from quadratic to linear in multi-user scenarios, and a segmented processing protocol to manage inference latency for a perceptually real-time experience. We implement a proof-of-concept pipeline and conduct a rigorous performance analysis across a multi-tiered hardware setup, including commodity (NVIDIA RTX 4060), cloud (NVIDIA T4), and enterprise (NVIDIA A100) GPUs. Our objective evaluation demonstrates that the system achieves real-time throughput () on modern hardware. A subjective user study further validates the approach, showing that a predictable, initial processing delay is highly acceptable to users in exchange for a smooth, uninterrupted playback experience. The work presents a validated, end-to-end system design that offers a practical roadmap for deploying scalable, real-time generative AI applications in multilingual communication platforms.",human
"Large language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.",human
"Lightweight, real-time text-to-speech systems are crucial for accessibility. However, the most efficient TTS models often rely on lightweight phonemizers that struggle with context-dependent challenges. In contrast, more advanced phonemizers with a deeper linguistic understanding typically incur high computational costs, which prevents real-time performance. This paper examines the trade-off between phonemization quality and inference speed in G2P-aided TTS systems, introducing a practical framework to bridge this gap. We propose lightweight strategies for context-aware phonemization and a service-oriented TTS architecture that executes these modules as independent services. This design decouples heavy context-aware components from the core TTS engine, effectively breaking the latency barrier and enabling real-time use of high-quality phonemization models. Experimental results confirm that the proposed system improves pronunciation soundness and linguistic accuracy while maintaining real-time responsiveness, making it well-suited for offline and end-device TTS applications.",human
"We investigate the challenge of emergent communication in multi-agent reinforcement learning (MARL) systems operating in complex, partially observable environments. Specifically, we address the problem of coordinating actions when agents have limited visibility and must develop their own communication protocols to achieve optimal collective performance. Our approach leverages a novel combination of differentiable inter-agent learning (DIAL) with a recurrent neural network architecture augmented by attention mechanisms. This allows agents to dynamically focus on relevant information from other agents, enhancing both the efficiency and expressiveness of the learned communication language. We evaluated our method on a series of cooperative navigation and resource allocation tasks within a simulated environment, demonstrating significant improvements over baseline methods that rely on either fixed communication protocols or no communication at all. Empirical results indicate that our attention-based communication strategy facilitates the emergence of more structured and task-specific communication, leading to superior coordination and overall system performance. Furthermore, we analyze the learned communication patterns to reveal insights into the semantic content encoded within the emergent language, suggesting that agents are effectively learning to communicate about environmental features and intended actions.",ai
"We investigate the challenge of identifying causal relationships from observational text data, specifically addressing the problem of distinguishing spurious correlations from genuine causal effects in the presence of confounding variables. Traditional statistical methods often fail in high-dimensional textual domains where confounders are latent and difficult to measure directly. We propose a novel approach, Causal Text Representation Learning (CTRL), which combines deep contextualized embeddings with structural causal models. CTRL leverages pre-trained language models to generate rich representations of textual features, incorporating contextual information to better capture underlying semantic nuances. Subsequently, we employ a modified version of the backdoor adjustment within a potential outcomes framework, using propensity scores estimated from the learned representations to control for confounding. We evaluate CTRL on synthetic and real-world text datasets designed to assess causal inference accuracy in the presence of varying degrees of confounding. Our results demonstrate that CTRL significantly outperforms existing methods, including standard regression techniques and methods that rely on explicit confounder identification. Notably, CTRL exhibits improved robustness to unmeasured confounding compared to baseline approaches, achieving a substantial improvement in average treatment effect (ATE) estimation accuracy.",ai
"Electric load is simultaneously affected across multiple time scales by exogenous factors such as weather and calendar rhythms, sudden events, and policies. Therefore, this paper proposes GRAFT (GRid-Aware Forecasting with Text), which modifies and improves STanHOP to better support grid-aware forecasting and multi-source textual interventions. Specifically, GRAFT strictly aligns daily-aggregated news, social media, and policy texts with half-hour load, and realizes text-guided fusion to specific time positions via cross-attention during both training and rolling forecasting. In addition, GRAFT provides a plug-and-play external-memory interface to accommodate different information sources in real-world deployment. We construct and release a unified aligned benchmark covering 2019--2021 for five Australian states (half-hour load, daily-aligned weather/calendar variables, and three categories of external texts), and conduct systematic, reproducible evaluations at three scales -- hourly, daily, and monthly -- under a unified protocol for comparison across regions, external sources, and time scales. Experimental results show that GRAFT significantly outperforms strong baselines and reaches or surpasses the state of the art across multiple regions and forecasting horizons. Moreover, the model is robust in event-driven scenarios and enables temporal localization and source-level interpretation of text-to-load effects through attention read-out. We release the benchmark, preprocessing scripts, and forecasting results to facilitate standardized empirical evaluation and reproducibility in power grid load forecasting.",human
"Tool calling enables large language models (LLMs) to interact with external environments through tool invocation, providing a practical way to overcome the limitations of pretraining. However, the effectiveness of tool use depends heavily on the quality of the associated documentation and knowledge base context. These materials are usually written for human users and are often misaligned with how LLMs interpret information. This problem is even more pronounced in industrial settings, where hundreds of tools with overlapping functionality create challenges in scalability, variability, and ambiguity. We propose Verification-Guided Context Optimization (VGCO), a framework that uses LLMs as editors to automatically refine tool-related documentation and knowledge base context. VGCO works in two stages. First, Evaluation collects real-world failure cases and identifies mismatches between tools and their context. Second, Optimization performs hierarchical editing through offline learning with structure-aware, in-context optimization. The novelty of our LLM editors has three main aspects. First, they use a hierarchical structure that naturally integrates into the tool-calling workflow. Second, they are state-aware, action-specific, and verification-guided, which constrains the search space and enables efficient, targeted improvements. Third, they enable cost-efficient sub-task specialization, either by prompt engineering large editor models or by post-training smaller editor models. Unlike prior work that emphasizes multi-turn reasoning, VGCO focuses on the single-turn, large-scale tool-calling problem and achieves significant improvements in accuracy, robustness, and generalization across LLMs.",human
"In this paper, the Multi-stage Edge Server Upgrade (M-ESU) is proposed as a new network planning problem, involving the upgrading of an existing multi-access edge computing (MEC) system through multiple stages (e.g., over several years). More precisely, the problem considers two key decisions: (i) whether to deploy additional edge servers or upgrade those already installed, and (ii) how tasks should be offloaded so that the average number of tasks that meet their delay requirement is maximized. The framework specifically involves: (i) deployment of new servers combined with capacity upgrades for existing servers, and (ii) the optimal task offloading to maximize the average number of tasks with a delay requirement. It also considers the following constraints: (i) budget per stage, (ii) server deployment and upgrade cost (in $) and cost depreciation rate, (iii) computation resource of servers, (iv) number of tasks and their growth rate (in %), and (v) the increase in task sizes and stricter delay requirements over time. We present two solutions: a Mixed Integer Linear Programming (MILP) model and an efficient heuristic algorithm (M-ESU/H). MILP yields the optimal solution for small networks, whereas M-ESU/H is used in large-scale networks. For small networks, the simulation results show that the solution computed by M-ESU/H is within 1.25% of the optimal solution while running several orders of magnitude faster. For large networks, M-ESU/H is compared against three alternative heuristic solutions that consider only server deployment, or giving priority to server deployment or upgrade. Our experiments show that M-ESU/H yields up to 21.57% improvement in task satisfaction under identical budget and demand growth conditions, confirming its scalability and practical value for long-term MEC systems.",human
"Understanding patients experiences is essential for advancing patient centered care, especially in chronic diseases that require ongoing communication. However, qualitative thematic analysis, the primary approach for exploring these experiences, remains labor intensive, subjective, and difficult to scale. In this study, we developed a multi agent large language model framework that automates qualitative thematic analysis through three agents (Instructor, Thematizer, CodebookGenerator), named Collaborative Theme Identification Agent (CoTI). We applied CoTI to 12 heart failure patient interviews to analyze their perceptions of medication intensity. CoTI identified key phrases, themes, and codebook that were more similar to those of the senior investigator than both junior investigators and baseline NLP models. We also implemented CoTI into a user-facing application to enable AI human interaction in qualitative analysis. However, collaboration between CoTI and junior investigators provided only marginal gains, suggesting they may overrely on CoTI and limit their independent critical thinking.",human
"We present Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery (ASR-KF-EGR), a training-free inference-time framework for efficient large language model generation. Our method introduces a reversible soft-freeze mechanism that temporarily suspends key-value (KV) updates for low-importance tokens identified within a sliding attention window. Unlike eviction-based approaches that permanently discard context, ASR-KF-EGR preserves all tokens in off-GPU storage and restores them on demand. We extend the framework with sublinear freeze scheduling, where freeze duration grows sublinearly with repeated low-importance detections, preventing over-aggressive compression. Preliminary experiments on LLaMA-3 8B demonstrate 55-67% reduction in active KV cache size while maintaining generation quality and passing needle-in-haystack retrieval tests. The method is architecture-agnostic, requires no fine-tuning, and provides a practical solution for memory-constrained deployment of long-context LLMs.",human
"This paper introduces a confidence-weighted, credibility-aware ensemble framework for text-based emotion detection, inspired by Condorcet's Jury Theorem (CJT). Unlike conventional ensembles that often rely on homogeneous architectures, our approach combines architecturally diverse small transformer-based large language models (sLLMs) - BERT, RoBERTa, DistilBERT, DeBERTa, and ELECTRA, each fully fine-tuned for emotion classification. To preserve error diversity, we minimize parameter convergence while taking advantage of the unique biases of each model. A dual-weighted voting mechanism integrates both global credibility (validation F1 score) and local confidence (instance-level probability) to dynamically weight model contributions. Experiments on the DAIR-AI dataset demonstrate that our credibility-confidence ensemble achieves a macro F1 score of 93.5 percent, surpassing state-of-the-art benchmarks and significantly outperforming large-scale LLMs, including Falcon, Mistral, Qwen, and Phi, even after task-specific Low-Rank Adaptation (LoRA). With only 595M parameters in total, our small LLMs ensemble proves more parameter-efficient and robust than models up to 7B parameters, establishing that carefully designed ensembles of small, fine-tuned models can outperform much larger LLMs in specialized natural language processing (NLP) tasks such as emotion detection.",human
"Multi-intent spoken language understanding (SLU) involves two tasks: multiple intent detection and slot filling, which jointly handle utterances containing more than one intent. Owing to this characteristic, which closely reflects real-world applications, the task has attracted increasing research attention, and substantial progress has been achieved. However, there remains a lack of a comprehensive and systematic review of existing studies on multi-intent SLU. To this end, this paper presents a survey of recent advances in multi-intent SLU. We provide an in-depth overview of previous research from two perspectives: decoding paradigms and modeling approaches. On this basis, we further compare the performance of representative models and analyze their strengths and limitations. Finally, we discuss the current challenges and outline promising directions for future research. We hope this survey will offer valuable insights and serve as a useful reference for advancing research in multi-intent SLU.",human
"We investigate a novel approach to distributionally robust optimization (DRO) for machine learning models, focusing on scenarios where training data is corrupted by adversarial noise. Traditional DRO methods, while effective in principle, often suffer from computational intractability, particularly with complex model architectures. Our work introduces a computationally efficient DRO framework based on a kernel density estimation (KDE) approach to uncertainty set construction. Specifically, we leverage a robustified KDE, resistant to outlier influence, to estimate the underlying data distribution and subsequently define an ambiguity set centered around this estimate. This ambiguity set is then used within a min-max optimization problem to derive model parameters resilient to worst-case distributional shifts within the set. The proposed method's tractability stems from a relaxation technique that transforms the original min-max problem into a tractable convex program under mild assumptions. We demonstrate the efficacy of our approach through extensive empirical evaluations on benchmark image classification datasets (e.g., MNIST, CIFAR-10) corrupted by various adversarial attacks. Our results show that the proposed KDE-based DRO method achieves superior robustness against adversarial perturbations compared to standard empirical risk minimization and existing DRO techniques, while maintaining comparable computational efficiency, especially in high-dimensional feature spaces. The observed improvements are statistically significant, validating the effectiveness of the proposed robustification strategy.",ai
"Collaborative fraud, where multiple fraudulent accounts coordinate to exploit online payment systems, poses significant challenges due to the formation of complex network structures. Traditional detection methods that rely solely on high-confidence identity links suffer from limited coverage, while approaches using all available linkages often result in fragmented graphs with reduced clustering effectiveness. In this paper, we propose a novel graph-based fraud detection framework that addresses the challenge of large-scale heterogeneous graph clustering through a principled link transformation approach. Our method distinguishes between (high-confidence identity relationships such as phone numbers, credit cards, and national IDs) and (behavioral associations including device fingerprints, cookies, and IP addresses). We introduce a graph transformation technique that first identifies connected components via hard links, merges them into super-nodes, and then reconstructs a weighted soft-link graph amenable to efficient embedding and clustering. The transformed graph is processed using LINE (Large-scale Information Network Embedding) for representation learning, followed by HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) for density-based cluster discovery. Experiments on a real-world payment platform dataset demonstrate that our approach achieves significant graph size reduction (from 25 million to 7.7 million nodes), doubles the detection coverage compared to hard-link-only baselines, and maintains high precision across identified fraud clusters. Our framework provides a scalable and practical solution for industrial-scale fraud detection systems.",human
"Diabetic retinopathy (DR) is a leading cause of preventable blindness worldwide, demanding accurate automated diagnostic systems. While general-domain vision-language models like Contrastive Language-Image Pre-Training (CLIP) perform well on natural image tasks, they struggle in medical domain applications, particularly in cross-modal retrieval for ophthalmological images. We propose a novel knowledge-enhanced joint embedding framework that integrates retinal fundus images, clinical text, and structured patient data through a multimodal transformer architecture to address the critical gap in medical image-text alignment. Our approach employs separate encoders for each modality: a Vision Transformer (ViT-B/16) for retinal images, Bio-ClinicalBERT for clinical narratives, and a multilayer perceptron for structured demographic and clinical features. These modalities are fused through a joint transformer with modality-specific embeddings, trained using multiple objectives including contrastive losses between modality pairs, reconstruction losses for images and text, and classification losses for DR severity grading according to ICDR and SDRG schemes. Experimental results on the Brazilian Multilabel Ophthalmological Dataset (BRSET) demonstrate significant improvements over baseline models. Our framework achieves near-perfect text-to-image retrieval performance with Recall@1 of 99.94% compared to fine-tuned CLIP's 1.29%, while maintaining state-of-the-art classification accuracy of 97.05% for SDRG and 97.97% for ICDR. Furthermore, zero-shot evaluation on the unseen DeepEyeNet dataset validates strong generalizability with 93.95% Recall@1 versus 0.22% for fine-tuned CLIP. These results demonstrate that our multimodal training approach effectively captures cross-modal relationships in the medical domain, establishing both superior retrieval capabilities and robust diagnostic performance.",human
"Foundation models for protein design raise concrete biosecurity risks, yet the community lacks a simple, reproducible baseline for sequence-level hazard screening that is explicitly evaluated under homology control and runs on commodity CPUs. We introduce SafeBench-Seq, a metadata-only, reproducible benchmark and baseline classifier built entirely from public data (SafeProtein hazards and UniProt benigns) and interpretable features (global physicochemical descriptors and amino-acid composition). To approximate ""never-before-seen"" threats, we homology-cluster the combined dataset at <=40% identity and perform cluster-level holdouts (no cluster overlap between train/test). We report discrimination (AUROC/AUPRC) and screening-operating points (TPR@1% FPR; FPR@95% TPR) with 95% bootstrap confidence intervals (n=200), and we provide calibrated probabilities via CalibratedClassifierCV (isotonic for Logistic Regression / Random Forest; Platt sigmoid for Linear SVM). We quantify probability quality using Brier score, Expected Calibration Error (ECE; 15 bins), and reliability diagrams. Shortcut susceptibility is probed via composition-preserving residue shuffles and length-/composition-only ablations. Empirically, random splits substantially overestimate robustness relative to homology-clustered evaluation; calibrated linear models exhibit comparatively good calibration, while tree ensembles retain slightly higher Brier/ECE. SafeBench-Seq is CPU-only, reproducible, and releases metadata only (accessions, cluster IDs, split labels), enabling rigorous evaluation without distributing hazardous sequences.",human
"Automated masking of Personally Identifiable Information (PII) is critical for privacy-preserving conversational systems. While current frontier large language models demonstrate strong PII masking capabilities, concerns about data handling and computational costs motivate exploration of whether lightweight models can achieve comparable performance. We compare encoder-decoder and decoder-only architectures by fine-tuning T5-small and Mistral-Instruct-v0.3 on English datasets constructed from the AI4Privacy benchmark. We create different dataset variants to study label standardization and PII representation, covering 24 standardized PII categories and higher-granularity settings. Evaluation using entity-level and character-level metrics, type accuracy, and exact match shows that both lightweight models achieve performance comparable to frontier LLMs for PII masking tasks. Label normalization consistently improves performance across architectures. Mistral achieves higher F1 and recall with greater robustness across PII types but incurs significantly higher generation latency. T5, while less robust in conversational text, offers more controllable structured outputs and lower inference cost, motivating its use in a real-time Discord bot for real-world PII redaction. Evaluation on live messages reveals performance degradation under informal inputs. These results clarify trade-offs between accuracy, robustness, and computational efficiency, demonstrating that lightweight models can provide effective PII masking while addressing data handling concerns associated with frontier LLMs.",human
"We investigate the challenge of achieving efficient and robust coordination in multi-agent reinforcement learning (MARL) within partially observable environments, focusing on scenarios where explicit communication is infeasible. Existing approaches often struggle with scalability and vulnerability to noisy or adversarial environments. This work introduces a novel decentralized learning paradigm, termed Adaptive Implicit Communication Network (AICN), that leverages recurrent neural networks and attention mechanisms to foster implicit coordination. AICN learns to infer the latent intentions and beliefs of other agents through observation histories, dynamically adjusting its behavior based on perceived environmental dynamics. The attention mechanism allows each agent to focus on the most relevant aspects of other agents' actions and states without direct communication. We empirically evaluate AICN on a series of challenging cooperative navigation and resource allocation tasks, demonstrating significant improvements in coordination efficiency and resilience compared to state-of-the-art MARL algorithms, including those relying on centralized training schemes. Furthermore, ablation studies validate the efficacy of the adaptive attention mechanism in facilitating robust implicit communication, especially in environments with high levels of noise and agent heterogeneity. These results suggest that AICN offers a promising approach for developing scalable and adaptable multi-agent systems in complex, real-world scenarios.",ai
"The rapid diffusion of generative artificial intelligence is transforming terminology work. While this technology promises gains in efficiency, its unstructured adoption risks weakening professional autonomy, amplifying bias, and eroding linguistic and conceptual diversity. This paper argues that a human-centered approach to artificial intelligence has become a necessity for terminology work. Building on research in artificial intelligence and translation studies, it proposes a human-centered framework that conceptualizes artificial intelligence as a means of amplifying the terminologist's capabilities, rather than replacing them. The framework is organized around three interrelated dimensions: the augmented terminologist, ethical AI, and human-centered design. Together, these dimensions emphasize the compatibility of high automation with strong human control, the central role of terminologists in bias mitigation, and the importance of designing AI tools and workflows around the needs, values, and well-being of the terminologist. The paper concludes by stressing that current choices in AI adoption will shape not only terminological practice, but also the preservation of accuracy, adequacy, and diversity in terminology and specialized knowledge.",human
"We present approximation theories and efficient training methods for derivative-informed Fourier neural operators (DIFNOs) with applications to PDE-constrained optimization. A DIFNO is an FNO trained by minimizing its prediction error jointly on output and FrÃ©chet derivative samples of a high-fidelity operator (e.g., a parametric PDE solution operator). As a result, a DIFNO can closely emulate not only the high-fidelity operator's response but also its sensitivities. To motivate the use of DIFNOs instead of conventional FNOs as surrogate models, we show that accurate surrogate-driven PDE-constrained optimization requires accurate surrogate FrÃ©chet derivatives. Then, for continuously differentiable operators, we establish (i) simultaneous universal approximation of FNOs and their FrÃ©chet derivatives on compact sets, and (ii) universal approximation of FNOs in weighted Sobolev spaces with input measures that have unbounded supports. Our theoretical results certify the capability of FNOs for accurate derivative-informed operator learning and accurate solution of PDE-constrained optimization. Furthermore, we develop efficient training schemes using dimension reduction and multi-resolution techniques that significantly reduce memory and computational costs for FrÃ©chet derivative learning. Numerical examples on nonlinear diffusion--reaction, Helmholtz, and Navier--Stokes equations demonstrate that DIFNOs are superior in sample complexity for operator learning and solving infinite-dimensional PDE-constrained inverse problems, achieving high accuracy at low training sample sizes.",human
"Semantic segmentation of outdoor street scenes plays a key role in applications such as autonomous driving, mobile robotics, and assistive technology for visually-impaired pedestrians. For these applications, accurately distinguishing between key surfaces and objects such as roads, sidewalks, vehicles, and pedestrians is essential for maintaining safety and minimizing risks. Semantic segmentation must be robust to different environments, lighting and weather conditions, and sensor noise, while being performed in real-time. We propose a region-level, uncertainty-gated retrieval mechanism that improves segmentation accuracy and calibration under domain shift. Our best method achieves an 11.3% increase in mean intersection-over-union while reducing retrieval cost by 87.5%, retrieving for only 12.5% of regions compared to 100% for always-on baseline.",human
"Context: Exhaustive fuzzing of modern JavaScript engines is infeasible due to the vast number of program states and execution paths. Coverage-guided fuzzers waste effort on low-risk inputs, often ignoring vulnerability-triggering ones that do not increase coverage. Existing heuristics proposed to mitigate this require expert effort, are brittle, and hard to adapt. Objective: We propose a data-centric, LLM-boosted alternative that learns from historical vulnerabilities to automatically identify minimal static (code) and dynamic (runtime) features for detecting high-risk inputs. Method: Guided by historical V8 bugs, iterative prompting generated 115 static and 49 dynamic features, with the latter requiring only five trace flags, minimizing instrumentation cost. After feature selection, 41 features remained to train an XGBoost model to predict high-risk inputs during fuzzing. Results: Combining static and dynamic features yields over 85% precision and under 1% false alarms. Only 25% of these features are needed for comparable performance, showing that most of the search space is irrelevant. Conclusion: This work introduces feature-guided fuzzing, an automated data-driven approach that replaces coverage with data-directed inference, guiding fuzzers toward high-risk states for faster, targeted, and reproducible vulnerability discovery. To support open science, all scripts and data are available at https://github.com/KKGanguly/DataCentricFuzzJS .",human
"We address the problem of automating compositional reasoning in complex, multi-step inference tasks, specifically focusing on scenarios where the relevant knowledge is distributed across multiple, heterogeneous sources. Traditional automated reasoning approaches often struggle with such scenarios due to the computational complexity of integrating and reasoning over diverse knowledge representations. We introduce a novel method, Neuro-Symbolic Reasoning with Dynamic Knowledge Retrieval (NSR-DKR), which combines the strengths of neural networks for knowledge retrieval and symbolic reasoners for logical inference. NSR-DKR employs a neural network to dynamically retrieve relevant facts from a collection of knowledge bases, conditioned on the current state of the reasoning process. These retrieved facts are then translated into logical axioms and fed into a pre-trained symbolic reasoner. The reasoner derives new conclusions, which are used to update the reasoning state and guide subsequent knowledge retrieval steps. We evaluate NSR-DKR on a benchmark dataset of multi-hop logical reasoning problems involving scientific knowledge. Our results demonstrate that NSR-DKR significantly outperforms existing end-to-end neural reasoning methods and traditional symbolic reasoners, achieving a 25% relative improvement in accuracy. Ablation studies confirm the importance of both dynamic knowledge retrieval and the synergistic integration of neural and symbolic components.",ai
"AI revolutionizes transportation through autonomous vehicles (AVs) but introduces complex criminal liability issues regarding infractions. This study employs a comparative legal analysis of primary statutes, real-world liability claims, and academic literature across the US, Germany, UK, China, and India; jurisdictions selected for their technological advancement and contrasting regulatory approaches. The research examines the attribution of human error, AI moral agency, and the identification of primary offenders in AV incidents. Findings reveal fragmented regulatory landscapes: India and the US rely on loose networks of state laws, whereas the UK enacted the pioneering Automated and Electric Vehicles Act 2018. Germany enforces strict safety standards, distinguishing liability based on the vehicle's operating mode, while China similarly aims for a stringent liability regime. The study concludes that globally harmonized legal standards are essential to foster technological innovation while ensuring minimum risk and clear liability attribution.",human
"We address the challenge of efficiently solving quantified constraint satisfaction problems (QCSPs) with complex dependency structures. While modern QCSP solvers employing counterexample-guided abstraction refinement (CEGAR) can handle significant problem instances, performance degrades substantially when variables exhibit intricate interdependencies, leading to an exponential explosion in the size of the abstraction space. To mitigate this issue, we introduce a novel decompositional reasoning framework that leverages structure learning to identify and exploit variable dependencies within the QCSP. Our method dynamically decomposes the problem into smaller, more manageable sub-problems based on a learned dependency graph, solving these sub-problems independently before integrating their solutions through a global consistency check. The key innovation lies in a hybrid approach combining constraint propagation within sub-problems with a CEGAR-based strategy for coordinating solutions across the decomposition. Empirical evaluation on a range of benchmark QCSP instances demonstrates that our approach significantly outperforms state-of-the-art CEGAR solvers, reducing solving time by an average of 45% and expanding the class of solvable QCSPs. Furthermore, analysis reveals that the learned dependency graphs accurately reflect the underlying problem structure, enabling more focused and efficient reasoning.",ai
"With the recent surge in personalized learning, Intelligent Tutoring Systems (ITS) that can accurately track students' individual knowledge states and provide tailored learning paths based on this information are in demand as an essential task. This paper focuses on the core technology of Knowledge Tracing (KT) models that analyze students' sequences of interactions to predict their knowledge acquisition levels. However, existing KT models suffer from limitations such as restricted input data formats, cold start problems arising with new student enrollment or new question addition, and insufficient stability in real-world service environments. To overcome these limitations, a Practical Interlinked Concept Knowledge Tracing (PICKT) model that can effectively process multiple types of input data is proposed. Specifically, a knowledge map structures the relationships among concepts considering the question and concept text information, thereby enabling effective knowledge tracing even in cold start situations. Experiments reflecting real operational environments demonstrated the model's excellent performance and practicality. The main contributions of this research are as follows. First, a model architecture that effectively utilizes diverse data formats is presented. Second, significant performance improvements are achieved over existing models for two core cold start challenges: new student enrollment and new question addition. Third, the model's stability and practicality are validated through delicate experimental design, enhancing its applicability in real-world product environments. This provides a crucial theoretical and technical foundation for the practical implementation of next-generation ITS.",human
"We present an operator learning framework for solving non-perturbative functional renormalization group equations, which are integro-differential equations defined on functionals. Our proposed approach uses Gaussian process operator learning to construct a flexible functional representation formulated directly on function space, making it independent of a particular equation or discretization. Our method is flexible, and can apply to a broad range of functional differential equations while still allowing for the incorporation of physical priors in either the prior mean or the kernel design. We demonstrate the performance of our method on several relevant equations, such as the Wetterich and Wilson--Polchinski equations, showing that it achieves equal or better performance than existing approximations such as the local-potential approximation, while being significantly more flexible. In particular, our method can handle non-constant fields, making it promising for the study of more complex field configurations, such as instantons.",human
"### Abstract This paper addresses the problem of decentralized task allocation in dynamic multi-agent systems operating under communication constraints and partial observability. Current approaches often struggle to maintain optimal performance when agents experience intermittent connectivity or limited knowledge of the global state, leading to suboptimal task assignments and reduced system efficiency. We propose a novel method, the Communication-Aware Dynamic Task Allocation (CADTA) algorithm, which integrates a Bayesian belief update mechanism with a decentralized auction-based allocation framework. Agents maintain probabilistic estimates of other agents' capabilities and task demands, refining these beliefs based on received communication and local observations. The auction process incorporates a communication cost function that penalizes bids requiring extensive information exchange, thus promoting local decision-making and reducing communication overhead. We evaluate CADTA in a simulated environment involving heterogeneous agents performing a range of interdependent tasks with stochastic arrival rates. Experimental results demonstrate that CADTA significantly outperforms existing decentralized allocation algorithms, achieving a 20-30% improvement in overall task completion rate and a 15-20% reduction in communication volume, particularly in scenarios with high agent density and fluctuating communication bandwidth. These findings suggest that CADTA offers a robust and scalable solution for task allocation in complex, resource-constrained multi-agent systems.",ai
"Aspect-Category Sentiment Analysis (ACSA) provides granular insights by identifying specific themes within reviews and their associated sentiment. While supervised learning approaches dominate this field, the scarcity and high cost of annotated data for new domains present significant barriers. We argue that leveraging large language models (LLMs) in a zero-shot setting is a practical alternative where resources for data annotation are limited. In this work, we propose a novel Chain-of-Thought (CoT) prompting technique that utilises an intermediate Unified Meaning Representation (UMR) to structure the reasoning process for the ACSA task. We evaluate this UMR-based approach against a standard CoT baseline across three models (Qwen3-4B, Qwen3-8B, and Gemini-2.5-Pro) and four diverse datasets. Our findings suggest that UMR effectiveness may be model-dependent. Whilst preliminary results indicate comparable performance for mid-sized models such as Qwen3-8B, these observations warrant further investigation, particularly regarding the potential applicability to smaller model architectures. Further research is required to establish the generalisability of these findings across different model scales.",human
"We address the problem of preserving data privacy while training high-performing machine learning models on sensitive datasets, specifically focusing on natural language processing tasks. Existing privacy-preserving methods often introduce significant performance degradation, particularly in resource-constrained settings. To mitigate this, we propose a novel approach, Differentially Private Parameter Averaging with Gradient Clipping (DP-PAGC), which combines federated learning principles with rigorous differential privacy guarantees. DP-PAGC minimizes communication overhead by averaging model parameters instead of gradients, while gradient clipping bounds the sensitivity of each parameter update, thus reducing the required noise addition for privacy. We theoretically analyze the privacy guarantees provided by DP-PAGC and empirically evaluate its performance on sentiment classification and text summarization tasks using benchmark datasets. Our experimental results demonstrate that DP-PAGC achieves a significant improvement in model accuracy compared to state-of-the-art differentially private optimization techniques, particularly when dealing with non-IID data distributions and limited computational resources. Specifically, DP-PAGC improves accuracy by up to 15% on sentiment classification and reduces perplexity by up to 8% on text summarization, while maintaining strong differential privacy guarantees (Îµ=10, Î´=10âˆ’5).",ai
"Purpose: Intraoperative navigation in spine surgery demands millimeter-level accuracy. Current systems based on intraoperative radiographic imaging and bone-anchored markers are invasive, radiation-intensive and workflow disruptive. Recent markerless RGB-D registration methods offer a promising alternative, but existing approaches rely on weak segmentation labels to isolate relevant anatomical structures, which can propagate errors throughout registration. Methods: We present End2Reg an end-to-end deep learning framework that jointly optimizes segmentation and registration, eliminating the need for weak segmentation labels and manual steps. The network learns segmentation masks specifically optimized for registration, guided solely by the registration objective without direct segmentation supervision. Results: The proposed framework achieves state-of-the-art performance on ex- and in-vivo benchmarks, reducing median Target Registration Error by 32% to 1.83mm and mean Root Mean Square Error by 45% to 3.95mm, respectively. An ablation study confirms that end-to-end optimization significantly improves registration accuracy. Conclusion: The presented end-to-end RGB-D registration pipeline removes dependency on weak labels and manual steps, advancing towards fully automatic, markerless intraoperative navigation. Code and interactive visualizations are available at: https://lorenzopettinari.github.io/end-2-reg/.",human
"Real-world software engineering tasks require coding agents that can operate over massive repositories, sustain long-horizon sessions, and reliably coordinate complex toolchains at test time. Existing research-grade coding agents offer transparency but struggle when scaled to heavier, production-level workloads, while production-grade systems achieve strong practical performance but provide limited extensibility, interpretability, and controllability. We introduce the Confucius Code Agent (CCA), a software engineering agent that can operate at large-scale codebases. CCA is built on top of the Confucius SDK, an agent development platform structured around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK integrates a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension system for reliable tool use. In addition, we introduce a meta-agent that automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid adaptation to new tasks, environments, and tool stacks. Instantiated with these mechanisms, CCA demonstrates strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA reaches a Resolve@1 of 54.3%, exceeding prior research baselines and comparing favorably to commercial results, under identical repositories, model backends, and tool access.",human
"A data product is created with the intention of solving a specific problem, addressing a specific business usecase or meeting a particular need, going beyond just serving data as a raw asset. Data products enable end users to gain greater insights about their data. Since it was first introduced over a decade ago, there has been considerable work, especially in industry, to create data products manually or semi-automatically. However, there exists hardly any benchmark to evaluate automatic data product creation. In this work, we present a benchmark, first of its kind, for this task. We call it DP-Bench. We describe how this benchmark was created by taking advantage of existing work in ELT (Extract-Load-Transform) and Text-to-SQL benchmarks. We also propose a number of LLM based approaches that can be considered as baselines for generating data products automatically. We make the DP-Bench and supplementary materials available in https://huggingface.co/datasets/ibm-research/dp-bench .",human
"The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.",human
"We address the challenge of constructing robust and transferable knowledge representations from multi-modal data, specifically focusing on scenarios with limited supervision. Traditional methods often struggle with heterogeneous data distributions and the inherent semantic gap between modalities, resulting in representations that are either overfit to the training data or lack sufficient discriminative power. To mitigate these issues, we propose a novel framework leveraging contrastive learning and hierarchical clustering within a shared embedding space. Our method, termed Contrastive Hierarchical Knowledge Representation (CHKR), learns to align representations from different modalities by maximizing agreement between semantically similar instances while simultaneously enforcing dissimilarity between dissimilar ones. Subsequently, hierarchical clustering is applied within the learned embedding space to discover latent semantic structures and generate a hierarchical knowledge graph. We evaluate CHKR on benchmark multi-modal datasets for image-text retrieval and zero-shot classification. Empirical results demonstrate that CHKR significantly outperforms existing state-of-the-art methods in terms of retrieval accuracy and classification performance. Furthermore, we show that the learned knowledge graph provides valuable insights into the underlying relationships between modalities, facilitating improved interpretability and transferability of the learned representations. Our findings suggest that CHKR offers a promising approach for learning generalizable knowledge representations from limited labeled multi-modal data.",ai
"We address the challenge of accurate and efficient lesion detection in medical imaging, specifically focusing on pulmonary nodule detection in computed tomography (CT) scans. Manual analysis of these scans is time-consuming and susceptible to inter-observer variability, leading to potential diagnostic delays and inaccuracies. To mitigate these limitations, we propose a novel multi-scale convolutional neural network (CNN) architecture incorporating attention mechanisms. The network utilizes a hierarchical feature extraction strategy, employing parallel convolutional streams with varying receptive fields to capture nodules of differing sizes and densities. Attention modules are integrated to selectively enhance relevant features and suppress background noise, thereby improving the network's sensitivity to subtle nodule characteristics. We evaluate our approach on the Lung Image Database Consortium image collection (LIDC-IDRI), a publicly available dataset of thoracic CT scans. Experimental results demonstrate that our model achieves a significantly improved performance in terms of sensitivity and positive predictive value compared to several state-of-the-art detection algorithms. Specifically, we observe a 15% reduction in false positive rate at a clinically relevant sensitivity level. These findings suggest that the proposed methodology holds substantial promise for assisting radiologists in the early and accurate diagnosis of lung cancer.",ai
"This article shows how fair voting methods can be a catalyst for change in the way we make collective decisions, and how such change can promote long-awaited upgrades of democracy. Based on real-world evidence from democratic innovations in participatory budgeting, in Switzerland and beyond, I highlight a trilogy of key research results: Fair voting methods achieve to be (i) legitimacy incubator, (ii) novel impact accelerator and (iii) safeguard for risks of artificial intelligence (AI). Compared to majoritarian voting methods, combining expressive ballot formats (e.g. cumulative voting) with ballot aggregation methods that promote proportional representation (e.g. equal shares) results in more winners and higher (geographical) representation of citizens. Such fair voting methods are preferred and found fairer even by voters who do not win, while promoting stronger democratic values for citizens such as altruism and compromise. They also result in new resourceful ideas to put for voting, which are cost-effective and win, especially in areas of welfare, education and culture. Strikingly, fair voting methods are also more resilient to biases and inconsistencies of generative AI in emerging scenarios of AI voting assistance or AI representation of voters who would be likely to abstain. I also review the relevance of such upgrades for democracies in crisis, such as the one of Greece featured in the recent study of `Unmute Democracy'. Greek democracy can build stronger resilience via higher representation of citizens in democratic processes as well as democratic innovations in participation. Fair voting methods can be a catalyst for both endeavors.",human
"We address the problem of efficiently constructing and traversing proof graphs for complex logical entailment problems, particularly those arising in formal verification and program synthesis. Traditional automated theorem provers often suffer from combinatorial explosion when faced with large axiom sets and deeply nested logical structures. Our proposed method, termed Guided Axiom Selection for Proof Graph Reduction (GASPR), leverages a graph neural network (GNN) to predict the relevance of individual axioms to the target entailment. The GNN is trained on a corpus of successful proofs, learning to identify latent relationships between axioms and goal statements based on their logical form and contextual usage within prior proofs. During proof search, GASPR dynamically prunes the search space by prioritizing axioms with higher relevance scores, effectively reducing the branching factor and preventing the exploration of unproductive proof branches. We evaluate GASPR on a benchmark of challenging first-order logic problems derived from software verification tasks. Our results demonstrate a significant improvement in proof completion rate compared to baseline systems employing standard breadth-first and depth-first search strategies. Specifically, GASPR achieves a 25% increase in successfully proven theorems within a fixed time limit, while simultaneously reducing the average proof search time by 40%. These findings suggest that GNN-guided axiom selection can substantially enhance the efficiency and scalability of automated reasoning systems.",ai
"We address the problem of compositional generalization in logical reasoning, specifically focusing on scenarios where knowledge is represented in a first-order logic (FOL) setting. Existing neural-symbolic approaches often struggle to effectively generalize to novel combinations of known concepts and relations. This limitation stems from difficulties in learning robust representations for FOL predicates and their interactions within complex logical formulas. We propose a novel differentiable reasoning framework, termed Neural Logic Inducer (NLI), that explicitly learns to induce logical structures from data and subsequently reason over them. NLI utilizes a neural module to map input facts and rules into continuous embeddings, which are then processed by a differentiable forward chaining algorithm. This algorithm iteratively applies inference rules to derive new facts, facilitating complex reasoning chains. Crucially, NLI incorporates a regularization term that encourages the learned predicate embeddings to align with their semantic roles within the logical rules, promoting compositional generalization. Experiments on benchmark datasets for logical reasoning demonstrate that NLI significantly outperforms existing neural-symbolic approaches, particularly in scenarios requiring multi-hop reasoning and generalization to unseen compositions of logical rules. We observe a relative improvement of up to 15% in accuracy on tasks involving novel combinations of predicates and relations, suggesting that NLI effectively captures the compositional structure of logical knowledge and enables more robust and generalizable reasoning. The results highlight the potential of differentiable reasoning frameworks for addressing the limitations of existing symbolic and neural approaches to automated reasoning.",ai
"We address the challenge of efficient exploration in reinforcement learning for environments with sparse and delayed rewards. Standard exploration techniques, such as Îµ-greedy and Boltzmann exploration, often prove inadequate in such settings, leading to slow learning rates and suboptimal policy convergence. To mitigate this, we propose a novel exploration strategy, termed ""Intrinsic Curiosity-driven Policy Shaping"" (ICPS), which integrates an intrinsic reward signal based on prediction error with policy shaping using potential-based rewards. ICPS employs a neural network to predict the next state given the current state and action, and uses the prediction error as a measure of novelty. This intrinsic reward is then combined with the environment's extrinsic reward to guide exploration towards unexplored regions of the state space. Furthermore, we leverage potential-based shaping to provide smooth, temporally consistent reward signals that facilitate faster learning. We evaluate ICPS on a suite of benchmark environments with sparse reward structures, including the Montezuma's Revenge game from the Atari Learning Environment. Experimental results demonstrate that ICPS significantly outperforms state-of-the-art exploration methods, achieving faster convergence and higher asymptotic performance. Specifically, ICPS achieves a 3x improvement in sample efficiency compared to existing curiosity-driven exploration approaches and demonstrates a more robust exploration strategy across diverse environmental conditions. These findings suggest that ICPS offers a promising avenue for addressing the exploration problem in challenging reinforcement learning scenarios.",ai
"We address the problem of enhancing automated reasoning capabilities in complex deductive tasks involving multi-hop inference and implicit knowledge. Current automated theorem provers often struggle with problems requiring the synthesis of information across multiple premises or necessitating the application of background knowledge not explicitly stated in the problem formulation. We propose a novel approach that integrates a pre-trained language model (PLM) to generate intermediate lemmas and guide the search process of a first-order logic theorem prover. Specifically, the PLM is fine-tuned on a dataset of formal proofs to predict relevant intermediate statements given a set of initial axioms and the desired goal. These generated lemmas are then incorporated as additional axioms within the theorem prover's knowledge base, effectively expanding its deductive search space. We evaluate our approach on challenging benchmark datasets requiring multi-hop reasoning, demonstrating a significant improvement in proof success rate compared to state-of-the-art automated theorem provers without PLM-guided lemma generation. Ablation studies reveal the critical role of the fine-tuning process in aligning the PLM's lemma generation with the specific requirements of the deductive task. These results suggest that the integration of language models can substantially enhance the performance of automated reasoners in scenarios demanding complex inferential steps and implicit knowledge application.",ai
"We address the problem of robust causal effect estimation in observational studies when confronted with unmeasured confounding and selection bias. Traditional methods often rely on strong assumptions about the absence of such biases, which are frequently violated in real-world settings. We propose a novel approach leveraging a combination of variational inference and instrumental variable (IV) techniques to simultaneously infer latent confounders and estimate causal effects. Specifically, we introduce a variational autoencoder (VAE) architecture tailored for causal inference, where the encoder learns a latent representation capturing unobserved confounders, while the decoder reconstructs observed covariates and the treatment variable. Crucially, we incorporate an instrumental variable within the VAE framework to identify and disentangle the causal effect from spurious correlations induced by the latent confounders. We derive an identifiable objective function based on the observed data and the IV, ensuring the consistency of our estimates. Empirical evaluations on synthetic and semi-synthetic datasets, emulating realistic confounding scenarios, demonstrate that our method significantly outperforms existing baseline approaches, including traditional IV regression and propensity score matching, in terms of bias reduction and mean squared error of the estimated causal effect. The proposed method provides a more robust and reliable approach to causal inference in the presence of complex unobserved confounding and selection bias.",ai
"We investigate the problem of coordinating heterogeneous agents with diverse capabilities and potentially conflicting goals in complex, dynamic environments. Existing multi-agent reinforcement learning (MARL) approaches often struggle with scalability due to the exponential growth of the joint action space and instability arising from non-stationarity. We propose a novel hierarchical learning framework, Cooperative Task Assignment and Skill Execution (CTASE), which decomposes the coordination problem into two levels: a high-level task assignment module and a low-level skill execution module. The task assignment module, implemented via a graph neural network (GNN), learns to allocate tasks to agents based on their individual capabilities and the current environmental state. The skill execution module consists of a set of pre-trained or concurrently trained skill policies, each specialized for a specific task. Agents execute assigned tasks using these skill policies, reducing the dimensionality of the action space and promoting specialization. We evaluate CTASE on a challenging simulated warehouse environment requiring efficient coordination of agents with varying movement speeds and loading capacities. Results demonstrate that CTASE significantly outperforms state-of-the-art MARL algorithms, achieving higher task completion rates and improved overall efficiency. Furthermore, the hierarchical structure of CTASE promotes greater robustness to dynamic changes in the environment and agent populations compared to monolithic approaches. The learned task assignment policies also exhibit interpretability, offering insights into effective coordination strategies.",ai
"We address the challenge of enabling automated reasoning over complex, structured data, specifically focusing on scenarios where traditional rule-based systems struggle due to uncertainty and incompleteness. Our investigation centers on a novel framework that integrates probabilistic logic programming with neural network-based knowledge acquisition. The proposed method, termed Neural Probabilistic Reasoning Network (NPRN), learns to extract relevant facts and relationships from raw data using a deep neural network architecture, subsequently representing these extracted features as probabilistic facts within a probabilistic logic program. Inference is then performed using a modified version of Markov Logic Networks (MLNs), allowing for the derivation of new, potentially uncertain, conclusions. We evaluate NPRN on a benchmark knowledge graph completion task and a simulated medical diagnosis dataset. Results demonstrate a significant improvement in inference accuracy compared to both standard MLNs using hand-engineered features and end-to-end neural network approaches for reasoning. Specifically, NPRN achieves a 15% increase in mean reciprocal rank (MRR) on the knowledge graph completion task and a 12% increase in diagnostic accuracy on the medical diagnosis dataset, highlighting its efficacy in handling uncertainty and learning representations suitable for automated reasoning.",ai
"We address the problem of representing and reasoning with complex, relational knowledge in open-domain question answering. Existing knowledge representation formalisms often struggle with the trade-off between expressive power and computational efficiency, particularly when dealing with noisy and incomplete knowledge graphs extracted from text. We propose a novel hybrid knowledge representation framework, KR-HARMONY, that integrates distributional embeddings with symbolic logic. KR-HARMONY leverages pre-trained language models to encode relational semantics into continuous vector spaces, enabling efficient similarity-based reasoning for identifying relevant facts. Simultaneously, we employ a rule-based system to encode structured relationships and constraints, allowing for precise logical inference and validation of retrieved information. The two components are harmonized through a differentiable knowledge fusion layer that dynamically weights their contributions based on the input query and the context of the retrieved facts. We evaluate KR-HARMONY on several benchmark question answering datasets requiring multi-hop reasoning and demonstrate a significant improvement over state-of-the-art baselines. Specifically, KR-HARMONY achieves a 15% relative increase in accuracy on questions requiring both factual recall and logical deduction, showcasing the effectiveness of our hybrid approach in bridging the gap between distributional and symbolic knowledge representation.",ai
"We address the challenge of coordinating communication strategies in decentralized multi-agent systems operating in dynamic and partially observable environments. Existing approaches often struggle with the inherent complexities of learning cooperative communication protocols in the absence of centralized control and global information. We propose a novel multi-agent deep reinforcement learning framework incorporating a differentiable communication module enhanced with a hierarchical attention mechanism. This allows agents to selectively attend to relevant information from their neighbors' messages while learning to encode contextually meaningful communication content. Furthermore, a decentralized critic network operating on individual agent observations coupled with aggregated communication signals provides improved credit assignment, enabling more effective learning of cooperative strategies. We evaluate our method on a benchmark cooperative navigation task and a novel collaborative target assignment scenario. Results demonstrate significant improvements in task completion rate, communication efficiency, and robustness to environmental noise compared to existing state-of-the-art communication learning approaches. Specifically, our method exhibits superior adaptability to varying agent densities and communication bandwidth limitations, indicating its potential for deployment in realistic, resource-constrained multi-agent settings.",ai
"Extracting coherent and human-understandable themes from large collections of unstructured historical newspaper archives presents significant challenges due to topic evolution, Optical Character Recognition (OCR) noise, and the sheer volume of text. Traditional topic-modeling methods, such as Latent Dirichlet Allocation (LDA), often fall short in capturing the complexity and dynamic nature of discourse in historical texts. To address these limitations, we employ BERTopic. This neural topic-modeling approach leverages transformerbased embeddings to extract and classify topics, which, despite its growing popularity, still remains underused in historical research. Our study focuses on articles published between 1955 and 2018, specifically examining discourse on nuclear power and nuclear safety. We analyze various topic distributions across the corpus and trace their temporal evolution to uncover long-term trends and shifts in public discourse. This enables us to more accurately explore patterns in public discourse, including the co-occurrence of themes related to nuclear power and nuclear weapons and their shifts in topic importance over time. Our study demonstrates the scalability and contextual sensitivity of BERTopic as an alternative to traditional approaches, offering richer insights into historical discourses extracted from newspaper archives. These findings contribute to historical, nuclear, and social-science research while reflecting on current limitations and proposing potential directions for future work.",human
"Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content. Large Language Models (LLMs) have been used to automate this process, acting as judges to evaluate summaries with respect to the original text. While previous research investigated the alignment between LLMs and Human responses, it is not yet well understood what properties or features are exploited by them when asked to evaluate based on a particular quality dimension, and there has not been much attention towards mapping between evaluation scores and metrics. In this paper, we address this issue and discover features aligned with Human and Generative Pre-trained Transformers (GPTs) responses by studying statistical and machine learning metrics. Furthermore, we show that instructing GPTs to employ metrics used by Human can improve their judgment and conforming them better with human responses.",human
"Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .",human
"Vision-language models (VLMs) are commonly trained by inserting image tokens from a pretrained vision encoder into the textual stream of a language model. This allows text and image information to fully attend to one another within the model, but becomes extremely costly for high-resolution images, long conversations, or streaming videos, both in memory and compute. VLMs leveraging cross-attention are an efficient alternative to token insertion but exhibit a clear performance gap, in particular on tasks involving fine-grained visual details. We find that a key to improving such models is to also enable local text-to-text interaction in the dedicated cross-attention layers. Building on this, we propose CASA, Cross-Attention via Self-Attention, a simple and efficient paradigm which substantially reduces the gap with full token insertion on common image understanding benchmarks, while enjoying the same scalability as cross-attention models when applied to long-context multimodal tasks such as streaming video captioning. For samples and code, please see our project page at https://kyutai.org/casa .",human
"Bridging the gap between natural language commands and autonomous execution in unstructured environments remains an open challenge for robotics. This requires robots to perceive and reason over the current task scene through multiple modalities, and to plan their behaviors to achieve their intended goals. Traditional robotic task-planning approaches often struggle to bridge low-level execution with high-level task reasoning, and cannot dynamically update task strategies when instructions change during execution, which ultimately limits their versatility and adaptability to new tasks. In this work, we propose a novel language model-based framework for dynamic robot task planning. Our Vision-Language-Policy (VLP) model, based on a vision-language model fine-tuned on real-world data, can interpret semantic instructions and integrate reasoning over the current task scene to generate behavior policies that control the robot to accomplish the task. Moreover, it can dynamically adjust the task strategy in response to changes in the task, enabling flexible adaptation to evolving task requirements. Experiments conducted with different robots and a variety of real-world tasks show that the trained model can efficiently adapt to novel scenarios and dynamically update its policy, demonstrating strong planning autonomy and cross-embodiment generalization. Videos: https://robovlp.github.io/",human
"Microreactors, particularly heat-pipe microreactors (HPMRs), are compact, transportable, self-regulated power systems well-suited for access-challenged remote areas where costly fossil fuels dominate. However, they suffer from diseconomies of scale, and their financial viability remains unconvincing. One step in addressing this shortcoming is to design these reactors with comprehensive economic and physics analyses informing early-stage design iteration. In this work, we present a novel unifying geometric design optimization approach that accounts for techno-economic considerations. We start by generating random samples to train surrogate models, including Gaussian processes (GPs) and multi-layer perceptrons (MLPs). We then deploy these surrogates within a reinforcement learning (RL)-based optimization framework to optimize the levelized cost of electricity (LCOE), all the while imposing constraints on the fuel lifetime, shutdown margin (SDM), peak heat flux, and rod-integrated peaking factor. We study two cases: one in which the axial reflector cost is very high, and one in which it is inexpensive. We found that the operation and maintenance and capital costs are the primary contributors to the overall LCOE particularly the cost of the axial reflectors (for the first case) and the control drum materials. The optimizer cleverly changes the design parameters so as to minimize one of them while still satisfying the constraints, ultimately reducing the LCOE by more than 57% in both instances. A comprehensive integration of fuel and HP performance with multi-objective optimization is currently being pursued to fully understand the interaction between constraints and cost performance.",human
"Parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), enable fast specialization of large pre-trained models to different downstream applications. However, this process often leads to catastrophic forgetting of the model's prior domain knowledge. We address this issue with LaLoRA, a weight-space regularization technique that applies a Laplace approximation to Low-Rank Adaptation. Our approach estimates the model's confidence in each parameter and constrains updates in high-curvature directions, preserving prior knowledge while enabling efficient target-domain learning. By applying the Laplace approximation only to the LoRA weights, the method remains lightweight. We evaluate LaLoRA by fine-tuning a Llama model for mathematical reasoning and demonstrate an improved learning-forgetting trade-off, which can be directly controlled via the method's regularization strength. We further explore different loss landscape curvature approximations for estimating parameter confidence, analyze the effect of the data used for the Laplace approximation, and study robustness across hyperparameters.",human
"We address the exploration-exploitation dilemma in reinforcement learning, focusing on continuous control tasks with sparse rewards. Traditional exploration strategies often struggle in environments where rewards are infrequent and delayed, leading to inefficient learning. To mitigate this, we introduce a novel approach, ""Curiosity-Driven Hierarchical Reinforcement Learning"" (CDHRL). This method decomposes the problem into a hierarchical structure, with a higher-level manager responsible for setting long-term exploration goals and lower-level workers trained to achieve these goals. The manager utilizes an intrinsic reward signal based on prediction error, guiding exploration towards regions of the state space where the agent is least familiar. Furthermore, we incorporate a learned dynamics model to facilitate planning and subgoal discovery at the manager level. We evaluate CDHRL on a suite of challenging continuous control benchmarks featuring sparse rewards and deceptive local optima. Experimental results demonstrate that CDHRL significantly outperforms state-of-the-art exploration methods, achieving higher success rates and faster learning convergence. Specifically, we observe a 30% increase in success rate on the ""FetchReach-Sparse"" environment compared to baseline algorithms. The hierarchical structure and curiosity-driven exploration prove to be crucial for navigating complex, sparse reward environments and discovering effective policies.",ai
"Real-world data sets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. This paper introduces Online Classification with Weighted Average (OLC-WA), an adaptive, hyperparameter-free online classification model equipped with an automated optimization mechanism. OLC-WA operates by blending incoming data streams with an existing base model. This blending is facilitated by an exponentially weighted moving average. Furthermore, an integrated optimization mechanism dynamically detects concept drift, quantifies its magnitude, and adjusts the model based on the observed data stream characteristics. This approach empowers the model to effectively adapt to evolving data distributions within streaming environments. Rigorous empirical evaluation across diverse benchmark datasets shows that OLC-WA achieves performance comparable to batch models in stationary environments, maintaining accuracy within 1-3%, and surpasses leading online baselines by 10-25% under drift, demonstrating its effectiveness in adapting to dynamic data streams.",human
"Non-random missing data is a ubiquitous yet undertreated flaw in multidimensional time series, fundamentally threatening the reliability of data-driven analysis and decision-making. Pure low-rank tensor completion, as a classical data recovery method, falls short in handling non-random missingness, both methodologically and theoretically. Hankel-structured tensor completion models provide a feasible approach for recovering multidimensional time series with non-random missing patterns. However, most Hankel-based multidimensional data recovery methods both suffer from unclear sources of Hankel tensor low-rankness and lack an exact recovery theory for non-random missing data. To address these issues, we propose the temporal isometric delay-embedding transform, which constructs a Hankel tensor whose low-rankness is naturally induced by the smoothness and periodicity of the underlying time series. Leveraging this property, we develop the (LRTC-TIDT) model, which characterizes the low-rank structure under the (t-SVD) framework. Once the prescribed non-random sampling conditions and mild incoherence assumptions are satisfied, the proposed LRTC-TIDT model achieves exact recovery, as confirmed by simulation experiments under various non-random missing patterns. Furthermore, LRTC-TIDT consistently outperforms existing tensor-based methods across multiple real-world tasks, including network flow reconstruction, urban traffic estimation, and temperature field prediction. Our implementation is publicly available at https://github.com/HaoShu2000/LRTC-TIDT.",human
"We address the problem of training machine learning models on sensitive data while minimizing privacy risks. Conventional model training necessitates direct access to the training dataset, posing significant vulnerabilities to data breaches and privacy violations. Our approach, Privacy-Preserving Federated Distillation (PPFD), leverages federated learning in conjunction with differential privacy and knowledge distillation to mitigate these risks. In PPFD, a server orchestrates the training of multiple local models on distributed, sensitive datasets using federated averaging. Gaussian noise is strategically injected into the gradients shared during the federated averaging process to enforce differential privacy guarantees. Subsequently, a public, non-sensitive dataset is utilized to train a student model via knowledge distillation, guided by the outputs of the differentially private teacher models aggregated from the federated clients. Empirical evaluations on benchmark datasets demonstrate that PPFD achieves a compelling trade-off between model accuracy and privacy protection. Specifically, PPFD exhibits comparable performance to centrally trained models with a privacy budget (Îµ) of 5, while significantly outperforming alternative federated learning baselines with similar privacy constraints. These results highlight the efficacy of PPFD as a robust and practical solution for privacy-preserving machine learning.",ai
"We investigate the challenge of cooperative task completion in multi-agent systems operating in partially observable environments with limited communication bandwidth. Traditional approaches often rely on centralized training or extensive message passing, both of which become computationally prohibitive or infeasible as the number of agents and the complexity of the environment increase. To address this, we propose a novel decentralized learning framework, Cooperative Attention-Based Action Selection (CAAS), that leverages attention mechanisms to facilitate implicit coordination. Each agent learns to attend to relevant observations and actions of its neighbors, allowing it to infer their intentions and anticipate their future behavior without explicit communication. CAAS integrates a differentiable communication bottleneck to regulate the information flow between agents, thereby enhancing scalability and robustness to noisy or unreliable communication channels. We evaluate CAAS on a suite of challenging cooperative navigation and resource allocation tasks. Experimental results demonstrate that CAAS significantly outperforms state-of-the-art decentralized reinforcement learning algorithms, achieving higher success rates and improved efficiency in task completion. Furthermore, we analyze the learned attention weights to provide insights into the emergent communication strategies adopted by the agents, revealing that CAAS effectively promotes specialization and division of labor within the team.",ai
"In this work, we introduce PhononBench, the first large-scale benchmark for dynamical stability in AI-generated crystals. Leveraging the recently developed MatterSim interatomic potential, which achieves DFT-level accuracy in phonon predictions across more than 10,000 materials, PhononBench enables efficient large-scale phonon calculations and dynamical-stability analysis for 108,843 crystal structures generated by six leading crystal generation models. PhononBench reveals a widespread limitation of current generative models in ensuring dynamical stability: the average dynamical-stability rate across all generated structures is only 25.83%, with the top-performing model, MatterGen, reaching just 41.0%. Further case studies show that in property-targeted generation-illustrated here by band-gap conditioning with MatterGen--the dynamical-stability rate remains as low as 23.5% even at the optimal band-gap condition of 0.5 eV. In space-group-controlled generation, higher-symmetry crystals exhibit better stability (e.g., cubic systems achieve rates up to 49.2%), yet the average stability across all controlled generations is still only 34.4%. An important additional outcome of this study is the identification of 28,119 crystal structures that are phonon-stable across the entire Brillouin zone, providing a substantial pool of reliable candidates for future materials exploration. By establishing the first large-scale dynamical-stability benchmark, this work systematically highlights the current limitations of crystal generation models and offers essential evaluation criteria and guidance for their future development toward the design and discovery of physically viable materials. All model-generated crystal structures, phonon calculation results, and the high-throughput evaluation workflows developed in PhononBench will be openly released at https://github.com/xqh19970407/PhononBench",human
"Large language models are exposed to risks of extraction, distillation, and unauthorized fine-tuning. Existing defenses use watermarking or monitoring, but these act after leakage. We design AlignDP, a hybrid privacy lock that blocks knowledge transfer at the data interface. The key idea is to separate rare and non-rare fields. Rare fields are shielded by PAC indistinguishability, giving effective zero-epsilon local DP. Non-rare fields are privatized with RAPPOR, giving unbiased frequency estimates under local DP. A global aggregator enforces composition and budget. This two-tier design hides rare events and adds controlled noise to frequent events. We prove limits of PAC extension to global aggregation, give bounds for RAPPOR estimates, and analyze utility trade-off. A toy simulation confirms feasibility: rare categories remain hidden, frequent categories are recovered with small error.",human
"Almost all scientific data have uncertainties originating from different sources. Gaussian process regression (GPR) models are a natural way to model data with Gaussian-distributed uncertainties. GPR also has the benefit of reducing I/O bandwidth and storage requirements for large scientific simulations. However, the reconstruction from the GPR models suffers from high computation complexity. To make the situation worse, classic approaches for visualizing the data uncertainties, like probabilistic marching cubes, are also computationally very expensive, especially for data of high resolutions. In this paper, we accelerate the level-crossing probability calculation efficiency on GPR models by subdividing the data spatially into a hierarchical data structure and only reconstructing values adaptively in the regions that have a non-zero probability. For each region, leveraging the known GPR kernel and the saved data observations, we propose a novel approach to efficiently calculate an upper bound for the level-crossing probability inside the region and use this upper bound to make the subdivision and reconstruction decisions. We demonstrate that our value occurrence probability estimation is accurate with a low computation cost by experiments that calculate the level-crossing probability fields on different datasets.",human
"We address the challenge of end-to-end differentiable reasoning within complex knowledge graphs, where the objective is to infer novel relationships between entities given a limited set of observed facts. Existing approaches often rely on path-ranking algorithms or embedding-based techniques, suffering from either computational intractability on large graphs or a lack of explicit reasoning chains. We propose a novel framework, Differentiable Relational Propagation Networks (DRPN), which combines message passing with a differentiable inductive logic programming (ILP) component. DRPN iteratively refines entity representations through relational propagation, aggregating information from neighborhood nodes using learned aggregation functions conditioned on relation types. Crucially, these aggregation functions are constrained to adhere to Horn clause logic, enabling the extraction of interpretable and verifiable reasoning rules. We train DRPN end-to-end using a reinforcement learning objective, rewarding accurate prediction of held-out facts. Empirical evaluation on benchmark knowledge graph completion datasets, including FB15k-237 and WN18RR, demonstrates that DRPN achieves state-of-the-art performance compared to existing differentiable reasoning models. Furthermore, we show that DRPN's learned rules exhibit high fidelity with human-understandable logical inferences, providing insights into the model's reasoning process. This work represents a step towards more transparent and robust automated reasoning systems.",ai
"Inferring causal relationships from observational data remains a significant challenge in scientific inquiry. Traditional methods often rely on strong assumptions about data generation processes, which may be unrealistic in complex systems. This paper addresses the problem of causal structure learning in settings with unobserved confounders and feedback loops, where conventional constraint-based or score-based approaches frequently fail. We propose a novel hybrid causal discovery algorithm that combines constraint-based skeleton learning with score-based orientation, incorporating a dedicated module for detecting and handling cyclic causal relationships. Our method leverages conditional independence tests conditioned on carefully selected variable sets to identify potential causal edges and then employs a modified Bayesian Information Criterion (BIC) score, penalized for cyclic structures, to orient these edges. Furthermore, we introduce a constraint satisfaction approach to refine the initial causal graph, ensuring consistency with identified conditional independencies. We evaluate the performance of our algorithm on synthetic datasets generated from complex causal models featuring unobserved confounders and feedback loops. Our results demonstrate that the proposed method significantly outperforms existing algorithms in terms of structural Hamming distance (SHD) and F1-score when recovering the true causal graph. We also present a real-world application to gene regulatory network inference using gene expression data, illustrating the practical utility of our approach in uncovering potentially novel causal interactions.",ai
"**Title: Deep Multi-Scale Contextual Reasoning for Enhanced Lung Nodule Detection in CT Scans** Lung cancer is a leading cause of cancer-related mortality, often diagnosed late due to the subtle nature of pulmonary nodules in computed tomography (CT) scans. Automated nodule detection systems offer the potential for early intervention, but current methods struggle with high false positive rates and the detection of small or indistinct nodules. This work addresses the limitations of existing approaches by proposing a novel deep learning framework that leverages multi-scale contextual reasoning to improve nodule detection accuracy. Our method incorporates a 3D convolutional neural network (CNN) backbone augmented with a multi-scale feature aggregation module. This module fuses contextual information extracted from multiple scales using dilated convolutions and attention mechanisms, allowing the network to effectively capture both local and global features relevant to nodule identification. Furthermore, we integrate a residual-based feature refinement block to suppress false positives by explicitly modeling background information. We evaluated our method on the publicly available LUNA16 dataset, achieving a state-of-the-art Competitive Performance Metric (CPM) score of 0.921. Ablation studies demonstrate the effectiveness of each component, particularly the multi-scale feature aggregation module, in improving detection performance. Our results demonstrate a significant reduction in false positives and an enhanced ability to detect subtle nodules, suggesting the potential for improved early diagnosis of lung cancer.",ai
"We address the challenge of training machine learning models on sensitive data while preserving individual privacy. Existing methods often involve trade-offs between utility and privacy, particularly in complex model architectures. We introduce a novel privacy-preserving training framework, Differentially Private Federated Averaging with Adaptive Noise (DP-FedAvg-AN), which combines federated learning with differential privacy and adaptive noise calibration. DP-FedAvg-AN mitigates the impact of privacy noise by dynamically adjusting the noise scale based on the observed gradient variance across participating clients. This adaptive mechanism allows for higher privacy budgets during periods of low gradient variance, leading to improved model accuracy. We evaluate the performance of DP-FedAvg-AN on benchmark datasets for image classification and natural language processing tasks. Our experimental results demonstrate that DP-FedAvg-AN achieves significantly higher accuracy compared to traditional differentially private federated learning methods with fixed noise scales, particularly in scenarios with heterogeneous data distributions across clients. Furthermore, we show that DP-FedAvg-AN effectively balances privacy guarantees and model utility, providing a robust and practical solution for privacy-preserving machine learning in federated environments. The framework exhibits resilience to various attacks designed to infer private information from model updates.",ai
"This work investigates the efficacy of Transformer-based architectures for natural language processing tasks, specifically focusing on long-range dependency modeling and contextual understanding. While Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) have traditionally been employed, they often struggle with capturing relationships between distant words and parallelization. We address this limitation by leveraging the self-attention mechanism inherent in Transformers, enabling the model to directly attend to all input tokens simultaneously. We propose a novel adaptation of the standard Transformer architecture incorporating a learnable positional encoding scheme and modified layer normalization for improved gradient flow during training. The proposed model is evaluated on three benchmark datasets: GLUE, SQuAD v2.0, and WikiText-103. Experimental results demonstrate significant performance gains compared to state-of-the-art RNN and CNN-based models across all tasks. Specifically, we observe a 5% improvement in GLUE benchmark score, a 3% increase in F1 score on SQuAD v2.0, and a 15% reduction in perplexity on WikiText-103. These findings suggest that the proposed Transformer-based approach provides a robust and effective solution for capturing complex linguistic relationships and achieving superior performance in diverse NLP applications.",ai
"Graph Neural Networks (GNNs) have demonstrated efficacy in modeling relational data across diverse domains. However, challenges remain in effectively capturing long-range dependencies and contextual information within complex graph structures, often leading to suboptimal performance on tasks requiring holistic graph understanding. This work addresses this limitation by introducing a novel Graph Transformer Network (GTN) architecture incorporating a multi-headed attention mechanism with learned structural encodings. Unlike conventional GNNs that rely on neighborhood aggregation, GTN leverages attention weights informed by node attributes and learned structural features to facilitate direct communication between distant nodes. The structural encodings are generated by a parameterized graph diffusion process, enabling the network to implicitly learn the importance of diverse graph substructures. We evaluate the proposed GTN on benchmark graph classification datasets, including MUTAG, PROTEINS, and IMDB-BINARY. Experimental results demonstrate that GTN significantly outperforms existing GNN architectures and graph kernel methods, achieving state-of-the-art performance on these datasets. Ablation studies further validate the contribution of the learned structural encodings and multi-headed attention mechanism to the overall performance gain. These findings suggest that GTN offers a powerful approach for modeling complex graph structures and enhancing the capabilities of GNNs for graph-level prediction tasks.",ai
"We address the problem of distributional robustness in natural language processing, specifically focusing on neural sequence models susceptible to adversarial attacks and noisy data. Such models often exhibit brittle performance when faced with even minor perturbations to the input distribution, hindering their deployment in real-world scenarios. We propose a novel robust optimization framework that incorporates an ensemble of adversarial training strategies coupled with a differentiable data augmentation policy. This approach aims to learn model parameters that are less sensitive to worst-case data distributions within a specified uncertainty set. The uncertainty set is dynamically adjusted during training based on the model's observed sensitivity to various data augmentations. We utilize a reinforcement learning-based policy gradient method to optimize the data augmentation policy, enabling the model to adapt to a continuously evolving adversarial landscape. Experimental results on benchmark NLP tasks, including text classification and machine translation, demonstrate significant improvements in robustness against both white-box and black-box adversarial attacks, as well as improved generalization performance on noisy datasets. Our method consistently outperforms existing adversarial training baselines and other robust optimization techniques, achieving state-of-the-art robustness with minimal degradation in clean data performance.",ai
"Medical image classification is a critical task in healthcare, enabling accurate and timely diagnosis. However, deploying deep learning models on resource-constrained edge devices presents significant challenges due to computational and memory limitations. This research investigates a resource-efficient approach to medical image classification by employing model quantization techniques. Quantization reduces the precision of model parameters and activations, significantly lowering computational overhead and memory requirements without sacrificing classification accuracy. The study focuses on the optimization of quantization-aware training (QAT) and post-training quantization (PTQ) methods tailored for edge devices, analyzing their impact on model performance across medical imaging datasets. Experimental results demonstrate that quantized models achieve substantial reductions in model size and inference latency, enabling real-time processing on edge hardware while maintaining clinically acceptable diagnostic accuracy. This work provides a practical pathway for deploying AI-driven medical diagnostics in remote and resource-limited settings, enhancing the accessibility and scalability of healthcare technologies.",human
"### Abstract This paper addresses the challenge of effectively representing and reasoning with hierarchical knowledge structures, particularly those containing overlapping concepts and intricate semantic relationships, which are often poorly handled by traditional symbolic representation formalisms. We introduce a novel knowledge representation approach called ""Contextualized Semantic Hierarchies"" (CSH), which leverages probabilistic graphical models to encode not only the hierarchical relationships between concepts but also contextual dependencies that influence the semantic meaning and relevance of those concepts in specific situations. CSH employs a Bayesian network structure where nodes represent concepts, and conditional probability distributions capture the likelihood of a concept being active given its parent and contextual variables. Inference within CSH is performed using a variational inference algorithm that approximates the posterior distribution over concept activations, allowing for efficient reasoning about concept membership and relationship strengths. Experimental evaluation on benchmark knowledge graph datasets and a real-world clinical diagnosis task demonstrates that CSH achieves significant improvements in accuracy and recall compared to baseline methods based on ontology learning and rule-based reasoning. Furthermore, the contextualized nature of CSH allows for more nuanced and accurate predictions in scenarios where simple hierarchical relationships are insufficient.",ai
"We address the challenge of achieving efficient and robust coordination in decentralized multi-agent systems operating in complex, partially observable environments. A key problem is balancing exploration of individual agent strategies with exploitation of observed collective behaviors to converge to globally optimal solutions. We propose a novel multi-agent reinforcement learning algorithm, Decoupled Policy Optimization with Implicit Communication (DPO-IC), which combines decentralized policy optimization with an implicit communication channel learned through a differentiable information bottleneck. Specifically, each agent learns a local policy conditioned on its private observations and an inferred communication signal. This signal is derived from a shared latent space modulated by an attention mechanism, allowing agents to selectively attend to relevant information without explicit message passing. We evaluate DPO-IC on a suite of challenging cooperative navigation and resource allocation tasks. Our results demonstrate that DPO-IC achieves significantly improved performance compared to state-of-the-art decentralized policy gradient methods, exhibiting faster convergence and enhanced robustness to noisy observations and adversarial perturbations. Furthermore, analysis of the learned communication channel reveals that agents develop specialized communication strategies aligned with their individual roles, suggesting the emergence of structured communication protocols. These findings highlight the potential of implicit communication for enabling efficient and scalable coordination in complex multi-agent systems.",ai
"Physics-informed machine learning uses governing ordinary and/or partial differential equations to train neural networks to represent the solution field. Like any machine learning problem, the choice of activation function influences the characteristics and performance of the solution obtained from physics-informed training. Several studies have compared common activation functions on benchmark differential equations, and have unanimously found that the rectified linear unit (ReLU) is outperformed by competitors such as the sigmoid, hyperbolic tangent, and swish activation functions. In this work, we diagnose the poor performance of ReLU on physics-informed machine learning problems. While it is well-known that the piecewise linear form of ReLU prevents it from being used on second-order differential equations, we show that ReLU fails even on variational problems involving only first derivatives. We identify the cause of this failure as second derivatives of the activation, which are taken not in the formulation of the loss, but in the process of training. Namely, we show that automatic differentiation in PyTorch fails to characterize derivatives of discontinuous fields, which causes the gradient of the physics-informed loss to be mis-specified, thus explaining the poor performance of ReLU.",human
"We address the challenge of decentralized policy learning in cooperative multi-agent systems (MAS) operating under partial observability and communication constraints. Conventional reinforcement learning algorithms often struggle with the non-stationarity induced by concurrent learning and the credit assignment problem across agents. To mitigate these issues, we propose a novel approach combining variational inference with a graph neural network (GNN) architecture. Specifically, each agent maintains a variational approximation of its belief about the latent intentions of other agents, conditioned on its local observations and communicated messages. These beliefs are iteratively refined via a message-passing mechanism implemented by the GNN, enabling agents to infer dependencies and predict future behaviors. We demonstrate the efficacy of our method on a suite of challenging cooperative navigation and target assignment tasks. Results show that our approach significantly outperforms state-of-the-art decentralized learning algorithms, particularly in scenarios with limited communication bandwidth and high levels of environmental stochasticity. Furthermore, we provide empirical evidence that the learned variational beliefs effectively capture the underlying coordination patterns, leading to more robust and adaptable joint policies. The improved performance stems from the agents' ability to more accurately model and anticipate the actions of their teammates, fostering more effective collaboration.",ai
"Despite advances in mathematical reasoning capabilities, Large Language Models (LLMs) still struggle with calculation verification when using established prompting techniques. We present MDToC (Metacognitive Dynamic Tree of Concepts), a three-phase approach that constructs a concept tree, develops accuracy-verified calculations for each concept, and employs majority voting to evaluate competing solutions. Evaluations across CHAMP, MATH, and Game-of-24 benchmarks demonstrate our MDToC's effectiveness, with GPT-4-Turbo achieving 58.1\% on CHAMP, 86.6\% on MATH, and 85\% on Game-of-24 - outperforming GoT by 5\%, 5.4\%, and 4\% on all these tasks, respectively, without hand-engineered hints. MDToC consistently surpasses existing prompting methods across all backbone models, yielding improvements of up to 7.6\% over ToT and 6.2\% over GoT, establishing metacognitive calculation verification as a promising direction for enhanced mathematical reasoning.",human
"We address the problem of enhancing knowledge representation in open-domain question answering systems, specifically focusing on improving the accuracy and efficiency of reasoning over complex, multi-hop relationships. Current approaches often struggle with representing subtle semantic nuances and struggle to efficiently traverse large knowledge graphs to identify relevant supporting facts. We propose a novel method, Relational Schema-Aware Knowledge Graph Embedding (RSA-KGE), which integrates schema information into the embedding learning process. RSA-KGE utilizes a hierarchical attention mechanism to prioritize relational paths based on their relevance to both the query and the overall knowledge graph structure. This mechanism dynamically weights different relation types during embedding generation, allowing for a more nuanced representation of semantic relationships. We evaluate RSA-KGE on several benchmark datasets for multi-hop question answering, including HotpotQA and ComplexWebQuestions. Our results demonstrate a significant improvement in answer accuracy compared to state-of-the-art baseline models, with an average increase of 5.7% in F1 score. Furthermore, RSA-KGE exhibits improved computational efficiency in knowledge graph traversal, reducing the average inference time by 18% due to the optimized relational path selection process. These findings suggest that incorporating schema awareness into knowledge graph embeddings provides a substantial benefit for complex reasoning tasks.",ai
"We address the challenge of sample inefficiency in reinforcement learning (RL) within sparse-reward environments. Many real-world scenarios present rewards that are infrequently encountered, hindering effective learning via traditional RL algorithms. We propose a novel approach termed ""Curriculum-Guided Intrinsic Motivation"" (CGIM), which leverages a dynamically generated curriculum to shape exploration. CGIM utilizes a learned value function to identify state spaces where the agent exhibits high uncertainty, subsequently crafting intrinsically motivated tasks that guide the agent towards these regions. The curriculum evolves based on the agent's progress, prioritizing tasks that are challenging yet attainable, thereby fostering a more focused and efficient exploration strategy. We evaluate CGIM on a suite of benchmark environments, including sparse-reward navigation tasks and robotic manipulation problems. Experimental results demonstrate that CGIM significantly outperforms state-of-the-art RL algorithms, achieving substantial improvements in sample efficiency and overall performance. Specifically, CGIM exhibits a 2x-5x reduction in the number of environment interactions required to reach equivalent performance levels compared to baseline methods. These findings highlight the efficacy of curriculum-guided intrinsic motivation as a powerful technique for accelerating learning in challenging RL settings.",ai
"We address the problem of efficiently verifying the satisfiability of complex first-order logic formulas with equality, a task crucial in theorem proving and formal verification. Traditional satisfiability modulo theories (SMT) solvers often struggle with formulas involving deeply nested quantifiers and complex equality reasoning, leading to scalability limitations. We propose a novel approach integrating a neural-guided term rewriting system with a conventional SMT solver. The neural network is trained on a dataset of proven theorems and refutations to predict promising term rewriting sequences that simplify the input formula while preserving satisfiability. These rewritten formulas are then fed into the SMT solver. The rewriting process prioritizes simplification strategies likely to eliminate quantifiers and reduce the complexity of equality relations. We evaluate our method on a benchmark suite consisting of problems from the TPTP and SMT-LIB libraries, focusing on problems known to be challenging for existing SMT solvers. Empirical results demonstrate that our neural-guided rewriting system significantly improves the success rate and reduces the solving time compared to state-of-the-art SMT solvers alone, particularly on problems requiring intricate equality reasoning and quantifier instantiation. Our approach achieves a 20% improvement in the number of problems solved within a fixed time limit, suggesting a promising direction for enhancing the scalability of automated reasoning systems.",ai
"We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.",human
"When finetuning large language models for specialized tasks such as mathematical reasoning, models exhibit catastrophic forgetting, losing previously learned capabilities. We investigate this by finetuning Flan-T5-Base (250M parameters) on the DeepMind Mathematics dataset and measuring forgetting on MultiNLI. Math-only training improves mathematical accuracy from 3.1\% to 12.0\% but causes NLI accuracy to collapse from 81.0\% to 16.5\%--a 64.5 percentage point drop occurring within the first 1,000 training steps. We propose mixed training strategies that interleave mathematical and NLI examples during training. Our results demonstrate that mixed training completely eliminates catastrophic forgetting while maintaining equivalent mathematical performance: the balanced 1:1 ratio achieves 12.0\% math accuracy (matching math-only) while preserving 86.2\% NLI accuracy. We systematically explore mixing ratios from 1:1 to 15:1, finding that even minimal NLI exposure (6.2\%) provides effective regularization. These findings demonstrate that specialization need not require forgetting general capabilities, with implications for scaling to larger models where mixed training may confer additional benefits beyond forgetting prevention.",human
"We address the problem of efficiently representing and reasoning with complex relationships between entities in dynamic knowledge graphs. Existing methods often struggle to maintain consistency and scalability when confronted with frequent updates and nuanced inferential requirements. We introduce a novel framework, Relational Attentive Embedding Networks (RAEN), which combines relational graph convolutional networks with an attention mechanism to dynamically learn and refine entity and relation embeddings. RAEN incorporates a temporal decay factor to prioritize recent interactions and a constraint satisfaction module to enforce logical consistency across the knowledge graph. We evaluate RAEN on benchmark knowledge graph completion and link prediction tasks, specifically FB15k-237 and WN18RR, under varying levels of data sparsity and update frequency. Results demonstrate that RAEN outperforms state-of-the-art models in both accuracy and computational efficiency, exhibiting a relative improvement of up to 15% in Mean Reciprocal Rank (MRR) compared to baseline methods. Further analysis reveals that the attention mechanism effectively captures long-range dependencies between entities, leading to improved inferential capabilities and robustness to noisy data. These findings suggest RAEN provides a promising approach for scalable and accurate knowledge representation in dynamic environments.",ai
"We present a novel methodology for improving the diagnostic accuracy of pulmonary embolism (PE) detection in computed tomography pulmonary angiography (CTPA) images. Despite advancements in medical imaging, accurately identifying small or subsegmental PEs remains challenging due to subtle visual characteristics and inter-observer variability. Our approach leverages a multi-scale convolutional neural network (CNN) architecture, incorporating attention mechanisms to focus on regions of interest within the pulmonary vasculature. Specifically, we employ a 3D U-Net variant with squeeze-and-excitation blocks, trained end-to-end to segment and classify potential emboli. The network is trained on a large dataset of CTPA scans, with ground truth annotations provided by experienced radiologists. Performance is evaluated using metrics relevant to clinical practice, including sensitivity, specificity, and area under the receiver operating characteristic curve (AUC). Our results demonstrate a significant improvement in PE detection accuracy compared to traditional methods, achieving an AUC of 0.94, a sensitivity of 0.91 at 0.85 specificity, and a reduction in false positive rate by 15% compared to a baseline model trained without attention mechanisms. Further, visualization of the attention maps highlights the regions within the CTPA scans that the network prioritizes for PE detection, offering potential insights for radiologists and facilitating more confident diagnoses. This methodology offers a promising tool for enhancing the accuracy and efficiency of PE diagnosis in clinical settings.",ai
"The globalization of education and rapid growth of online learning have made localizing educational content a critical challenge. Lecture materials are inherently multimodal, combining spoken audio with visual slides, which requires systems capable of processing multiple input modalities. To provide an accessible and complete learning experience, translations must preserve all modalities: text for reading, slides for visual understanding, and speech for auditory learning. We present , a multimodal multilingual lecture companion that jointly translates lecture audio and slides to produce synchronized outputs across three modalities: translated text, localized slides with preserved visual elements, and synthesized speech. This end-to-end approach enables students to access lectures in their native language while aiming to preserve the original content in its entirety. Our experiments demonstrate that slide-aware transcripts also yield cascading benefits for downstream tasks such as summarization and question answering. We release our Slide Translation code at https://github.com/saikoneru/image-translator and integrate it in Lecture Translator at https://gitlab.kit.edu/kit/isl-ai4lt/lt-middleware/ltpipeline}\footnote{All released code and models are licensed under the MIT License.",human
"Decentralized federated learning (DFL) enables collaborative model training without centralized trust, but it remains vulnerable to Byzantine clients that poison gradients under heterogeneous (Non-IID) data. Existing defenses face a scalability trilemma: distance-based filtering (e.g., Krum) can reject legitimate Non-IID updates, geometric-median methods incur prohibitive cost, and many certified defenses are evaluated only on models below 100M parameters. We propose Spectral Sentinel, a Byzantine detection and aggregation framework that leverages a random-matrix-theoretic signature: honest Non-IID gradients produce covariance eigenspectra whose bulk follows the Marchenko-Pastur law, while Byzantine perturbations induce detectable tail anomalies. Our algorithm combines Frequent Directions sketching with data-dependent MP tracking, enabling detection on models up to 1.5B parameters using memory with . Under a threat model with coordinate-wise honest variance bounded by and adversaries, we prove -Byzantine resilience with convergence rate , and we provide a matching information-theoretic lower bound , establishing minimax optimality. We implement the full system with blockchain integration on Polygon networks and validate it across 144 attack-aggregator configurations, achieving 78.4 percent average accuracy versus 48-63 percent for baseline methods.",human
"The widespread application of wireless communication technology has promoted the development of smart agriculture, where unmanned aerial vehicles (UAVs) play a multifunctional role. We target a multi-UAV smart agriculture system where UAVs cooperatively perform data collection, image acquisition, and communication tasks. In this context, we model a Markov decision process to solve the multi-UAV trajectory planning problem. Moreover, we propose a novel Elite Imitation Actor-Shared Ensemble Critic (EIA-SEC) framework, where agents adaptively learn from the elite agent to reduce trial-and-error costs, and a shared ensemble critic collaborates with each agent's local critic to ensure unbiased objective value estimates and prevent overestimation. Experimental results demonstrate that EIA-SEC outperforms state-of-the-art baselines in terms of reward performance, training stability, and convergence speed.",human
"We investigate the problem of representing and reasoning with complex relational knowledge in open-domain question answering. Existing knowledge representation formalisms often struggle to capture the nuances of natural language and exhibit limitations in scalable inference. This paper introduces a novel knowledge representation framework, Relationally Anchored Conceptual Graphs (RACGs), designed to explicitly encode semantic roles and inter-entity relationships derived from text. RACGs extend traditional conceptual graphs by anchoring nodes to specific spans in the source text, facilitating traceability and improving interpretability. We propose a graph neural network-based reasoning module that operates directly on RACGs, enabling multi-hop inference over structured knowledge. This module leverages attention mechanisms to dynamically weigh the relevance of different relational paths for answering a given question. We evaluate RACGs on several challenging question answering datasets requiring multi-hop reasoning and compare against state-of-the-art knowledge graph embedding and symbolic reasoning methods. Experimental results demonstrate that our approach significantly outperforms existing techniques, achieving a relative improvement of 8-12% in accuracy, while also providing improved explainability through the textual grounding of inference paths. Further analysis reveals the RACG formalism's superior ability to handle implicit relationships and contextual nuances, contributing to more robust and accurate knowledge-driven question answering.",ai
"### Abstract The automated detection and segmentation of anatomical structures in medical imaging modalities such as computed tomography (CT) and magnetic resonance imaging (MRI) remains a challenging problem due to inherent image noise, variability in patient anatomy, and limited availability of annotated training data. Current deep learning approaches, while promising, often suffer from overfitting and poor generalization performance across diverse datasets. This work presents a novel deep learning architecture, termed Spatially Attentive Dense Network (SADN), designed to improve segmentation accuracy and robustness in medical image analysis. SADN incorporates a dense connectivity pattern to facilitate feature reuse and gradient flow, mitigating the vanishing gradient problem often encountered in deep networks. Furthermore, a spatial attention mechanism is integrated to selectively focus on relevant anatomical regions, suppressing irrelevant background noise and enhancing feature representation. The proposed SADN architecture was evaluated on three publicly available medical imaging datasets for lung nodule segmentation, brain tumor segmentation, and cardiac structure segmentation. Experimental results demonstrate that SADN achieves superior performance compared to state-of-the-art segmentation methods, exhibiting Dice similarity coefficients (DSC) of 0.89, 0.82, and 0.91 for lung nodule, brain tumor, and cardiac structure segmentation respectively. These results indicate that SADN provides a robust and accurate solution for automated anatomical structure segmentation in medical imaging, potentially improving diagnostic efficiency and clinical workflow.",ai
"We address the challenge of automated pulmonary nodule detection in computed tomography (CT) scans, a critical task for early lung cancer diagnosis. Manual review of these scans is time-consuming and prone to inter-observer variability, necessitating robust and efficient automated solutions. We propose a novel multi-scale convolutional neural network (MS-CNN) architecture incorporating spatial attention mechanisms to improve nodule localization and reduce false positive rates. The MS-CNN leverages convolutional layers with varying receptive fields to capture nodule characteristics at different scales, while the attention mechanism dynamically weights feature maps to emphasize relevant regions and suppress irrelevant background noise. The network is trained end-to-end using a large, publicly available dataset of chest CT scans annotated with nodule locations. Evaluation on a held-out test set demonstrates that our MS-CNN achieves a sensitivity of 92.3% at 4 false positives per scan, surpassing the performance of several existing state-of-the-art nodule detection algorithms. Furthermore, ablation studies validate the contribution of both the multi-scale architecture and the spatial attention mechanism to the overall performance. These results suggest that the proposed MS-CNN offers a promising approach for automated pulmonary nodule detection, potentially improving diagnostic accuracy and efficiency in clinical settings.",ai
"We provide causal mechanistic validation that in-context learning (ICL) decomposes into two separable mechanisms: Task Schema (abstract task type recognition) and Binding (specific input-output associations). Through activation patching experiments across 9 models from 7 Transformer families plus Mamba (370M-13B parameters), we establish three key findings: 1. Double dissociation: Task Schema transfers at 100% via late MLP patching; Binding transfers at 62% via residual stream patching -- proving separable mechanisms 2. Prior-Schema trade-off: Schema reliance inversely correlates with prior knowledge (Spearman rho = -0.596, p < 0.001, N=28 task-model pairs) 3. Architecture generality: The mechanism operates across all tested architectures including the non-Transformer Mamba These findings offer a mechanistic account of the ICL puzzle that contrasts with prior views treating ICL as a monolithic mechanism (whether retrieval-based, gradient descent-like, or purely Bayesian). By establishing that Schema and Binding are neurally dissociable -- not merely behavioral modes -- we provide causal evidence for dual-process theories of ICL. Models rely on Task Schema when prior knowledge is absent, but prior knowledge interferes through attentional mis-routing (72.7% recency bias) rather than direct output competition (0%). This explains why arbitrary mappings succeed (zero prior leads to full Schema reliance) while factual overrides fail -- and reveals that the true bottleneck is attentional, not output-level. Practical implications: Understanding these dual mechanisms enables more efficient prompt engineering -- reliable schema transfer reduces required demonstrations for novel tasks, while prior-aware design can mitigate the 38% binding failure rate in high-prior scenarios, improving ICL system reliability in production deployments.",human
"We address the challenge of robust causal effect estimation in the presence of unobserved confounding and selection bias, a prevalent problem in observational studies. Traditional causal inference methods often rely on strong assumptions, such as ignorability, which are easily violated in real-world scenarios. To mitigate this issue, we propose a novel approach based on a doubly robust estimator that integrates instrumental variable (IV) regression with a conditional outcome model learned via adversarial training. Specifically, we leverage the IV to identify a valid instrument and use it to estimate the causal effect while simultaneously learning a balanced representation of the treatment and control groups through adversarial training. This adversarial balancing minimizes the dependence between treatment assignment and observed covariates, thereby reducing the impact of selection bias. We demonstrate the efficacy of our method on both synthetic datasets, where the ground truth causal effect is known, and real-world healthcare datasets. Our results indicate that the proposed approach significantly outperforms state-of-the-art causal inference techniques in terms of bias reduction and estimation accuracy, especially when the assumptions of strong ignorability are violated and selection bias is present. We further provide theoretical guarantees for the consistency of our estimator under specific conditions.",ai
"**Multi-Agent Coordination via Differentiable Communication Topologies** Coordination in multi-agent systems (MAS) is often hampered by fixed communication topologies that may be suboptimal for specific task demands and agent capabilities. This paper addresses the problem of adaptively shaping communication structures to enhance team performance in cooperative settings. We propose a novel end-to-end differentiable framework that learns communication topologies directly from observed agent interactions and environmental context. Our method employs a Gated Graph Neural Network (GGNN) to represent the MAS, where edge weights in the graph represent communication intensity. We introduce a differentiable relaxation of discrete graph structures, allowing gradient-based optimization of communication patterns. This relaxation is achieved through a sigmoid-based edge gating mechanism that modulates message passing between agents. A reinforcement learning agent learns to control these gate parameters, influencing the communication topology based on the current state and observed rewards. Experiments conducted on challenging cooperative navigation and resource allocation tasks demonstrate that our approach significantly outperforms MAS with fixed communication topologies and those that rely on hand-engineered communication protocols. Furthermore, learned communication structures reveal emergent specialization and role differentiation within the agent team, providing insights into effective coordination strategies. The results indicate that dynamically adaptable communication topologies are crucial for achieving efficient and robust multi-agent cooperation in complex environments.",ai
"We investigate the problem of decentralized learning in multi-agent systems characterized by non-stationary environments and partial observability. Traditional reinforcement learning algorithms often struggle in such settings due to the violation of the Markov property and the challenges of coordinating policies across agents without explicit communication. We propose a novel approach, Decentralized Variational Policy Gradient (DVPG), which leverages a variational autoencoder to learn a latent representation of each agent's observation history. This latent space is then used to condition a policy network, enabling agents to implicitly infer the states and intentions of other agents and adapt their policies accordingly. A key feature of DVPG is its decentralized nature; agents learn their individual latent spaces and policies independently, eliminating the need for centralized training or communication during execution. Empirical evaluation on a suite of benchmark multi-agent environments demonstrates that DVPG achieves superior performance compared to existing decentralized learning algorithms, exhibiting improved coordination, robustness to noisy observations, and faster convergence rates. Furthermore, we analyze the learned latent spaces, revealing that they capture meaningful information about the underlying dynamics of the environment and the behavior of other agents. These findings suggest that DVPG provides a promising framework for addressing the challenges of decentralized learning in complex multi-agent systems.",ai
"We address the challenge of coordinating decentralized agents in complex, partially observable environments where communication is unreliable and intermittent. Traditional multi-agent reinforcement learning (MARL) algorithms often struggle in such settings due to the difficulty of inferring agent intentions and maintaining consistent joint action policies. We propose a novel Hierarchical Intention Inference Network (HIIN) which incorporates a hierarchical latent variable model to infer both individual agent intentions and the overall group objective. HIIN learns a global policy based on the inferred group objective, while simultaneously deriving individualized policies conditioned on agent-specific intentions. Critically, the inference process is designed to be robust to communication failures by leveraging both communicated messages (when available) and local observations to update the latent representations. We evaluate HIIN on a set of challenging cooperative navigation and resource allocation tasks within a simulated environment that includes variable communication reliability. Our results demonstrate that HIIN significantly outperforms state-of-the-art MARL algorithms, particularly in scenarios with high communication noise and partial observability. We further show that the learned latent representations effectively capture the underlying agent intentions and group objectives, leading to improved coordination and robustness.",ai
"Transformer architectures have demonstrated remarkable success in various natural language processing (NLP) tasks. However, the computational demands of training and deploying large transformer models remain a significant challenge, particularly for resource-constrained environments. This paper addresses the problem of efficiently adapting transformer models to specific downstream tasks while minimizing computational overhead. We introduce a novel method, Task-Adaptive Parameter Reduction (TAPR), which dynamically identifies and prunes redundant parameters within the transformer layers based on task-specific data. TAPR utilizes a learnable masking mechanism that is jointly optimized with the primary model parameters during fine-tuning. The masking mechanism is trained to prioritize parameter retention that maximizes performance on the target task, resulting in a sparse model structure. Experimental results on a diverse set of NLP benchmarks, including text classification, question answering, and named entity recognition, demonstrate that TAPR achieves substantial parameter reduction (up to 60%) with minimal degradation in performance compared to fully fine-tuned dense transformer models. Furthermore, TAPR exhibits improved inference speed and reduced memory footprint, making it a viable solution for deploying transformer-based NLP models in resource-limited settings.",ai
"Reinforcement learning with verifiable rewards (RLVR) has proven effective in training large reasoning models (LRMs) by leveraging answer-verifiable signals to guide policy optimization, which, however, suffers from high annotation costs. To alleviate this problem, recent work has explored unsupervised RLVR methods that derive rewards solely from the model's internal consistency, such as through entropy and majority voting. While seemingly promising, these methods often suffer from model collapse in the later stages of training, which may arise from the reinforcement of incorrect reasoning patterns in the absence of external supervision. In this work, we investigate a novel semi-supervised RLVR paradigm that utilizes a small labeled set to guide RLVR training on unlabeled samples. Our key insight is that supervised rewards are essential for stabilizing consistency-based training on unlabeled samples, ensuring that only reasoning patterns verified on labeled instances are incorporated into RL training. Technically, we propose an effective policy optimization algorithm, TraPO, that identifies reliable unlabeled samples by matching their learning trajectory similarity to labeled ones. Building on this, TraPO achieves remarkable data efficiency and strong generalization on six widely used mathematical reasoning benchmarks (AIME24/25, AMC, MATH-500, Minerva, and Olympiad) and three out-of-distribution tasks (ARC-c, GPQA-diamond, and MMLU-pro). With only 1K labeled and 3K unlabeled samples, TraPO reaches 42.6% average accuracy, surpassing the best unsupervised method trained on 45K unlabeled samples (38.3%). Notably, when using 4K labeled and 12K unlabeled samples, TraPO even outperforms the fully supervised model trained on the full 45K labeled samples on all benchmarks, while using only 10% of the labeled data. The code is available via https://github.com/ShenzhiYang2000/TRAPO.",human
"This work addresses the critical challenge of training machine learning models on sensitive data while adhering to stringent privacy constraints. We investigate a novel approach to privacy-preserving machine learning utilizing a combination of differentially private stochastic gradient descent (DPSGD) and federated learning (FL) with client-side data augmentation. Specifically, we propose a modified DPSGD algorithm incorporating a dynamically adjusted privacy budget allocation based on client data heterogeneity, optimizing for model utility under a fixed privacy loss parameter, epsilon. Furthermore, we introduce a generative adversarial network (GAN) framework trained locally on each client's data to augment their respective datasets with synthetic samples, mitigating the impact of data scarcity and further enhancing model generalization. Experimental results on benchmark datasets, including MNIST and CIFAR-10, demonstrate that our proposed method achieves a significant improvement in model accuracy compared to standard DPSGD and FL implementations. Specifically, we observe a 5-10% increase in test accuracy while maintaining comparable levels of differential privacy, quantified by epsilon and delta. These findings suggest that dynamically adjusting privacy budget allocation and leveraging client-side GAN-based data augmentation can substantially improve the performance of privacy-preserving machine learning algorithms in heterogeneous federated settings.",ai
"Recent advancements in machine learning (ML) have heightened concerns regarding data privacy, particularly when models are trained on sensitive user data. A significant challenge lies in balancing the utility of trained models with the imperative to protect individual privacy. This work addresses the problem of training ML models, specifically text classifiers, while preserving differential privacy (DP). We introduce a novel approach leveraging a combination of federated learning (FL) and differentially private stochastic gradient descent (DPSGD) with a refined privacy accounting mechanism. Our method, termed Privacy-Preserving Federated Text Classification (PP-FTC), involves training a text classification model iteratively across decentralized datasets held by multiple participants, each contributing to the global model without directly sharing their raw data. Furthermore, we introduce a dynamic clipping strategy for DPSGD to mitigate the impact of outlier gradients on model performance. Experiments conducted on benchmark text classification datasets, including AG News and IMDb, demonstrate that PP-FTC achieves a significant improvement in classification accuracy compared to existing DP-SGD baselines under comparable privacy budgets. Specifically, PP-FTC exhibits a relative improvement of up to 15% in F1-score while maintaining strong privacy guarantees (Îµ < 5). These results suggest that PP-FTC offers a practical and effective approach for privacy-preserving text classification in real-world scenarios.",ai
"We address the critical challenge of training machine learning models on sensitive data while preserving individual privacy. Specifically, we focus on scenarios where data owners are unwilling to directly share their raw data due to privacy concerns, but are willing to participate in a collaborative learning process. Our work introduces a novel differentially private federated learning framework that leverages homomorphic encryption to enhance security and privacy guarantees. This framework enables the aggregation of model updates from multiple clients without revealing individual client data or model contributions to the central server. Our method employs a Paillier cryptosystem to encrypt client-side model updates before aggregation. Crucially, we incorporate a customized clipping and noise addition mechanism tailored to the encrypted domain to enforce differential privacy. The parameters of the clipping and noise addition are dynamically adjusted based on the observed distribution of encrypted updates, optimizing the utility-privacy trade-off. We theoretically analyze the privacy guarantees of our framework, proving -differential privacy. Empirical evaluations on benchmark datasets demonstrate that our method achieves comparable model performance to non-private federated learning baselines, while providing strong privacy protection. Furthermore, our experiments show that our adaptive noise mechanism significantly outperforms static noise addition methods in terms of both accuracy and privacy budget expenditure. These results suggest the potential of our framework for practical deployment in privacy-sensitive applications, such as healthcare and finance.",ai
"We address the problem of automating propositional satisfiability (SAT) solving via machine learning. While traditional SAT solvers rely on hand-crafted heuristics and intricate branching strategies, our approach aims to learn these strategies directly from problem instance characteristics. We propose a novel graph neural network (GNN) architecture, ClausePropNet, that operates on a bipartite graph representation of the SAT formula, explicitly encoding clauses and variables as distinct node types. ClausePropNet iteratively propagates information between clauses and variables, learning to predict variable assignments that lead to solution. A reinforcement learning framework is employed, where the agent (ClausePropNet) chooses a variable assignment at each step, and the environment provides a reward signal based on progress towards satisfying the formula. Our reward function incorporates both immediate clause satisfaction and long-term solution potential. We train and evaluate ClausePropNet on a diverse set of SAT benchmarks, including instances from combinatorial design, circuit verification, and software verification. Empirical results demonstrate that ClausePropNet achieves competitive performance compared to state-of-the-art SAT solvers, particularly on structured instances where the learned representation captures underlying problem structure. Furthermore, ClausePropNet exhibits improved generalization capabilities to unseen problem distributions compared to traditional heuristic-based solvers, suggesting its potential for learning robust SAT solving strategies.",ai
"This paper presents the first end-to-end pipeline for Handwritten Text Recognition (HTR) for Old Nepali, a historically significant but low-resource language. We adopt a line-level transcription approach and systematically explore encoder-decoder architectures and data-centric techniques to improve recognition accuracy. Our best model achieves a Character Error Rate (CER) of 4.9\%. In addition, we implement and evaluate decoding strategies and analyze token-level confusions to better understand model behaviour and error patterns. While the dataset we used for evaluation is confidential, we release our training code, model configurations, and evaluation scripts to support further research in HTR for low-resource historical scripts.",human
"Understanding intraventricular hemodynamics requires compact and physically interpretable representations of the underlying flow structures, as characteristic flow patterns are closely associated with cardiovascular conditions and can support early detection of cardiac deterioration. Conventional visualization of velocity or pressure fields, however, provides limited insight into the coherent mechanisms driving these dynamics. Reduced-order modeling techniques, like Proper Orthogonal Decomposition (POD) and Autoencoder (AE) architectures, offer powerful alternatives to extract dominant flow features from complex datasets. This study systematically compares POD with several AE variants (Linear, Nonlinear, Convolutional, and Variational) using left ventricular flow fields obtained from computational fluid dynamics simulations. We show that, for a suitably chosen latent dimension, AEs produce modes that become nearly orthogonal and qualitatively resemble POD modes that capture a given percentage of kinetic energy. As the number of latent modes increases, AE modes progressively lose orthogonality, leading to linear dependence, spatial redundancy, and the appearance of repeated modes with substantial high-frequency content. This degradation reduces interpretability and introduces noise-like components into AE-based reduced-order models, potentially complicating their integration with physics-based formulations or neural-network surrogates. The extent of interpretability loss varies across the AEs, with nonlinear, convolutional, and variational models exhibiting distinct behaviors in orthogonality preservation and feature localization. Overall, the results indicate that AEs can reproduce POD-like coherent structures under specific latent-space configurations, while highlighting the need for careful mode selection to ensure physically meaningful representations of cardiac flow dynamics.",human
"We investigate the challenge of coordinating decentralized agents in complex, partially observable environments where agents possess heterogeneous capabilities and limited communication bandwidth. Current multi-agent reinforcement learning (MARL) algorithms often struggle with scalability and efficient credit assignment in such settings. To address this, we propose a novel framework, Hierarchical Attention-Based Communication for Decentralized Execution (HABCODE), which leverages hierarchical reinforcement learning principles to decompose the joint action space into a high-level strategic decision and low-level execution primitives. Agents learn to attend selectively to relevant information from their neighbors using a differentiable attention mechanism, allowing for efficient information aggregation while mitigating the communication bottleneck. The high-level policy learns to dynamically allocate resources and coordinate tasks across agents, while the low-level policies focus on executing these tasks within their local environments. We evaluate HABCODE in a challenging multi-agent resource allocation task and a cooperative navigation scenario. Empirical results demonstrate that HABCODE significantly outperforms state-of-the-art MARL algorithms, achieving higher cumulative rewards and improved coordination efficiency. Furthermore, analysis reveals that the learned attention mechanisms effectively filter out irrelevant information, leading to more robust and scalable performance, particularly as the number of agents increases and communication costs become more pronounced.",ai
"Machine learning approaches for Alzheimer's disease (AD) diagnosis face a fundamental challenges. Clinical assessments are expensive and invasive, leaving ground truth labels available for only a fraction of neuroimaging datasets. We introduce Multi view Adaptive Transport Clustering for Heterogeneous Alzheimer's Disease (MATCH-AD), a semi supervised framework that integrates deep representation learning, graph-based label propagation, and optimal transport theory to address this limitation. The framework leverages manifold structure in neuroimaging data to propagate diagnostic information from limited labeled samples to larger unlabeled populations, while using Wasserstein distances to quantify disease progression between cognitive states. Evaluated on nearly five thousand subjects from the National Alzheimer's Coordinating Center, encompassing structural MRI measurements from hundreds of brain regions, cerebrospinal fluid biomarkers, and clinical variables MATCHAD achieves near-perfect diagnostic accuracy despite ground truth labels for less than one-third of subjects. The framework substantially outperforms all baseline methods, achieving kappa indicating almost perfect agreement compared to weak agreement for the best baseline, a qualitative transformation in diagnostic reliability. Performance remains clinically useful even under severe label scarcity, and we provide theoretical convergence guarantees with proven bounds on label propagation error and transport stability. These results demonstrate that principled semi-supervised learning can unlock the diagnostic potential of the vast repositories of partially annotated neuroimaging data accumulating worldwide, substantially reducing annotation burden while maintaining accuracy suitable for clinical deployment.",human
"We address the problem of automating logical reasoning over complex knowledge graphs with incomplete information. Traditional methods often struggle with scalability and the inability to effectively handle uncertainty inherent in real-world datasets. This work introduces a novel neural-symbolic framework, Knowledge Graph Reasoning via Probabilistic Embedding Disentanglement (KG-PRED), which integrates differentiable reasoning with probabilistic knowledge graph embeddings. KG-PRED learns disentangled representations of entities and relations, explicitly modeling both deterministic and stochastic aspects of their interactions. Specifically, we employ variational autoencoders to capture the probabilistic nature of relation composition and entity connectivity, enabling the model to perform approximate Bayesian inference over possible reasoning paths. Furthermore, KG-PRED incorporates a differentiable path ranking mechanism, prioritizing paths based on both their learned embeddings and logical plausibility scores. Evaluated on benchmark datasets for knowledge graph completion and multi-hop reasoning, KG-PRED demonstrates significant improvements over existing state-of-the-art methods, particularly in scenarios with high levels of data incompleteness and logical complexity. Empirical results show that our approach achieves a mean reciprocal rank improvement of up to 15% compared to competitive baselines, highlighting the effectiveness of probabilistic disentanglement for robust and accurate automated reasoning.",ai
"We investigate the challenge of scalable automated reasoning over large-scale knowledge graphs (KGs) with complex logical constraints, specifically focusing on the task of knowledge graph completion. Current embedding-based methods often struggle to incorporate expressive logical rules, while symbolic reasoners face scalability issues when dealing with KGs containing millions of entities and relations. We propose a novel framework, Logic-Aware Graph Decomposition (LAGD), which combines the strengths of both paradigms. LAGD leverages a learned attention mechanism based on logical rule similarity to decompose the KG into smaller, more manageable subgraphs. Specifically, we first identify a set of high-confidence logical rules that hold within the KG. Then, for each target query, we utilize these rules to selectively attend to relevant portions of the KG, creating a focused subgraph. Finally, we employ a symbolic reasoner over the subgraph to efficiently infer new knowledge. We evaluate LAGD on several benchmark KG completion datasets, including FB15k-237 and WN18RR. Our experiments demonstrate that LAGD significantly improves both the accuracy and efficiency of KG completion compared to state-of-the-art embedding-based and symbolic reasoning approaches. In particular, LAGD achieves a relative improvement of up to 15% in Hits@10 while reducing inference time by an order of magnitude in certain scenarios. The results indicate that LAGD offers a promising path towards scalable and accurate automated reasoning over large, complex knowledge bases.",ai
"We address the exploration-exploitation dilemma in sparse-reward reinforcement learning environments, a persistent challenge that significantly hinders learning efficiency. Traditional exploration strategies often prove insufficient when rewards are infrequent, leading to prolonged periods of unproductive exploration. We introduce a novel hierarchical reinforcement learning framework, termed ""Temporal Abstraction with Learned Skills (TALS),"" which decomposes the problem into skill discovery and skill utilization phases. TALS employs a meta-controller operating at a higher temporal scale, responsible for selecting learned skills, and a lower-level controller executing the chosen skill for a specified duration. Crucially, the skill discovery phase leverages unsupervised learning techniques to identify temporally extended actions (skills) that reliably lead to state changes and exploration of previously unvisited states. The meta-controller is then trained via reinforcement learning to sequence these skills effectively, promoting efficient exploration and reward acquisition. Empirical evaluation across several challenging sparse-reward benchmark environments demonstrates that TALS significantly outperforms existing state-of-the-art methods, achieving higher cumulative rewards and faster learning rates. Ablation studies validate the contribution of each component of the TALS framework, highlighting the synergistic effect of temporal abstraction and learned skills in addressing the exploration challenge.",ai
"Advances in vision-language models (VLMs) have enabled effective cross-modality retrieval. However, when both text and images exist in the database, similarity scores would differ in scale by modality. This phenomenon, known as the modality gap, hinders accurate retrieval. Most existing studies address this issue with manually labeled data, e.g., by fine-tuning VLMs on them. In this work, we propose a similarity standardization approach with pseudo data construction. We first compute the mean and variance of the similarity scores between each query and its paired data in text or image modality. Using these modality-specific statistics, we standardize all similarity scores to compare on a common scale across modalities. These statistics are calculated from pseudo pairs, which are constructed by retrieving the text and image candidates with the highest cosine similarity to each query. We evaluate our method across seven VLMs using two multi-modal QA benchmarks (MMQA and WebQA), where each question requires retrieving either text or image data. Our experimental results show that our method significantly improves retrieval performance, achieving average Recall@20 gains of 64% on MMQA and 28% on WebQA when the query and the target data belong to different modalities. Compared to E5-V, which addresses the modality gap through image captioning, we confirm that our method more effectively bridges the modality gap.",human
"We address the problem of efficiently reasoning about large-scale knowledge graphs (KGs) with inherent incompleteness, a significant bottleneck in knowledge-intensive tasks. Traditional methods struggle with the computational complexity of inferring new facts and maintaining consistency in the presence of noisy or missing information. We propose a novel approach leveraging a hybrid symbolic-subsymbolic reasoning framework. Specifically, we integrate differentiable inductive logic programming (dILP) with a graph neural network (GNN) architecture. The GNN provides efficient embedding-based reasoning to identify candidate inferences, while the dILP component refines these inferences through logical rule learning and validation against existing KG constraints. The dILP component is trained using a differentiable loss function, enabling end-to-end optimization with the GNN. This allows the system to learn both factual knowledge encoded in the KG and logical reasoning patterns jointly. We evaluate our approach on standard KG completion benchmarks, including FB15k-237 and WN18RR. Our results demonstrate a significant improvement in link prediction accuracy compared to state-of-the-art embedding-based and symbolic methods. Furthermore, ablation studies reveal the complementary roles of the GNN and dILP components in achieving superior performance, highlighting the effectiveness of our hybrid reasoning paradigm.",ai
"We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of questionnaire presentation, prompt perturbations, and response generation methods. Our extensive evaluation ( million survey responses) shows that question structure and response generation methods have a significant impact on the alignment of generated survey responses with human answers, and can be obtained for a fraction of the compute cost. In addition, we offer a no-code user interface that allows researchers to set up robust experiments with LLMs without coding knowledge. We hope that QSTN will support the reproducibility and reliability of LLM-based research in the future.",human
"We investigate the problem of distributionally robust optimization (DRO) for machine learning models under Wasserstein ambiguity sets. Traditional DRO approaches, while providing robustness against distributional shifts, often suffer from computational intractability and may lead to overly conservative solutions, especially when dealing with high-dimensional data or limited training samples. To mitigate these limitations, we propose a novel method incorporating a regularized Wasserstein DRO formulation coupled with a data-driven approach for constructing the ambiguity set. Specifically, we employ a kernel density estimation technique with adaptive bandwidth selection to estimate the empirical distribution, subsequently using this estimate to define a refined ambiguity set centered around the training data. We further introduce a regularization term based on the Fisher divergence to control the complexity of the robust solution and improve generalization performance. We present a computationally efficient algorithm to solve the resulting optimization problem, leveraging duality theory and stochastic gradient descent. Empirical evaluations on benchmark datasets demonstrate that our proposed method achieves significant improvements in out-of-distribution robustness compared to existing DRO techniques and standard empirical risk minimization, while maintaining competitive performance on in-distribution data. The results highlight the efficacy of our approach in balancing robustness, generalization, and computational feasibility in machine learning applications susceptible to distributional uncertainties.",ai
"Graph Neural Networks (GNNs) have demonstrated considerable efficacy in learning representations for graph-structured data across diverse domains. However, many existing GNN architectures struggle to effectively capture long-range dependencies and global structural information present within larger, more complex graphs. This limitation hinders performance on tasks requiring reasoning over distant relationships and holistic graph properties. To address this, we propose a novel GNN architecture, the Global-Aware Graph Neural Network (GAGNN), which integrates a learnable global graph representation into the message-passing mechanism. GAGNN employs an attention mechanism to aggregate node-specific information into a compact global embedding. This global embedding is then incorporated as a contextual bias during the message-passing phase, enabling nodes to consider the global graph structure when updating their representations. We evaluate GAGNN on a suite of benchmark graph classification and node classification datasets, including those with sparse connectivity and large graph diameters. Experimental results demonstrate that GAGNN consistently outperforms state-of-the-art GNN models, achieving significant improvements in accuracy, particularly on datasets requiring long-range dependency modeling. Ablation studies confirm the importance of the global embedding and the attention mechanism in capturing salient global graph features. The proposed GAGNN offers a promising approach for enhancing GNN performance in scenarios characterized by complex graph structures and long-range dependencies.",ai
"We address the challenge of sample inefficiency in reinforcement learning (RL) within sparse reward environments, specifically focusing on scenarios where successful task completion requires precise sequences of actions. Traditional RL algorithms often struggle to learn effectively under such conditions due to the infrequency of reward signals. To mitigate this, we introduce a novel hierarchical reinforcement learning framework incorporating a learned skill proposal mechanism. This mechanism leverages a generative model, trained offline on a small set of expert demonstrations, to propose promising skill sequences for the agent to explore. The high-level controller then selects and executes these proposed skills, while a low-level controller optimizes the parameters of each skill. We demonstrate the efficacy of our approach on a simulated robotic manipulation task requiring precise object placement. Experimental results indicate that our hierarchical framework achieves significantly higher success rates and faster learning convergence compared to both flat RL algorithms and alternative hierarchical methods relying on hand-engineered skills. Furthermore, we analyze the impact of demonstration set size on the performance of the skill proposal mechanism, revealing a trade-off between exploration guidance and potential bias. Our findings suggest that the proposed framework provides a robust and sample-efficient approach to learning complex tasks in sparse reward settings.",ai
"The accurate and efficient analysis of medical images remains a critical challenge in clinical diagnostics and treatment planning. Existing methods often suffer from limitations in their ability to effectively segment complex anatomical structures and detect subtle pathological features, hindering timely and accurate diagnoses. This work introduces a novel approach leveraging convolutional neural networks (CNNs) combined with attention mechanisms for improved medical image analysis. Specifically, we propose an attention-guided multi-scale feature fusion (AMFF) network that adaptively integrates features from different convolutional layers, emphasizing salient regions while suppressing irrelevant background noise. The attention mechanism is designed to learn spatial dependencies within the image, enabling the model to focus on diagnostically relevant areas. We evaluated the performance of AMFF on two benchmark datasets: the LIDC-IDRI lung nodule dataset and the ISIC 2018 skin lesion dataset. Experimental results demonstrate that AMFF achieves superior segmentation and classification accuracy compared to state-of-the-art methods, with an average Dice score improvement of 3.2% on lung nodule segmentation and a 2.1% increase in AUC for skin lesion classification. Furthermore, visualization of the attention maps reveals that the model effectively highlights regions corresponding to nodules and lesions, suggesting improved interpretability and diagnostic potential.",ai
"We address the problem of distributionally robust optimization (DRO) in machine learning models subjected to adversarial perturbations of the input data. Specifically, we consider a scenario where the underlying data distribution is unknown but belongs to an ambiguity set centered around an empirical distribution. Existing DRO approaches often exhibit computational intractability or rely on overly conservative ambiguity sets, leading to suboptimal performance. We propose a novel DRO framework based on a refined Wasserstein ambiguity set defined by a data-dependent radius, constructed using a concentration inequality that leverages empirical Rademacher complexity. This allows for tighter control over the uncertainty quantification, adapting the robustness level to the complexity of the underlying data distribution. Furthermore, we develop a computationally efficient algorithm to solve the resulting minimax optimization problem, utilizing a primal-dual reformulation and stochastic gradient descent. Experimental results on benchmark image classification datasets, including CIFAR-10 and ImageNet, demonstrate that our proposed method achieves superior robust accuracy compared to state-of-the-art DRO algorithms and empirical risk minimization under both white-box and black-box adversarial attacks. The improvements are particularly significant in high-dimensional input spaces, showcasing the benefits of our data-dependent ambiguity set.",ai
"We address the challenge of learning decentralized control policies for cooperative multi-agent systems (MAS) under partial observability and communication constraints. Specifically, we consider settings where agents must coordinate to achieve a common goal, yet each agent only has access to local observations and can only communicate with a limited subset of other agents. Existing approaches often struggle with scalability and the exploration of effective communication strategies in such complex environments. We propose a novel framework, CommNet-GNN, which integrates a Graph Neural Network (GNN) with a communication-augmented policy gradient algorithm. The GNN enables agents to learn adaptive communication topologies, allowing for selective information aggregation based on the relevance of other agents' states. Furthermore, we introduce a differentiable message compression mechanism to mitigate bandwidth limitations. Empirical evaluations on benchmark cooperative navigation and cooperative transport tasks demonstrate that CommNet-GNN significantly outperforms state-of-the-art decentralized reinforcement learning methods. Notably, our approach achieves higher task completion rates, demonstrates improved communication efficiency, and exhibits superior generalization capabilities to varying team sizes and communication topologies. These results highlight the efficacy of leveraging GNNs for adaptive communication learning in decentralized MAS, paving the way for more robust and scalable solutions in real-world collaborative scenarios.",ai
"Bilingual mathematical problem solving needs a clear link between language reasoning and symbolic calculation. Large language models often handle language well but are weak in accurate computation. This paper presents HERALD (Hybrid Ensemble Reasoning with Adaptive Learning and Distillation), a framework that joins reasoning and calculation using NuminaMath-7B-TIR, GPT-4o, and Mistral-7B. HERALD uses adaptive routing, tool-based reinforcement learning, and knowledge distillation to connect different reasoning paths. Confidence calibration keeps weighting stable, and dual-path checking keeps results correct. Reinforcement learning controls tool use to cut redundancy, and distillation lowers delay without hurting accuracy. The system shows that combining symbolic checking, adaptive ensembles, and bilingual fine-tuning helps achieve both fluent reasoning and precise calculation. HERALD offers a practical solution for multilingual mathematical reasoning with better accuracy, stability, and clarity.",human
"Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.",human
"Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.",human
"We investigate the problem of distributionally robust optimization (DRO) under moment ambiguity, specifically focusing on data corrupted by adversarial noise. Existing methods often exhibit computational intractability or poor performance in high-dimensional settings due to the exponential growth in complexity with the number of uncertain parameters. To address this, we propose a novel DRO framework leveraging a smoothed Wasserstein distance to construct the ambiguity set. This allows us to derive tractable reformulations of the robust optimization problem as a convex program, enabling efficient computation even with high-dimensional data. Our approach incorporates a regularization term that penalizes deviations from the empirical distribution, promoting generalization and mitigating overfitting to adversarial perturbations. We provide theoretical guarantees on the out-of-sample performance of our proposed method, bounding the generalization error under specific conditions. Empirical evaluations on synthetic and real-world datasets demonstrate that our approach achieves state-of-the-art performance in terms of both robustness and accuracy compared to existing DRO and robust optimization algorithms. Furthermore, our method exhibits significantly improved computational efficiency, particularly in high-dimensional settings, making it a practical solution for real-world applications.",ai
"Existing two-sample testing techniques, particularly those based on choosing a kernel for the Maximum Mean Discrepancy (MMD), often assume equal sample sizes from the two distributions. Applying these methods in practice can require discarding valuable data, unnecessarily reducing test power. We address this long-standing limitation by extending the theory of generalized U-statistics and applying it to the usual MMD estimator, resulting in new characterization of the asymptotic distributions of the MMD estimator with unequal sample sizes (particularly outside the proportional regimes required by previous partial results). This generalization also provides a new criterion for optimizing the power of an MMD test with unequal sample sizes. Our approach preserves all available data, enhancing test accuracy and applicability in realistic settings. Along the way, we give much cleaner characterizations of the variance of MMD estimators, revealing something that might be surprising to those in the area: while zero MMD implies a degenerate estimator, it is sometimes possible to have a degenerate estimator with nonzero MMD as well; we give a construction and a proof that it does not happen in common situations.",human
"Video Large Language Models (VLLMs) unlock world-knowledge-aware video understanding through pretraining on internet-scale data and have already shown promise on tasks such as movie analysis and video question answering. However, deploying VLLMs for downstream tasks such as video recommendation remains challenging, since real systems require multi-video inputs, lightweight backbones, low-latency sequential inference, and rapid response. In practice, (1) decode-only generation yields high latency for sequential inference, (2) typical interfaces do not support multi-video inputs, and (3) constraining outputs to language discards fine-grained visual details that matter for downstream vision tasks. We argue that these limitations stem from the absence of a representation that preserves pixel-level detail while leveraging world knowledge. We present LinkedOut, a representation that extracts VLLM world knowledge directly from video to enable fast inference, supports multi-video histories, and removes the language bottleneck. LinkedOut extracts semantically grounded, knowledge-aware tokens from raw frames using VLLMs, guided by promptable queries and optional auxiliary modalities. We introduce a cross-layer knowledge fusion MoE that selects the appropriate level of abstraction from the rich VLLM features, enabling personalized, interpretable, and low-latency recommendation. To our knowledge, LinkedOut is the first VLLM-based video recommendation method that operates on raw frames without handcrafted labels, achieving state-of-the-art results on standard benchmarks. Interpretability studies and ablations confirm the benefits of layer diversity and layer-wise fusion, pointing to a practical path that fully leverages VLLM world-knowledge priors and visual reasoning for downstream vision tasks such as recommendation.",human
"Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.",human
"We introduce the Continuous Edit Distance (CED), a geodesic and elastic distance for time-varying persistence diagrams (TVPDs). The CED extends edit-distance ideas to TVPDs by combining local substitution costs with penalized deletions/insertions, controlled by two parameters: \(Î±\) (trade-off between temporal misalignment and diagram discrepancy) and \(Î²\) (gap penalty). We also provide an explicit construction of CED-geodesics. Building on these ingredients, we present two practical barycenter solvers, one stochastic and one greedy, that monotonically decrease the CED Frechet energy. Empirically, the CED is robust to additive perturbations (both temporal and spatial), recovers temporal shifts, and supports temporal pattern search. On real-life datasets, the CED achieves clustering performance comparable or better than standard elastic dissimilarities, while our clustering based on CED-barycenters yields superior classification results. Overall, the CED equips TVPD analysis with a principled distance, interpretable geodesics, and practical barycenters, enabling alignment, comparison, averaging, and clustering directly in the space of TVPDs. A C++ implementation is provided for reproducibility at the following address https://github.com/sebastien-tchitchek/ContinuousEditDistance.",human
"We address the challenge of robust causal effect estimation in observational studies where unmeasured confounding may be present. Existing instrumental variable (IV) methods often suffer from weak instrument bias and sensitivity to model misspecification. To mitigate these limitations, we propose a novel approach, Deconfounded Direct Effect Estimation (D3E), which leverages a learned representation of the observed covariates to identify a proxy for the direct effect of the treatment on the outcome, even in the presence of unmeasured confounding. D3E employs a variational autoencoder (VAE) to learn a latent representation of the covariates, subsequently using this representation within a doubly robust estimation framework to estimate the average treatment effect on the treated (ATT). Crucially, D3E incorporates identification constraints to ensure the learned latent representation is plausibly deconfounded. We evaluate D3E on both synthetic datasets with varying degrees of unmeasured confounding and real-world benchmark datasets for causal inference. Our results demonstrate that D3E consistently outperforms state-of-the-art IV methods and other robust causal inference techniques, particularly in scenarios with weak instruments and non-linear relationships. The improved performance is attributed to the VAE's ability to capture complex dependencies within the observed covariates and the doubly robust estimation framework's resilience to model misspecification.",ai
"Detecting critical transitions in complex, noisy time-series data is a fundamental challenge across science and engineering. Such transitions may be anticipated by the emergence of a low-dimensional order parameter, whose signature is often masked by high-amplitude stochastic variability. Standard contrastive learning approaches based on deep neural networks, while promising for detecting critical transitions, are often overparameterized and sensitive to irrelevant noise, leading to inaccurate identification of critical points. To address these limitations, we propose a neural network architecture, constructed using singular value decomposition technique, together with a strictly semi-orthogonality-constrained training algorithm, to enhance the performance of traditional contrastive learning. Extensive experiments demonstrate that the proposed method matches the performance of traditional contrastive learning techniques in identifying critical transitions, yet is considerably more lightweight and markedly more resistant to noise.",human
"We investigate the problem of representing structured knowledge in a manner that facilitates both efficient reasoning and robust generalization in complex, relational domains. Existing approaches often struggle to simultaneously achieve these goals, exhibiting limitations in handling novel compositions of known facts or scaling to large knowledge bases. To address this, we propose a novel Knowledge Representation Network (KRN) architecture that integrates differentiable symbolic reasoning with neural embedding learning. The KRN leverages a graph neural network to encode entities and relations into latent embeddings, which are subsequently utilized within a differentiable rule engine to perform logical inference. Specifically, we introduce a compositional scoring function that evaluates the satisfiability of logical rules by aggregating evidence from the embedded entity and relation representations. The training objective combines a knowledge base completion task with a regularization term promoting the discovery of sparse, interpretable rules. Empirical evaluations on standard knowledge graph benchmarks, including FB15k-237 and WN18RR, demonstrate that the KRN achieves state-of-the-art performance in link prediction while simultaneously uncovering underlying logical relationships within the data. Furthermore, ablation studies reveal that the learned rule set generalizes effectively to unseen entity pairs and relational contexts, suggesting a promising avenue for building robust and explainable knowledge representation systems.",ai
"Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. While current detection methods leverage embedding similarity and natural language inference (NLI), their reliability in safety-critical settings remains unproven. We apply conformal prediction to RAG hallucination detection, transforming heuristic scores into decision sets with finite-sample coverage guarantees (1-alpha). Using calibration sets of n=600, we demonstrate a fundamental dichotomy: on synthetic hallucinations (Natural Questions), embedding methods achieve 95% coverage with 0% False Positive Rate (FPR). However, on real hallucinations from RLHF-aligned models (HaluEval), the same methods fail catastrophically, yielding 100% FPR at target coverage. We analyze this failure through the lens of distributional tails, showing that while NLI models achieve acceptable AUC (0.81), the ""hardest"" hallucinations are semantically indistinguishable from faithful responses, forcing conformal thresholds to reject nearly all valid outputs. Crucially, GPT-4 as a judge achieves 7% FPR (95% CI:[3.4%, 13.7%]) on the same data, proving the task is solvable via reasoning but opaque to surface-level semantics--a phenomenon we term the ""Semantic Illusion.""",human
"We investigate the problem of distributionally robust optimization (DRO) with moment-based ambiguity sets, focusing on mitigating the impact of outliers and adversarial data corruptions in statistical learning. Traditional DRO formulations often exhibit sensitivity to the choice of moment constraints, potentially leading to overly conservative solutions or poor out-of-sample performance. To address this, we propose a novel adaptive DRO framework that dynamically adjusts the ambiguity set based on empirical data characteristics. Our method leverages a data-driven estimation of the support of the underlying data distribution and incorporates this information into the moment constraints, effectively trimming outliers and restricting the ambiguity set to a more plausible region. We derive theoretical guarantees on the generalization performance of our adaptive DRO approach, demonstrating improved robustness against adversarial perturbations compared to standard DRO formulations with fixed moment constraints. Furthermore, we present empirical evaluations on various benchmark datasets, showcasing the efficacy of our method in enhancing the robustness and predictive accuracy of machine learning models in the presence of data contamination. Our results demonstrate a significant improvement in out-of-sample performance and a reduction in sensitivity to hyperparameter tuning compared to existing robust optimization techniques.",ai
"This paper addresses the problem of distributional robustness in natural language processing (NLP) models, specifically concerning sensitivity to adversarial perturbations in input text. While standard NLP models often achieve high accuracy on benchmark datasets, their performance degrades significantly under even minor adversarial attacks. We propose a novel robust optimization framework, Augmented Contextual Encoding with Min-Max Adversarial Training (ACE-MMAT), to mitigate this vulnerability. ACE-MMAT incorporates an augmented contextual encoding layer that generates diverse, semantically similar variations of the input text. These variations are then utilized within a min-max adversarial training scheme. Specifically, the inner maximization problem seeks to identify the most deleterious perturbation from the augmented context, while the outer minimization problem optimizes the model to be robust against this worst-case perturbation. We evaluate ACE-MMAT on sentiment analysis and text classification tasks, comparing its performance against standard training and existing adversarial training methods. Our results demonstrate that ACE-MMAT significantly improves robustness against both word-level and character-level adversarial attacks, while maintaining competitive performance on clean data. Ablation studies highlight the individual contributions of the augmented contextual encoding and min-max training components. These findings indicate the efficacy of ACE-MMAT as a practical and effective approach for improving the distributional robustness of NLP models.",ai
"We address the problem of robust commonsense reasoning in question answering, focusing on scenarios requiring implicit knowledge beyond readily available facts. Many existing systems struggle with questions demanding nuanced understanding of causality, physical properties, and social conventions. We propose a novel approach, the Knowledge-Augmented Reasoning Network (KARN), which integrates external knowledge graph embeddings with a transformer-based architecture. KARN leverages a knowledge graph populated with commonsense assertions to extract relevant entities and relations pertaining to the question. These extracted elements are then encoded as embeddings and dynamically fused with the contextualized word embeddings derived from the transformer. The resulting fused representation is utilized to predict the answer span. Our experimental evaluation on the CommonsenseQA and OpenBookQA datasets demonstrates that KARN significantly outperforms several state-of-the-art baselines. Specifically, KARN achieves a 5% absolute improvement on CommonsenseQA and a 3% absolute improvement on OpenBookQA, showcasing its enhanced capability to leverage commonsense knowledge for improved reasoning. Furthermore, ablation studies reveal the importance of both the knowledge graph embeddings and the dynamic fusion mechanism in achieving these results. These findings suggest that explicit integration of commonsense knowledge into neural reasoning models leads to improved robustness and accuracy in challenging question answering tasks.",ai
"The adsorption energy serves as a crucial descriptor for the large-scale screening of catalysts. Nevertheless, the limited distribution of training data for the extensively utilised machine learning interatomic potential (MLIP), predominantly sourced from near-equilibrium structures, results in unreliable adsorption structures and consequent adsorption energy predictions. In this context, we present DBCata, a deep generative model that integrates a periodic Brownian-bridge framework with an equivariant graph neural network to establish a low-dimensional transition manifold between unrelaxed and DFT-relaxed structures, without requiring explicit energy or force information. Upon training, DBCata effectively generates high-fidelity adsorption geometries, achieving an interatomic distance mean absolute error (DMAE) of 0.035 \textÃ… on the Catalysis-Hub dataset, which is nearly three times superior to that of the current state-of-the-art machine learning potential models. Moreover, the corresponding DFT accuracy can be improved within 0.1 eV in 94\% of instances by identifying and refining anomalous predictions through a hybrid chemical-heuristic and self-supervised outlier detection approach. We demonstrate that the remarkable performance of DBCata facilitates accelerated high-throughput computational screening for efficient alloy catalysts in the oxygen reduction reaction, highlighting the potential of DBCata as a powerful tool for catalyst design and optimisation.",human
"Objectives: To evaluate large language model (LLM) performance on pharmacy licensure-style question-answering (QA) tasks and develop an external knowledge integration method to improve their accuracy. Methods: We benchmarked eleven existing LLMs with varying parameter sizes (8 billion to 70+ billion) using a 141-question pharmacy dataset. We measured baseline accuracy for each model without modification. We then developed a three-step retrieval-augmented generation (RAG) pipeline, DrugRAG, that retrieves structured drug knowledge from validated sources and augments model prompts with evidence-based context. This pipeline operates externally to the models, requiring no changes to model architecture or parameters. Results: Baseline accuracy ranged from 46% to 92%, with GPT-5 (92%) and o3 (89%) achieving the highest scores. Models with fewer than 8 billion parameters scored below 50%. DrugRAG improved accuracy across all tested models, with gains ranging from 7 to 21 percentage points (e.g., Gemma 3 27B: 61% to 71%, Llama 3.1 8B: 46% to 67%) on the 141-item benchmark. Conclusion: We demonstrate that external structured drug knowledge integration through DrugRAG measurably improves LLM accuracy on pharmacy tasks without modifying the underlying models. This approach provides a practical pipeline for enhancing pharmacy-focused AI applications with evidence-based information.",human
"Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.",human
"Recent advancements in natural language processing have demonstrated remarkable capabilities in generating coherent text and answering complex questions. However, a persistent limitation lies in the faithful and comprehensive representation of structured knowledge extracted from unstructured textual data. This work addresses the problem of effectively embedding knowledge graphs within a neural network architecture to improve knowledge-aware reasoning. We propose a novel approach, Knowledge-Augmented Latent Space Embedding (KALSE), which utilizes a relational graph convolutional network to encode knowledge graph entities and relations into a latent space, subsequently integrated with transformer-based language models. KALSE introduces a dynamic attention mechanism that modulates the influence of knowledge embeddings based on the context of the input text. This allows the model to selectively attend to relevant knowledge components during reasoning. We evaluate KALSE on several benchmark datasets for knowledge graph completion and question answering tasks, including FB15k-237 and WebQuestionsSP. Experimental results demonstrate that KALSE outperforms existing state-of-the-art methods in terms of accuracy and F1-score, exhibiting a significant improvement in capturing long-range dependencies and resolving ambiguous queries. The ablation studies further validate the effectiveness of the dynamic attention mechanism in enhancing the model's ability to leverage relevant knowledge.",ai
"We address the problem of identifying causal effects in the presence of unobserved confounding, specifically focusing on scenarios where instrumental variables (IVs) are weak or unavailable. Traditional IV methods often suffer from significant bias and instability in such settings. We propose a novel two-stage approach combining residual balancing and variational inference to estimate average treatment effects (ATE). In the first stage, we employ a residual balancing technique conditioned on observed covariates, aiming to mitigate the effects of residual confounding by ensuring that the distributions of residuals from outcome and treatment models are balanced. The second stage utilizes a variational autoencoder (VAE) framework to learn latent representations of the data, effectively capturing complex relationships and facilitating the imputation of potential outcomes under different treatment regimes. We derive theoretical identifiability conditions under which our approach consistently estimates the ATE. Empirical evaluations on synthetic datasets and a semi-synthetic application using real-world healthcare data demonstrate that our method outperforms existing approaches in terms of bias, variance, and robustness to weak confounding and model misspecification. Specifically, we observe a reduction in ATE estimation error of up to 40% compared to competing methods in scenarios with weak instrumental variables. Our findings highlight the potential of leveraging residual balancing and variational inference for robust causal inference in challenging observational settings.",ai
"We consider the problem of auditing black-box large language models (LLMs) to ensure they behave reliably when deployed in production settings, particularly in high-stakes domains such as legal, medical, and regulatory compliance. Existing approaches for LLM auditing often focus on isolated aspects of model behavior, such as detecting specific biases or evaluating fairness. We are interested in a more general question -- can we understand how the outputs of black-box LLMs depend on each input token? There is a critical need to have such tools in real-world applications that rely on inaccessible API endpoints to language models. However, this is a highly non-trivial problem, as LLMs are stochastic functions (i.e. two outputs will be different by chance), while computing prompt-level gradients to approximate input sensitivity is infeasible. To address this, we propose Distribution-Based Sensitivity Analysis (DBSA), a lightweight model-agnostic procedure to evaluate the sensitivity of the output of a language model for each input token, without making any distributional assumptions about the LLM. DBSA is developed as a practical tool for practitioners, enabling quick, plug-and-play visual exploration of LLMs reliance on specific input tokens. Through illustrative examples, we demonstrate how DBSA can enable users to inspect LLM inputs and find sensitivities that may be overlooked by existing LLM interpretability methods.",human
"Existing intelligent sports analysis systems mainly focus on ""scoring and visualization,"" often lacking automatic performance diagnosis and interpretable training guidance. Recent advances in Large Language Models (LLMs) and motion analysis techniques provide new opportunities to address the above limitations. In this paper, we propose SportsGPT, an LLM-driven framework for interpretable sports motion assessment and training guidance, which establishes a closed loop from motion time-series input to professional training guidance. First, given a set of high-quality target models, we introduce MotionDTW, a two-stage time series alignment algorithm designed for accurate keyframe extraction from skeleton-based motion sequences. Subsequently, we design a Knowledge-based Interpretable Sports Motion Assessment Model (KISMAM) to obtain a set of interpretable assessment metrics (e.g., insufficient extension) by contrasting the keyframes with the target models. Finally, we propose SportsRAG, a RAG-based training guidance model built upon Qwen3. Leveraging a 6B-token knowledge base, it prompts the LLM to generate professional training guidance by retrieving domain-specific QA pairs. Experimental results demonstrate that MotionDTW significantly outperforms traditional methods with lower temporal error and higher IoU scores. Furthermore, ablation studies validate the KISMAM and SportsRAG, confirming that SportsGPT surpasses general LLMs in diagnostic accuracy and professionalism.",human
"We address the challenge of enhancing the logical consistency and deductive power of large language models (LLMs) in complex, multi-hop reasoning scenarios. LLMs often struggle with maintaining coherence across long inference chains, leading to logical fallacies and incorrect conclusions. Our approach, termed ""Constrained Reasoning with Verification and Revision"" (CRVR), integrates symbolic reasoning techniques into the LLM workflow. CRVR first leverages the LLM to generate a sequence of intermediate reasoning steps towards a conclusion. Each step is then parsed and translated into a formal logical representation within a knowledge base. A theorem prover is subsequently employed to verify the validity of each inference and identify potential inconsistencies. Detected inconsistencies trigger a revision module, which prompts the LLM to regenerate the erroneous reasoning step under constraints derived from the knowledge base and the theorem prover's output. We evaluate CRVR on a suite of challenging benchmark datasets requiring multi-hop logical deduction and commonsense reasoning. Experimental results demonstrate that CRVR significantly improves the logical soundness and accuracy of LLM reasoning, achieving an average accuracy gain of 15-20% compared to baseline LLMs and existing prompting techniques. Furthermore, ablation studies confirm the efficacy of both the verification and revision components in improving overall performance.",ai
"The structure of topology underpins much of the research on performance and robustness, yet available topology data are typically scarce, necessitating the generation of synthetic graphs with desired properties for testing or release. Prior diffusion-based approaches either embed conditions into the diffusion model, requiring retraining for each attribute and hindering real-time applicability, or use classifier-based guidance post-training, which does not account for topology scale and practical constraints. In this paper, we show from a discrete perspective that gradients from a pre-trained graph-level classifier can be incorporated into the discrete reverse diffusion posterior to steer generation toward specified structural properties. Based on this insight, we propose Classifier-guided Conditional Topology Generation with Persistent Homology (CoPHo), which builds a persistent homology filtration over intermediate graphs and interprets features as guidance signals that steer generation toward the desired properties at each denoising step. Experiments on four generic/network datasets demonstrate that CoPHo outperforms existing methods at matching target metrics, and we further validate its transferability on the QM9 molecular dataset.",human
"### Abstract Precise segmentation of anatomical structures in medical images is crucial for diagnosis, treatment planning, and surgical navigation. Manual segmentation is a time-consuming and subjective process, hindering efficient clinical workflows. This study addresses the problem of automated and accurate segmentation of multiple organs in abdominal computed tomography (CT) scans. We propose a novel deep learning framework based on a cascaded U-Net architecture incorporating attention mechanisms and spatial context aggregation. The initial U-Net stage performs coarse segmentation, followed by a refined segmentation stage focusing on boundary delineation. Attention modules are integrated within the U-Net to enhance the network's focus on relevant anatomical features, while spatial context aggregation modules utilize dilated convolutions to capture long-range dependencies. The proposed method was evaluated on a publicly available abdominal multi-organ segmentation dataset, achieving a mean Dice Similarity Coefficient (DSC) of 0.88, significantly outperforming existing state-of-the-art methods by an average of 3% across all organs. Furthermore, the framework demonstrates robust performance in segmenting organs with varying sizes and shapes, suggesting its potential for clinical application in diverse patient populations. The improved segmentation accuracy achieved by our approach facilitates more reliable quantitative image analysis and enhances the efficiency of clinical workflows.",ai
"We investigate the problem of decentralized learning in multi-agent systems where agents possess heterogeneous and non-stationary local data distributions. Existing approaches often rely on strong assumptions such as data homogeneity or periodic global synchronization, which are frequently violated in real-world scenarios. To address this challenge, we propose a novel distributed learning algorithm, termed ""Adaptive Consensus via Kernel Embedding"" (ACKE), that leverages kernel embedding techniques to implicitly align local data distributions without explicit data sharing. ACKE operates by each agent locally training a model and then broadcasting a kernel embedding representation of its local data. These embeddings are subsequently used to compute a consensus direction that guides the agent's model update. This approach implicitly minimizes the divergence between local and global data distributions. We provide theoretical convergence guarantees for ACKE under mild assumptions on the data generating process and network topology. Empirical evaluations on both synthetic and real-world datasets demonstrate that ACKE significantly outperforms state-of-the-art decentralized learning algorithms, particularly in highly heterogeneous and non-stationary environments. We observe substantial improvements in convergence speed and final model accuracy compared to baseline methods such as D-PSGD and FedAvg, while maintaining communication efficiency. Our findings suggest that kernel embedding provides a powerful and practical tool for addressing data heterogeneity in decentralized multi-agent learning systems.",ai
"Diffusion models have emerged as powerful priors for image editing tasks such as inpainting and local modification, where the objective is to generate realistic content that remains consistent with observed regions. In particular, zero-shot approaches that leverage a pretrained diffusion model, without any retraining, have been shown to achieve highly effective reconstructions. However, state-of-the-art zero-shot methods typically rely on a sequence of surrogate likelihood functions, whose scores are used as proxies for the ideal score. This procedure however requires vector-Jacobian products through the denoiser at every reverse step, introducing significant memory and runtime overhead. To address this issue, we propose a new likelihood surrogate that yields simple and efficient to sample Gaussian posterior transitions, sidestepping the backpropagation through the denoiser network. Our extensive experiments show that our method achieves strong observation consistency compared with fine-tuned baselines and produces coherent, high-quality reconstructions, all while significantly reducing inference cost. Code is available at https://github.com/YazidJanati/ding.",human
"### Abstract Knowledge representation (KR) systems often struggle to effectively integrate diverse types of information, particularly when dealing with incomplete or inconsistent data. This paper addresses the challenge of constructing a unified knowledge graph from heterogeneous sources exhibiting varying levels of certainty and logical coherence. We propose a novel probabilistic knowledge representation framework, ProbLog-Extend (PLE), which extends ProbLog with mechanisms for explicit representation of epistemic uncertainty and belief revision. PLE allows for encoding both probabilistic dependencies between facts and logical constraints that may be violated under uncertainty, employing a soft-logic inference mechanism based on weighted model counting. Unlike traditional approaches that typically rely on ad-hoc conflict resolution strategies, PLE leverages a principled probabilistic grounding to resolve inconsistencies. We evaluate PLE on a benchmark dataset comprising scientific publications and expert opinions regarding drug interactions, demonstrating its ability to construct a more accurate and coherent knowledge graph compared to baseline methods that utilize deterministic or purely probabilistic KR approaches. Specifically, PLE achieves a 15% improvement in link prediction accuracy for previously unseen interactions and a significant reduction in logical contradictions within the generated knowledge graph, highlighting its effectiveness in handling uncertain and conflicting information.",ai
"We address the challenge of coordinating policies in multi-agent reinforcement learning (MARL) systems where agents exhibit diverse and potentially conflicting objectives. Specifically, we focus on scenarios where a centralized critic is unavailable, necessitating decentralized execution based on local observations. A key problem is the credit assignment challenge, exacerbated by the non-stationarity induced by other learning agents. We introduce a novel method, Decentralized Implicit Policy Optimization (DIPO), which leverages implicit differentiation to optimize individual agent policies while implicitly accounting for the anticipated responses of other agents. DIPO utilizes a shared value network to approximate the global reward structure, facilitating more accurate credit assignment through counterfactual reasoning on each agent's actions. The implicit differentiation step stabilizes learning by mitigating the effects of policy drift. We evaluate DIPO on a suite of challenging cooperative and competitive MARL benchmarks, including StarCraft II micromanagement and cooperative navigation tasks. Our results demonstrate that DIPO significantly outperforms state-of-the-art decentralized MARL algorithms, achieving higher team rewards and exhibiting improved coordination strategies. Furthermore, DIPO demonstrates enhanced robustness to changes in agent population size and environmental noise, highlighting its adaptability and practical applicability.",ai
"Recent advances in explainable recommendations have explored the integration of language models to analyze natural language rationales for user-item interactions. Despite their potential, existing methods often rely on ID-based representations that obscure semantic meaning and impose structural constraints on language models, thereby limiting their applicability in open-ended scenarios. These challenges are intensified by the complex nature of real-world interactions, where diverse user intents are entangled and collaborative signals rarely align with linguistic semantics. To overcome these limitations, we propose BEAT, a unified and transferable framework that tokenizes user and item behaviors into discrete, interpretable sequences. We construct a behavior vocabulary via a vector-quantized autoencoding process that disentangles macro-level interests and micro-level intentions from graph-based representations. We then introduce multi-level semantic supervision to bridge the gap between behavioral signals and language space. A semantic alignment regularization mechanism is designed to embed behavior tokens directly into the input space of frozen language models. Experiments on three public datasets show that BEAT improves zero-shot recommendation performance while generating coherent and informative explanations. Further analysis demonstrates that our behavior tokens capture fine-grained semantics and offer a plug-and-play interface for integrating complex behavior patterns into large language models.",human
"We address the problem of automated lesion detection and characterization in multi-modal medical imaging, specifically focusing on distinguishing between benign and malignant pulmonary nodules in computed tomography (CT) and positron emission tomography (PET) scans. Manual analysis of these scans is time-consuming and prone to inter-observer variability, motivating the development of robust and accurate computational methods. Our proposed approach leverages a deep convolutional neural network (CNN) architecture modified with attention mechanisms to selectively focus on salient image features relevant to nodule classification. The network is trained on a large, retrospectively collected dataset of thoracic CT and PET images, incorporating both pixel-level data and associated patient metadata. We further introduce a novel fusion strategy that integrates information from both imaging modalities at multiple layers of the network to improve discriminative power. Experimental results demonstrate that our method achieves state-of-the-art performance in pulmonary nodule classification, surpassing existing methods with an AUC score of 0.92 on an independent validation set. Furthermore, ablation studies confirm the effectiveness of the attention mechanism and the multi-modal fusion strategy in enhancing diagnostic accuracy. These findings suggest that our approach has significant potential for improving the efficiency and reliability of pulmonary nodule diagnosis in clinical practice.",ai
"We address the challenge of efficient exploration in sparse-reward reinforcement learning environments. Such environments present a significant hurdle for traditional reinforcement learning algorithms, often requiring prohibitively long training times to discover rewarding states. Our approach leverages a novel intrinsic motivation mechanism based on predictive coding, specifically focusing on prediction error. This intrinsic reward signal, dynamically scaled by an entropy-based measure of state novelty, encourages the agent to explore regions of the state space where its predictions are most inaccurate and unexplored. We implement this method within a deep reinforcement learning framework using a modified Proximal Policy Optimization (PPO) algorithm. Empirical evaluations were conducted on a suite of challenging benchmark environments, including the Montezuma's Revenge and Pitfall! Atari 2600 games. Results demonstrate a significant improvement in sample efficiency and overall performance compared to standard PPO and other state-of-the-art exploration strategies. Specifically, our agent achieved a substantial increase in episodic reward and faster learning convergence, highlighting the effectiveness of our intrinsic motivation mechanism in facilitating efficient exploration in sparse-reward environments. The proposed method demonstrates promise for tackling complex reinforcement learning tasks requiring extensive exploration.",ai
"Modern LLM applications such as deep-research assistants, coding agents, and Retrieval-Augmented Generation (RAG) systems, repeatedly process long prompt histories containing shared document or code chunks, creating significant pressure on the Key Value (KV) cache, which must operate within limited memory while sustaining high throughput and low latency. Prefix caching partially alleviates some of these costs by reusing KV cache for previously processed tokens, but limited by strict prefix matching. Position-independent caching (PIC) enables chunk-level reuse at arbitrary positions, but requires selective recomputation and positional-encoding (PE) adjustments. However, because these operations vary across queries, KV for the same chunk diverges across requests. Moreover, without page alignment, chunk KV layouts diverge in memory, preventing page sharing. These issues result in only modest HBM savings even when many requests reuse the same content. We present MEPIC, a memory-efficient PIC system that enables chunk KV reuse across positions, requests, and batches. MEPIC aligns chunk KV to paged storage, shifts recomputation from token- to block-level so only the first block is request-specific, removes positional encodings via Rotary Position Embedding (RoPE) fusion in the attention kernel, and makes remaining blocks fully shareable. These techniques eliminate most duplicate chunk KV in HBM, reducing usage by up to 2x over state-of-the-art PIC at comparable latency and accuracy, and up to 5x for long prompts, without any model changes.",human
"Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.",human
"**Differentially Private Federated Learning with Adaptive Gradient Perturbation** Federated learning (FL) enables collaborative model training across decentralized devices without direct data sharing, mitigating privacy concerns. However, naive aggregation of gradients still leaks sensitive information. Differential privacy (DP) provides a rigorous framework for privacy protection by adding noise to the gradients, but often at the cost of model utility. We address this trade-off by introducing an adaptive gradient perturbation mechanism for differentially private FL. Our method dynamically adjusts the noise scale based on the gradient norm distribution observed during training. Specifically, we employ a clipping norm that adapts to the quantiles of the client gradients, ensuring that a larger noise scale is added only when necessary to achieve the desired privacy level. This approach minimizes unnecessary perturbation and preserves model accuracy. We conduct extensive experiments on various benchmark datasets, including MNIST, CIFAR-10, and Fashion-MNIST, demonstrating that our adaptive perturbation mechanism significantly outperforms fixed-noise DP-FL baselines. Empirical results indicate that our method achieves comparable or superior model accuracy while maintaining a strong privacy guarantee, measured by the privacy budget (Îµ). Our work provides a practical and efficient solution for privacy-preserving federated learning with improved utility.",ai
"We address the challenge of sample inefficiency in reinforcement learning (RL) for continuous control tasks with sparse rewards. While model-free RL algorithms have demonstrated success in various domains, their performance often necessitates a prohibitively large number of environment interactions. To mitigate this, we propose a novel algorithm, Adaptive Reward Shaping with Bayesian Optimization (ARS-BO), which dynamically shapes the reward function to provide informative feedback during exploration. ARS-BO leverages Bayesian Optimization with Gaussian Process priors to efficiently search for optimal reward shaping functions within a predefined function space. The reward shaping function is parameterized to adapt to the agent's current policy, guiding it towards promising regions of the state space and accelerating learning. Empirical evaluations on a suite of challenging continuous control benchmarks with sparse rewards demonstrate that ARS-BO significantly outperforms state-of-the-art model-free RL algorithms, including PPO and SAC, in terms of both sample efficiency and asymptotic performance. Furthermore, an ablation study validates the contribution of each component of the ARS-BO algorithm. These results highlight the effectiveness of dynamically shaped rewards optimized via Bayesian Optimization in improving the performance of RL agents in sparse reward environments.",ai
"We address the critical challenge of preserving data privacy in machine learning (ML) systems, specifically focusing on scenarios where sensitive user data is required for model training. The inherent risk of data leakage through model inversion and membership inference attacks necessitates robust privacy protection mechanisms. Our work introduces a novel differentially private Federated Learning (DP-FL) algorithm, termed ""Differentially Private Aggregated Gradient Perturbation"" (DP-AGP), that combines local differential privacy at the client level with secure aggregation techniques. Unlike existing DP-FL approaches that often compromise model utility due to excessive noise injection, DP-AGP strategically perturbs aggregated gradients based on a client-specific sensitivity analysis. This allows for adaptive noise calibration, minimizing the impact on model accuracy. We provide a rigorous privacy analysis demonstrating that DP-AGP satisfies Îµ-differential privacy. Empirical evaluations on benchmark datasets (CIFAR-10 and MNIST) show that DP-AGP achieves significantly higher model accuracy compared to standard DP-FL implementations while maintaining comparable privacy guarantees. Furthermore, our experiments demonstrate the scalability of DP-AGP in handling a large number of participating clients, making it a practical solution for privacy-preserving ML in real-world federated environments. The observed improvements in utility represent a significant advancement in the development of privacy-preserving machine learning techniques.",ai
"Large language models (LLMs) can act as both problem solvers and solution verifiers, with verifiers improving solver performance by selecting high-quality answers from a pool of candidates. However, prior studies of solver-verifier interactions have been limited, focusing mainly on self-verification and rarely examining how verifiers judge outputs from models in their own or in another model family. Modern LLMs also undergo extensive post-training, but its effect on verification remains unclear. We present a systematic study across 37 models spanning multiple families, sizes, and base vs. post-trained variants, evaluated on 9 benchmarks covering logical reasoning, structured puzzles, symbolic computation, mathematics, commonsense, factual recall, and domain knowledge. We compare self-verification with verification within the same family and across different families. To support this, we introduce and empirically validate verifier gain, a metric that predicts the performance improvements from test-time verifier-based rejection sampling. We analyze how metrics like verifier gain and false positive rate scale with model size and post-training, and characterize differences in dataset verifiability. Our findings show that cross-family verification is especially effective; post-training reduces self-improvement but strengthens cross-family improvement; and mathematical and logical tasks exhibit the highest inherent verifiability.",human
"We investigate the problem of coordinating decentralized agents with limited communication bandwidth and unknown, heterogeneous reward structures in multi-agent reinforcement learning (MARL). Specifically, we address the challenge of efficient communication in large-scale systems where transmitting complete state information is infeasible. We introduce a novel approach, the Differentiable Inter-Agent Learning with Gated Information Exchange (DIAL-GIX) framework, which integrates a differentiable communication channel with a gated recurrent unit (GRU) to selectively transmit and process relevant information. This allows agents to dynamically adapt their communication strategy based on the perceived utility of the exchanged messages. Unlike traditional DIAL, DIAL-GIX employs a gating mechanism to modulate the influence of incoming messages on the agent's policy update, mitigating the impact of irrelevant or misleading information. We evaluated DIAL-GIX on challenging cooperative navigation and resource allocation tasks. Empirical results demonstrate that DIAL-GIX outperforms state-of-the-art MARL algorithms, including standard DIAL and variants utilizing attention mechanisms, in terms of both learning speed and asymptotic performance. Furthermore, ablation studies validate the efficacy of the gated communication channel in improving coordination and resilience to noisy communication environments. The proposed approach represents a significant step towards achieving scalable and robust cooperation in decentralized multi-agent systems.",ai
"Document forgery poses a growing threat to legal, economic, and governmental processes, requiring increasingly sophisticated verification mechanisms. One approach involves the use of plausibility checks, rule-based procedures that assess the correctness and internal consistency of data, to detect anomalies or signs of manipulation. Although these verification procedures are essential for ensuring data integrity, existing plausibility checks are manually implemented by software engineers, which is time-consuming. Recent advances in code generation with large language models (LLMs) offer new potential for automating and scaling the generation of these checks. However, adapting LLMs to the specific requirements of an unknown domain remains a significant challenge. This work investigates the extent to which LLMs, adapted on domain-specific code and data through different fine-tuning strategies, can generate rule-based plausibility checks for forgery detection on constrained hardware resources. We fine-tune open-source LLMs, Llama 3.1 8B and OpenCoder 8B, on structured datasets derived from real-world application scenarios and evaluate the generated plausibility checks on previously unseen forgery patterns. The results demonstrate that the models are capable of generating executable and effective verification procedures. This also highlights the potential of LLMs as scalable tools to support human decision-making in security-sensitive contexts where comprehensibility is required.",human
"The rapid growth of short-form video platforms increases the need for privacy-preserving moderation, as cloud-based pipelines expose raw videos to privacy risks, high bandwidth costs, and inference latency. To address these challenges, we propose an on-device federated learning framework for video violence detection that integrates self-supervised VideoMAE representations, LoRA-based parameter-efficient adaptation, and defense-in-depth privacy protection. Our approach reduces the trainable parameter count to 5.5M (~3.5% of a 156M backbone) and incorporates DP-SGD with configurable privacy budgets and secure aggregation. Experiments on RWF-2000 with 40 clients achieve 77.25% accuracy without privacy protection and 65-66% under strong differential privacy, while reducing communication cost by compared to full-model federated learning. The code is available at: {https://github.com/zyt-599/FedVideoMAE}",human
"Graph Neural Networks (GNNs) have emerged as powerful tools for representation learning on graph-structured data. However, the performance of GNNs is often limited by the presence of noisy or irrelevant edges in the input graph, hindering the propagation of useful information. This work addresses the problem of robust GNN learning in the presence of adversarial edge perturbations. We propose a novel regularization technique, Graph Structure Consistency Regularization (GSCR), which encourages the learned node embeddings to be invariant to subtle changes in the graph structure. GSCR operates by introducing small perturbations to the adjacency matrix during training and penalizing deviations in the resulting node embeddings. Specifically, we leverage an adversarial perturbation strategy to identify and modify edges that maximally affect the embedding space, promoting robustness against worst-case structural noise. Empirical evaluations on several benchmark datasets for node classification and graph classification demonstrate that GSCR significantly improves the robustness of GNNs against adversarial edge attacks and noisy graph structures. Furthermore, our method achieves state-of-the-art performance on these tasks, highlighting its effectiveness in learning robust and generalizable graph representations. The observed gains are consistent across various GNN architectures, indicating the broad applicability of GSCR.",ai
"Large language models (LLM) have achieved remarkable performance across a wide range of tasks. However, their substantial parameter sizes pose significant challenges for deployment on edge devices with limited computational and memory resources. Low-rank compression is a promising approach to address this issue, as it reduces both computational and memory costs, making LLM more suitable for resource-constrained environments. Nonetheless, naÃ¯ve low-rank compression methods require a significant reduction in the retained rank to achieve meaningful memory and computation savings. For a low-rank model, the ranks need to be reduced by more than half to yield efficiency gains. Such aggressive truncation, however, typically results in substantial performance degradation. To address this trade-off, we propose SkipCat, a novel low-rank compression framework that enables the use of higher ranks while achieving the same compression rates. First, we introduce an intra-layer shared low-rank projection method, where multiple matrices that share the same input use a common projection. This reduces redundancy and improves compression efficiency. Second, we propose a block skipping technique that omits computations and memory transfers for selected sub-blocks within the low-rank decomposition. These two techniques jointly enable our compressed model to retain more effective ranks under the same compression budget. Experimental results show that, without any additional fine-tuning, our method outperforms previous low-rank compression approaches by 7% accuracy improvement on zero-shot tasks under the same compression rate. These results highlight the effectiveness of our rank-maximized compression strategy in preserving model performance under tight resource constraints.",human
"Real-world ecommerce recommender systems must deliver relevant items under strict tens-of-milliseconds latency constraints despite challenges such as cold-start products, rapidly shifting user intent, and dynamic context including seasonality, holidays, and promotions. We introduce STARS, a transformer-based sequential recommendation framework built for large-scale, low-latency ecommerce settings. STARS combines several innovations: dual-memory user embeddings that separate long-term preferences from short-term session intent; semantic item tokens that fuse pretrained text embeddings, learnable deltas, and LLM-derived attribute tags, strengthening content-based matching, long-tail coverage, and cold-start performance; context-aware scoring with learned calendar and event offsets; and a latency-conscious two-stage retrieval pipeline that performs offline embedding generation and online maximum inner-product search with filtering, enabling tens-of-milliseconds response times. In offline evaluations on production-scale data, STARS improves Hit@5 by more than 75 percent relative to our existing LambdaMART system. A large-scale A/B test on 6 million visits shows statistically significant lifts, including Total Orders +0.8%, Add-to-Cart on Home +2.0%, and Visits per User +0.5%. These results demonstrate that combining semantic enrichment, multi-intent modeling, and deployment-oriented design can yield state-of-the-art recommendation quality in real-world environments without sacrificing serving efficiency.",human
"LLM-based tutors are typically single-turn assistants that lack persistent representations of learner knowledge, making it difficult to provide principled, transparent, and long-term pedagogical support. We introduce IntelliCode, a multi-agent LLM tutoring system built around a centralized, versioned learner state that integrates mastery estimates, misconceptions, review schedules, and engagement signals. A StateGraph Orchestrator coordinates six specialized agents: skill assessment, learner profiling, graduated hinting, curriculum selection, spaced repetition, and engagement monitoring, each operating as a pure transformation over the shared state under a single-writer policy. This architecture enables auditable mastery updates, proficiency-aware hints, dependency-aware curriculum adaptation, and safety-aligned prompting. The demo showcases an end-to-end tutoring workflow: a learner attempts a DSA problem, receives a conceptual hint when stuck, submits a corrected solution, and immediately sees mastery updates and a personalized review interval. We report validation results with simulated learners, showing stable state updates, improved task success with graduated hints, and diverse curriculum coverage. IntelliCode demonstrates how persistent learner modeling, orchestrated multi-agent reasoning, and principled instructional design can be combined to produce transparent and reliable LLM-driven tutoring.",human
"Walking has always been a primary mode of transportation and is recognized as an essential activity for maintaining good health. Despite the need for safe walking conditions in urban environments, sidewalks are frequently obstructed by various obstacles that hinder free pedestrian movement. Any object obstructing a pedestrian's path can pose a safety hazard. The advancement of pervasive computing and egocentric vision techniques offers the potential to design systems that can automatically detect such obstacles in real time, thereby enhancing pedestrian safety. The development of effective and efficient identification algorithms relies on the availability of comprehensive and well-balanced datasets of egocentric data. In this work, we introduce the PEDESTRIAN dataset, comprising egocentric data for 29 different obstacles commonly found on urban sidewalks. A total of 340 videos were collected using mobile phone cameras, capturing a pedestrian's point of view. Additionally, we present the results of a series of experiments that involved training several state-of-the-art deep learning algorithms using the proposed dataset, which can be used as a benchmark for obstacle detection and recognition tasks. The dataset can be used for training pavement obstacle detectors to enhance the safety of pedestrians in urban areas.",human
"Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases and frequency awareness, limiting their generalization under structured missing patterns and distribution shifts. We propose FADTI, a diffusion-based framework that injects frequency-informed feature modulation via a learnable Fourier Bias Projection (FBP) module and combines it with temporal modeling through self-attention and gated convolution. FBP supports multiple spectral bases, enabling adaptive encoding of both stationary and non-stationary patterns. This design injects frequency-domain inductive bias into the generative imputation process. Experiments on multiple benchmarks, including a newly introduced biological time series dataset, show that FADTI consistently outperforms state-of-the-art methods, particularly under high missing rates. Code is available at https://anonymous.4open.science/r/TimeSeriesImputation-52BF",human
"### Abstract Deep learning methodologies have demonstrated significant promise in the analysis of medical imaging data. However, challenges remain in accurately segmenting and classifying lesions, particularly in modalities with low contrast and high noise levels. This study addresses the problem of automated lesion detection and characterization in magnetic resonance imaging (MRI) of the brain, focusing on improving performance in scenarios with limited training data. We propose a novel architecture, a weakly-supervised contrastive learning framework integrated with a multi-scale convolutional neural network (CNN), to enhance feature representation and segmentation accuracy. The contrastive learning component is designed to learn discriminative features from unannotated data, effectively leveraging unlabeled information to augment the supervised learning process. The multi-scale CNN incorporates feature extraction at different resolutions, allowing the model to capture both fine-grained details and global contextual information. We evaluated the proposed method on a publicly available dataset of brain MRI scans containing various types of lesions. Experimental results demonstrate a significant improvement in segmentation performance, achieving a Dice score of 0.82 and an Intersection over Union (IoU) of 0.74. These results surpass the performance of several state-of-the-art methods, highlighting the effectiveness of the proposed approach for medical image analysis, particularly when dealing with limited labeled data.",ai
"We address the problem of efficiently verifying the satisfiability of quantified bit-vector formulas (QBV) with arbitrarily nested quantifiers, a challenge common in hardware verification and security analysis. Existing solvers often struggle with quantifier alternations and complex bit-vector arithmetic. We introduce a novel approach, QBV-AR, which leverages Abstract Refinement techniques within a counterexample-guided quantifier instantiation (CEGQI) framework. QBV-AR employs a portfolio of abstract domains, including interval, congruence, and bitwise domains, to iteratively refine the search space. Specifically, abstract domains are used to generate quantified instantiations, prioritizing those likely to refute or satisfy the formula. These instantiations are then checked by a back-end SAT solver. A counterexample-driven refinement process strategically tightens the abstract domains based on SAT solver results, guiding the instantiation process and reducing redundancy. We evaluate QBV-AR on a suite of challenging QBV benchmarks derived from hardware verification problems and compare its performance against state-of-the-art QBV solvers. Experimental results demonstrate that QBV-AR achieves a significant improvement in the number of solved instances and runtime compared to existing solvers, particularly on problems with complex quantifier structures and bit-vector operations. The portfolio approach and adaptive refinement strategy of QBV-AR prove effective in navigating the search space of quantified bit-vector formulas.",ai
"Recent advancements in neural language models have shown promise in tackling complex reasoning tasks. However, their application to formal mathematical reasoning, particularly proof verification and generation, remains a significant challenge. This work addresses the problem of automatically proving theorems in first-order logic, focusing on improving the efficiency and correctness of automated theorem provers. We introduce a novel approach that integrates a pre-trained language model with a symbolic reasoning engine based on resolution and paramodulation. The language model is employed to guide the search strategy of the prover, predicting promising clauses to explore and pruning irrelevant branches of the search tree. We fine-tune the language model on a large corpus of formal proofs and use its output to prioritize inferences during proof search. Empirical evaluation on a standard benchmark of first-order theorem proving problems demonstrates that our integrated system significantly outperforms existing automated theorem provers, achieving a higher success rate and requiring fewer inference steps. Specifically, we observe a 15% increase in the number of solved problems compared to a state-of-the-art resolution prover, coupled with a 20% reduction in average proof search time. These results indicate that the integration of language models with symbolic reasoning engines offers a promising avenue for advancing automated reasoning capabilities.",ai
"We investigate distributionally robust optimization (DRO) problems where the ambiguity set is constructed using divergences between probability measures. Specifically, we focus on scenarios where the underlying data distribution is subject to adversarial perturbations and propose a novel DRO framework leveraging the Wasserstein distance to construct ambiguity sets centered around a data-driven nominal distribution. Our approach addresses the limitations of traditional DRO formulations that rely on strong distributional assumptions or overly conservative solutions. We introduce a computationally tractable reformulation of the Wasserstein DRO problem using duality theory, resulting in a convex optimization problem that can be efficiently solved via standard solvers. Furthermore, we derive finite-sample guarantees for the out-of-sample performance of the resulting robust solution. We demonstrate the efficacy of our method on benchmark machine learning problems, including classification and regression tasks, by comparing its performance against standard empirical risk minimization and existing DRO approaches. Empirical results show that our Wasserstein DRO framework achieves superior generalization performance and robustness against adversarial attacks, particularly in scenarios with limited training data and high levels of distributional uncertainty. The proposed framework offers a practical and theoretically sound approach for training robust machine learning models.",ai
"We address the challenge of scalable automated reasoning within complex, structured knowledge bases. Traditional symbolic reasoning methods often struggle with the computational demands imposed by large knowledge graphs and uncertain data. We propose a novel approach, termed Differentiable Inductive Logic Programming (DILP), that integrates differentiable learning techniques with inductive logic programming (ILP). DILP learns probabilistic logic programs directly from data by leveraging gradient-based optimization, enabling efficient handling of noisy and incomplete knowledge. Specifically, we introduce a differentiable framework for grounding and inference in ILP, allowing us to approximate the logical entailment relation with a neural network. This network is trained to predict the truth values of logical atoms based on evidence from the knowledge base and learned program clauses. We evaluate DILP on several benchmark reasoning tasks, including link prediction in knowledge graphs and program synthesis. Experimental results demonstrate that DILP achieves significant improvements in accuracy and scalability compared to existing ILP systems and graph neural network-based reasoning approaches, particularly in scenarios with large knowledge bases and noisy data. The proposed method provides a promising avenue for bridging the gap between symbolic reasoning and statistical learning.",ai
"### Abstract Accurate and efficient analysis of medical images is crucial for timely diagnosis and treatment planning. However, manual interpretation of large volumes of medical imaging data is time-consuming and subject to inter-observer variability. This work addresses the challenge of automating the detection of pulmonary nodules in Computed Tomography (CT) scans, a critical task for early lung cancer diagnosis. We propose a novel multi-scale feature fusion network (MSFF-Net) leveraging a 3D convolutional neural network (CNN) backbone. MSFF-Net incorporates an attention mechanism to selectively enhance salient features at varying scales, effectively capturing both subtle and prominent nodule characteristics. Furthermore, a custom loss function, combining focal loss and dice loss, is employed to mitigate the class imbalance inherent in nodule detection tasks. The proposed method was evaluated on the publicly available LUNA16 dataset. Experimental results demonstrate that MSFF-Net achieves a competitive performance, with a reported Free-Response Operating Characteristic (FROC) score of 0.88 at 8 False Positives Per Scan (FP/scan). This represents a significant improvement compared to baseline 3D CNN architectures and state-of-the-art methods, indicating the efficacy of the proposed multi-scale feature fusion and attention-based mechanism for robust nodule detection in CT images.",ai
"We investigate the challenge of achieving efficient and robust coordination in multi-agent systems (MAS) where agents possess limited communication bandwidth and heterogeneous action spaces. Specifically, we address the problem of decentralized task allocation under uncertainty in a dynamically changing environment. Traditional approaches often rely on extensive message passing or centralized control, both of which become impractical with resource constraints and decentralized architectures. We propose a novel communication-efficient learning framework, Adaptive Attention-based Communication (AABC), wherein each agent learns to selectively attend to relevant information from its neighbors based on the current state and task requirements. AABC employs a differentiable attention mechanism coupled with a variational autoencoder to compress and transmit only the most salient information, thereby reducing communication overhead. The architecture is trained via a decentralized variant of proximal policy optimization. Empirical evaluations on a suite of cooperative navigation and resource gathering tasks demonstrate that AABC significantly outperforms existing communication protocols, including fixed-rate broadcasting and simple attention mechanisms. We observe a reduction in communication volume of up to 60% while simultaneously achieving superior task completion rates and robustness against communication noise compared to benchmark algorithms. Further analysis reveals that the learned attention patterns reflect meaningful inter-agent dependencies and facilitate efficient role specialization within the MAS.",ai
"Large Language Model (LLM) agents relying on external retrieval are increasingly deployed in high-stakes environments. While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process. We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically ""analysis paralysis"" or ""cognitive haste""--without altering underlying facts or using explicit triggers. To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus. Experiments on HotpotQA and FEVER using ReAct, Reflection, and Tree of Thoughts (ToT) architectures reveal that GSI significantly degrades performance. It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters. Finally, we propose RSP-M, a lightweight runtime monitor that calculates RSV metrics in real-time and triggers alerts when values exceed safety thresholds. Our work demonstrates that reasoning style is a distinct, exploitable vulnerability, necessitating process-level defenses beyond static content analysis.",human
"We introduce graph pattern-based association rules (GPARs) for directed labeled multigraphs such as RDF graphs. GPARs support both generative tasks, where a graph is extended, and evaluative tasks, where the plausibility of a graph is assessed. The framework goes beyond related formalisms such as graph functional dependencies, graph entity dependencies, relational association rules, graph association rules, multi-relation and path association rules, and Horn rules. Given a collection of graphs, we evaluate graph patterns under no-repeated-anything semantics, which allows the topology of a graph to be taken into account more effectively. We define a probability space and derive confidence, lift, leverage, and conviction in a probabilistic setting. We further analyze how these metrics relate to their classical itemset-based counterparts and identify conditions under which their characteristic properties are preserved.",human
"We investigate the problem of sample inefficiency in reinforcement learning (RL) for continuous control tasks with sparse rewards and high-dimensional state spaces. Such environments pose significant challenges for traditional RL algorithms, often requiring an impractical number of interactions to achieve acceptable performance. We propose a novel hierarchical reinforcement learning framework, named ""Task-Decomposed Imitation Learning with Intrinsic Motivation"" (TDIL-IM), which leverages expert demonstrations to accelerate learning while simultaneously promoting exploration through an intrinsic motivation module. TDIL-IM decomposes the overall task into a sequence of simpler sub-goals, learned via imitation learning from a limited set of expert trajectories. Subsequently, an intrinsic reward signal, based on novelty-seeking behavior within the sub-goal space, is introduced to encourage the agent to autonomously explore and refine its policy. We evaluate TDIL-IM on a suite of challenging continuous control benchmarks with sparse rewards. Empirical results demonstrate that TDIL-IM significantly outperforms state-of-the-art model-free RL algorithms, achieving superior performance with orders of magnitude fewer samples. Ablation studies further validate the effectiveness of both the task decomposition and intrinsic motivation components. The results suggest that TDIL-IM provides a promising approach to address the sample inefficiency bottleneck in RL for complex, real-world applications.",ai
"Black-box AI (BBAI) systems such as foundational models are increasingly being used for sequential decision making. To ensure that such systems are safe to operate and deploy, it is imperative to develop efficient methods that can provide a sound and interpretable representation of the BBAI's capabilities. This paper shows that PDDL-style representations can be used to efficiently learn and model an input BBAI's planning capabilities. It uses the Monte-Carlo tree search paradigm to systematically create test tasks, acquire data, and prune the hypothesis space of possible symbolic models. Learned models describe a BBAI's capabilities, the conditions under which they can be executed, and the possible outcomes of executing them along with their associated probabilities. Theoretical results show soundness, completeness and convergence of the learned models. Empirical results with multiple BBAI systems illustrate the scope, efficiency, and accuracy of the presented methods.",human
"We address the challenge of training machine learning models on decentralized datasets while guaranteeing differential privacy. Federated learning (FL) offers a promising framework for such scenarios, but naive implementations are susceptible to privacy breaches due to gradient leakage. This work proposes a novel approach, FedCurv, that combines differential privacy with curvature regularization to enhance both privacy and model accuracy in FL settings. FedCurv leverages a differentially private (DP) stochastic gradient descent algorithm at each client to update model parameters and incorporates a curvature regularization term based on the Fisher information matrix. This regularization term encourages smoother model updates, mitigating the impact of noise injected for privacy preservation and improving generalization performance. We analytically derive bounds on the privacy loss incurred by FedCurv, demonstrating its formal privacy guarantees under the moments accountant framework. Empirically, we evaluate FedCurv on image classification tasks using benchmark datasets (MNIST, CIFAR-10) and demonstrate that it achieves significantly higher accuracy compared to standard DP-SGD and DP-FedAvg baselines for a given privacy budget. Furthermore, FedCurv exhibits improved robustness to non-IID data distributions across clients, a common challenge in practical FL deployments. These results highlight the efficacy of curvature regularization in enhancing privacy-preserving federated learning.",ai
"We address the challenge of sample inefficiency in reinforcement learning (RL) within environments characterized by sparse rewards and high-dimensional state spaces. Existing methods often struggle to learn effective policies in such settings due to the difficulty of exploring the state space and attributing credit to relevant actions. We introduce a novel approach, Hierarchical Reward Shaping with Intrinsic Motivation (HRSIM), that combines hierarchical reinforcement learning with a learned reward shaping function driven by intrinsic motivation. HRSIM decomposes the task into a hierarchy of sub-goals, allowing the agent to learn simpler, more manageable policies at each level. The intrinsic reward signal, generated by a variational autoencoder trained on observed state transitions, encourages exploration in under-visited regions of the state space and guides the learning of the reward shaping function. Empirical evaluations on benchmark robotic manipulation tasks and a challenging navigation environment demonstrate that HRSIM significantly outperforms state-of-the-art RL algorithms, achieving higher success rates and faster convergence. Specifically, we observe a 30-50% improvement in final performance compared to baseline methods like SAC and HRL when evaluated on tasks with sparse rewards and complex dynamics. These results suggest that HRSIM provides a promising framework for addressing the sample efficiency problem in challenging RL environments.",ai
"Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context into answer via prompt . We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from to and are modeled as transition matrices and encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.",human
"Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.",human
"We present DeepBridge, an 80K-line Python library that unifies multi-dimensional validation, automatic compliance verification, knowledge distillation, and synthetic data generation. DeepBridge offers: (i) 5 validation suites (fairness with 15 metrics, robustness with weakness detection, uncertainty via conformal prediction, resilience with 5 drift types, hyperparameter sensitivity), (ii) automatic EEOC/ECOA/GDPR verification, (iii) multi-format reporting system (interactive/static HTML, PDF, JSON), (iv) HPM-KD framework for knowledge distillation with meta-learning, and (v) scalable synthetic data generation via Dask. Through 6 case studies (credit scoring, hiring, healthcare, mortgage, insurance, fraud) we demonstrate that DeepBridge: reduces validation time by 89% (17 min vs. 150 min with fragmented tools), automatically detects fairness violations with complete coverage (10/10 features vs. 2/10 from existing tools), generates audit-ready reports in minutes. HPM-KD demonstrates consistent superiority across compression ratios 2.3--7x (CIFAR100): +1.00--2.04pp vs. Direct Training (p<0.05), confirming that Knowledge Distillation is effective at larger teacher-student gaps. Usability study with 20 participants shows SUS score 87.5 (top 10%, ``excellent''), 95% success rate, and low cognitive load (NASA-TLX 28/100). DeepBridge is open-source under MIT license at https://github.com/deepbridge/deepbridge, with complete documentation at https://deepbridge.readthedocs.io",human
"## Automated Detection of Pulmonary Embolism in CT Pulmonary Angiograms via Multi-Scale Feature Fusion The accurate and timely detection of pulmonary embolism (PE) in Computed Tomography Pulmonary Angiograms (CTPA) is crucial for effective patient management. Manual interpretation of CTPA images is time-consuming and susceptible to inter-observer variability. This work addresses the problem of automated PE detection by proposing a novel deep learning framework that leverages multi-scale feature fusion to enhance the detection of emboli of varying sizes and locations within the pulmonary vasculature. Our method employs a 3D convolutional neural network architecture, incorporating attention mechanisms to focus on regions of interest. Furthermore, we introduce a hierarchical feature fusion strategy that combines features extracted at different scales within the network, allowing the model to capture both fine-grained details and global contextual information. We evaluated our approach on a publicly available CTPA dataset, achieving a sensitivity of 92.3% and a specificity of 95.7% for PE detection at the patient level. These results demonstrate a significant improvement over existing methods, highlighting the efficacy of the proposed multi-scale feature fusion technique for automated PE detection in CTPA images. The proposed framework has the potential to assist radiologists in improving diagnostic accuracy and efficiency in the detection of pulmonary embolism.",ai
"We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.",human
"Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.",human
"Early and accessible detection of Alzheimer's disease (AD) remains a critical clinical challenge, and cube-copying tasks offer a simple yet informative assessment of visuospatial function. This work proposes a multimodal framework that converts hand-drawn cube sketches into graph-structured representations capturing geometric and topological properties, and integrates these features with demographic information and neuropsychological test (NPT) scores for AD classification. Cube drawings are modeled as graphs with node features encoding spatial coordinates, local graphlet-based topology, and angular geometry, which are processed using graph neural networks and fused with age, education, and NPT features in a late-fusion model. Experimental results show that graph-based representations provide a strong unimodal baseline and substantially outperform pixel-based convolutional models, while multimodal integration further improves performance and robustness to class imbalance. SHAP-based interpretability analysis identifies specific graphlet motifs and geometric distortions as key predictors, closely aligning with clinical observations of disorganized cube drawings in AD. Together, these results establish graph-based analysis of cube copying as an interpretable, non-invasive, and scalable approach for Alzheimer's disease screening.",human
"The integration of generative Artificial Intelligence into the digital ecosystem necessitates a critical re-evaluation of Indian criminal jurisprudence regarding computational forensics integrity. While algorithmic efficiency enhances evidence extraction, a research gap exists regarding the Digital Personal Data Protection Act, 2023's compatibility with adversarial AI threats, specifically anti-forensics and deepfakes. This study scrutinizes the AI ""dual-use"" dilemma, functioning as both a cyber-threat vector and forensic automation mechanism, to delineate privacy boundaries in high-stakes investigations. Employing a doctrinal legal methodology, the research synthesizes statutory analysis of the DPDP Act with global ethical frameworks (IEEE, EU) to evaluate regulatory efficacy. Preliminary results indicate that while Machine Learning offers high accuracy in pattern recognition, it introduces vulnerabilities regarding data poisoning and algorithmic bias. Findings highlight a critical tension between the Act's data minimization principles and forensic data retention requirements. Furthermore, the paper identifies that existing legal definitions inadequately encompass AI-driven ""tool crimes"" and ""target crimes."" Consequently, the research proposes a ""human-centric"" forensic model prioritizing explainable AI (XAI) to ensure evidence admissibility. These implications suggest that synchronizing Indian privacy statutes with international forensic standards is imperative to mitigate synthetic media risks, establishing a roadmap for future legislative amendments and technical standardization.",human
"Graph Neural Networks (GNNs) have demonstrated remarkable efficacy in learning representations of graph-structured data across diverse domains. However, existing GNN architectures often struggle with capturing long-range dependencies due to the limitations of message passing mechanisms over a fixed number of hops. This constraint hampers their ability to model complex relationships and intricate patterns present in large and sparse graphs. To address this limitation, we propose a novel GNN architecture, the Adaptive Path Integrated Graph Neural Network (APIGNN). APIGNN incorporates an adaptive path selection mechanism that dynamically identifies and integrates relevant paths between nodes, circumventing the fixed hop constraint. This mechanism leverages attention scores derived from node embeddings to prioritize paths that contribute significantly to the learning task. Furthermore, we introduce a path aggregation function that effectively combines information from selected paths, mitigating the potential for information dilution over longer distances. Empirical evaluations on several benchmark graph datasets, including citation networks and social networks, demonstrate that APIGNN consistently outperforms state-of-the-art GNN models in node classification and graph classification tasks. Specifically, we observe significant improvements in accuracy and F1-score, particularly on datasets characterized by long-range dependencies. The results highlight the effectiveness of APIGNN in capturing and utilizing information from distant nodes, enabling more comprehensive and nuanced graph representation learning.",ai
"The performance of machine learning (ML) models often deteriorates when the underlying data distribution changes over time, a phenomenon known as data distribution drift. When this happens, ML models need to be retrained and redeployed. ML Operations (MLOps) is often manual, i.e., humans trigger the process of model retraining and redeployment. In this work, we present an automated MLOps pipeline designed to address neural network classifier retraining in response to significant data distribution changes. Our MLOps pipeline employs multi-criteria statistical techniques to detect distribution shifts and triggers model updates only when necessary, ensuring computational efficiency and resource optimization. We demonstrate the effectiveness of our framework through experiments on several benchmark anomaly detection data sets, showing significant improvements in model accuracy and robustness compared to traditional retraining strategies. Our work provides a foundation for deploying more reliable and adaptive ML systems in dynamic real-world settings, where data distribution changes are common.",human
"While graph neural networks have shown remarkable success in molecular property prediction, current approaches like the Equivariant Subgraph Aggregation Networks (ESAN) treat molecules as bags of independent substructures, overlooking crucial relationships between these components. We present Graph of Molecule Substructures (GoMS), a novel architecture that explicitly models the interactions and spatial arrangements between molecular substructures. Unlike ESAN's bag-based representation, GoMS constructs a graph where nodes represent subgraphs and edges capture their structural relationships, preserving critical topological information about how substructures are connected and overlap within the molecule. Through extensive experiments on public molecular datasets, we demonstrate that GoMS outperforms ESAN and other baseline methods, with particularly improvements for large molecules containing more than 100 atoms. The performance gap widens as molecular size increases, demonstrating GoMS's effectiveness for modeling industrial-scale molecules. Our theoretical analysis demonstrates that GoMS can distinguish molecules with identical subgraph compositions but different spatial arrangements. Our approach shows particular promise for materials science applications involving complex molecules where properties emerge from the interplay between multiple functional units. By capturing substructure relationships that are lost in bag-based approaches, GoMS represents a significant advance toward scalable and interpretable molecular property prediction for real-world applications.",human
"Learning accurate and stable time-advancement operators for nonlinear partial differential equations (PDEs) remains challenging, particularly for chaotic, stiff, and long-horizon dynamical systems. While neural operator methods such as the Fourier Neural Operator (FNO) and Koopman-inspired extensions achieve good short-term accuracy, their long-term stability is often limited by unconstrained latent representations and cumulative rollout errors. In this work, we introduce an inverse scattering inspired Fourier Neural Operator(IS-FNO), motivated by the reversibility and spectral evolution structure underlying the classical inverse scattering transform. The proposed architecture enforces a near-reversible pairing between lifting and projection maps through an explicitly invertible neural transformation, and models latent temporal evolution using exponential Fourier layers that naturally encode linear and nonlinear spectral dynamics. We systematically evaluate IS-FNO against baseline FNO and Koopman-based models on a range of benchmark PDEs, including the Michelson-Sivashinsky and Kuramoto-Sivashinsky equations (in one and two dimensions), as well as the integrable Korteweg-de Vries and Kadomtsev-Petviashvili equations. The results demonstrate that IS-FNO achieves lower short-term errors and substantially improved long-horizon stability in non-stiff regimes. For integrable systems, reduced IS-FNO variants that embed analytical scattering structure retain competitive long-term accuracy despite limited model capacity. Overall, this work shows that incorporating physical structure -- particularly reversibility and spectral evolution -- into neural operator design significantly enhances robustness and long-term predictive fidelity for nonlinear PDE dynamics.",human
"As Large Language Models (LLMs) become ubiquitous, the challenge of securing them against adversarial ""jailbreaking"" attacks has intensified. Current defense strategies often rely on computationally expensive external classifiers or brittle lexical filters, overlooking the intrinsic dynamics of the model's reasoning process. In this work, the Laminar Flow Hypothesis is introduced, which posits that benign inputs induce smooth, gradual transitions in an LLM's high-dimensional latent space, whereas adversarial prompts trigger chaotic, high-variance trajectories - termed Semantic Turbulence - resulting from the internal conflict between safety alignment and instruction-following objectives. This phenomenon is formalized through a novel, zero-shot metric: the variance of layer-wise cosine velocity. Experimental evaluation across diverse small language models reveals a striking diagnostic capability. The RLHF-aligned Qwen2-1.5B exhibits a statistically significant 75.4% increase in turbulence under attack (p less than 0.001), validating the hypothesis of internal conflict. Conversely, Gemma-2B displays a 22.0% decrease in turbulence, characterizing a distinct, low-entropy ""reflex-based"" refusal mechanism. These findings demonstrate that Semantic Turbulence serves not only as a lightweight, real-time jailbreak detector but also as a non-invasive diagnostic tool for categorizing the underlying safety architecture of black-box models.",human
"Automated road sign recognition is a critical task for intelligent transportation systems, but traditional deep learning methods struggle with the sheer number of sign classes and the impracticality of creating exhaustive labeled datasets. This paper introduces a novel zero-shot recognition framework that adapts the Retrieval-Augmented Generation (RAG) paradigm to address this challenge. Our method first uses a Vision Language Model (VLM) to generate a textual description of a sign from an input image. This description is used to retrieve a small set of the most relevant sign candidates from a vector database of reference designs. Subsequently, a Large Language Model (LLM) reasons over the retrieved candidates to make a final, fine-grained recognition. We validate this approach on a comprehensive set of 303 regulatory signs from the Ohio MUTCD. Experimental results demonstrate the framework's effectiveness, achieving 95.58% accuracy on ideal reference images and 82.45% on challenging real-world road data. This work demonstrates the viability of RAG-based architectures for creating scalable and accurate systems for road sign recognition without task-specific training.",human
"We address the challenge of representing and reasoning with complex, interconnected concepts in dynamic environments. Traditional knowledge representation formalisms often struggle to efficiently manage the computational overhead associated with maintaining consistency and inferring novel relationships within large, evolving knowledge bases. This work introduces a novel hybrid knowledge representation framework, termed Adaptive Semantic Graph Networks (ASGNs), which combines the expressive power of semantic graphs with the adaptability of neural networks. ASGNs represent concepts and relations as nodes and edges, respectively, while employing trainable embedding functions to capture semantic similarity and enable efficient reasoning. A key component is a dynamic graph adaptation mechanism that automatically adjusts the network structure based on observed data and inference requirements, allowing for continuous refinement of the knowledge representation. We evaluate ASGNs on benchmark knowledge graph completion and inductive reasoning tasks. Experimental results demonstrate that ASGNs achieve state-of-the-art performance compared to existing symbolic and neural approaches, exhibiting significant improvements in accuracy, inference speed, and scalability. Furthermore, the adaptive network structure promotes efficient knowledge compression and facilitates the discovery of previously unknown relationships within the represented domain.",ai
"We address the problem of estimating heterogeneous treatment effects in the presence of unobserved confounding, a persistent challenge in causal inference. Traditional methods often rely on strong ignorability assumptions that are readily violated in real-world observational studies. We propose a novel instrumental variable (IV) approach leveraging deep representation learning to construct instruments from high-dimensional covariates. Specifically, we train a variational autoencoder (VAE) to learn a lower-dimensional latent representation of the observed covariates, and then utilize this representation as an instrument. The validity of the instrument is enhanced by the VAE's ability to disentangle confounding factors from the treatment assignment mechanism. We derive theoretical conditions under which our method yields consistent estimates of treatment effects. Empirically, we demonstrate the efficacy of our approach on both synthetic datasets with complex non-linear relationships and real-world healthcare data. Our results show that our method outperforms existing IV methods and other causal inference techniques, particularly in scenarios with high-dimensional confounding and weak instruments. The proposed framework provides a robust and scalable solution for estimating heterogeneous treatment effects in challenging observational settings.",ai
"Training large neural networks and merging task-specific models both exploit low-rank structure and require parameter importance estimation, yet these challenges have been pursued in isolation. Current workflows compute curvature information during training, discard it, then recompute similar information for merging -- wasting computation and discarding valuable trajectory data. We introduce a unified framework that maintains factorized momentum and curvature statistics during training, then reuses this information for geometry-aware model composition. The proposed method achieves memory efficiency comparable to state-of-the-art approaches while accumulating task saliency scores that enable curvature-aware merging without post-hoc Fisher computation. We establish convergence guarantees for non-convex objectives with approximation error bounded by gradient singular value decay. On natural language understanding benchmarks, curvature-aware parameter selection outperforms magnitude-only baselines across all sparsity levels, with multi-task merging improving over strong baselines. The proposed framework exhibits rank-invariant convergence and superior hyperparameter robustness compared to existing low-rank optimizers. By treating the optimization trajectory as a reusable asset rather than discarding it, our approach eliminates redundant computation while enabling more principled model composition.",human
"We address the problem of enhancing the logical consistency and coherence of large language model (LLM) outputs in complex reasoning scenarios. Existing LLMs, while proficient in generating fluent text, often struggle with maintaining adherence to strict logical constraints, leading to fallacies and inconsistencies within extended arguments. We introduce a novel framework, termed ""Constrained Abductive Reasoning Network"" (CARN), which integrates abductive reasoning with constraint satisfaction techniques. CARN first abductively infers a latent knowledge graph that plausibly explains the LLM's initial assertions. Subsequently, it employs a constraint satisfaction solver to identify and rectify inconsistencies within the graph, guided by a predefined set of logical axioms and domain-specific constraints. Finally, the revised knowledge graph is used to refine and regenerate the LLM's initial output, ensuring consistency and coherence. We evaluate CARN on a suite of challenging reasoning tasks involving temporal reasoning, spatial reasoning, and causal inference. Empirical results demonstrate that CARN significantly improves the logical validity and coherence of LLM-generated text, achieving a 35% reduction in logical fallacies and a 20% increase in human-rated coherence compared to state-of-the-art LLMs without explicit reasoning constraints. The findings suggest CARN is a promising approach for improving the reliability of LLMs in high-stakes applications demanding rigorous reasoning.",ai
"Soft sensing infers hard-to-measure data through a large number of easily obtainable variables. However, in complex industrial scenarios, the issue of insufficient data volume persists, which diminishes the reliability of soft sensing. Generative Adversarial Networks (GAN) are one of the effective solutions for addressing insufficient samples. Nevertheless, traditional GAN fail to account for the mapping relationship between labels and features, which limits further performance improvement. Although some studies have proposed solutions, none have considered both performance and efficiency simultaneously. To address these problems, this paper proposes the multi-task learning-based regression GAN framework that integrates regression information into both the discriminator and generator, and implements a shallow sharing mechanism between the discriminator and regressor. This approach significantly enhances the quality of generated samples while improving the algorithm's operational efficiency. Moreover, considering the importance of training samples and generated samples, a dual data evaluation strategy is designed to make GAN generate more diverse samples, thereby increasing the generalization of subsequent modeling. The superiority of method is validated through four classic industrial soft sensing cases: wastewater treatment plants, surface water, absorption towers, and industrial gas turbines.",human
"This study provides an overview of heart disease prediction using an intelligent system. Predicting disease accurately is crucial in the medical field, but traditional methods relying solely on a doctor's experience often lack precision. To address this limitation, intelligent systems are applied as an alternative to traditional approaches. While various intelligent system methods exist, this study focuses on three: Fuzzy Logic, Neural Networks, and Case-Based Reasoning (CBR). A comparison of these techniques in terms of accuracy was conducted, and ultimately, Case-Based Reasoning (CBR) was selected for heart disease prediction. In the prediction phase, the heart disease dataset underwent data pre-processing to clean the data and data splitting to separate it into training and testing sets. The chosen intelligent system was then employed to predict heart disease outcomes based on the processed data. The experiment concluded with Case-Based Reasoning (CBR) achieving a notable accuracy rate of 97.95% in predicting heart disease. The findings also revealed that the probability of heart disease was 57.76% for males and 42.24% for females. Further analysis from related studies suggests that factors such as smoking and alcohol consumption are significant contributors to heart disease, particularly among males.",human
"We introduce Vibe Reasoning, a human-AI collaborative paradigm for solving complex mathematical problems. Our key insight is that frontier AI models already possess the knowledge required to solve challenging problems -- they simply do not know how, what, or when to apply it. Vibe Reasoning transforms AI's latent potential into manifested capability through generic meta-prompts, agentic grounding, and model orchestration. We demonstrate this paradigm through IMO 2025 Problem 6, a combinatorial optimization problem where autonomous AI systems publicly reported failures. Our solution combined GPT-5's exploratory capabilities with Gemini 3 Pro's proof strengths, leveraging agentic workflows with Python code execution and file-based memory, to derive both the correct answer (2112) and a rigorous mathematical proof. Through iterative refinement across multiple attempts, we discovered the necessity of agentic grounding and model orchestration, while human prompts evolved from problem-specific hints to generic, transferable meta-prompts. We analyze why capable AI fails autonomously, how each component addresses specific failure modes, and extract principles for effective vibe reasoning. Our findings suggest that lightweight human guidance can unlock frontier models' mathematical reasoning potential. This is ongoing work; we are developing automated frameworks and conducting broader evaluations to further validate Vibe Reasoning's generality and effectiveness.",human
"We address the challenge of representing complex, multi-relational knowledge graphs within a vector space while preserving both structural and semantic information. Existing embedding models often struggle to effectively capture long-range dependencies and hierarchical relationships present in real-world knowledge bases, leading to suboptimal performance in downstream tasks such as link prediction and knowledge graph completion. We propose a novel approach, Hierarchical Relational Graph Embeddings (HRGE), which leverages a combination of hyperbolic geometry and relational attention mechanisms to embed entities and relations. HRGE represents entities hierarchically in hyperbolic space, allowing for efficient encoding of taxonomic structures and inheritance relationships. Furthermore, a relational attention mechanism dynamically weights neighboring entities based on their relevance to the target entity and relation, facilitating the propagation of information across multiple hops. We evaluate HRGE on standard benchmark datasets, including WordNet, Freebase, and YAGO, demonstrating significant improvements over state-of-the-art embedding models in link prediction and triple classification tasks. Specifically, HRGE achieves an average improvement of 5-8% in Mean Reciprocal Rank (MRR) compared to existing Euclidean and hyperbolic embedding techniques, indicating enhanced ability to infer missing relationships and generalize to unseen data. The improved performance highlights the efficacy of combining hierarchical representation and relational attention for knowledge graph embedding.",ai
"We investigate a novel approach to robust optimization under distributional uncertainty, specifically addressing the challenge of efficiently computing solutions when the ambiguity set is defined by Wasserstein distance. Traditional methods often suffer from computational intractability, particularly with large datasets and complex decision spaces. Our work introduces a stochastic approximation algorithm that leverages sample average approximation (SAA) in conjunction with gradient-based optimization. We develop a computationally tractable surrogate objective that allows for efficient gradient estimation within the Wasserstein ambiguity set, thereby mitigating the curse of dimensionality inherent in deterministic approaches. Furthermore, we establish asymptotic convergence guarantees for our algorithm, demonstrating that it converges to an optimal solution of the robust counterpart under mild regularity conditions. Empirical evaluations on benchmark portfolio optimization and inventory management problems showcase the superior scalability and performance of our method compared to state-of-the-art robust optimization solvers. The results indicate a significant reduction in computational time while maintaining comparable or improved levels of robustness against adversarial distributional shifts. The proposed algorithm provides a practical and efficient framework for solving large-scale robust optimization problems with Wasserstein uncertainty.",ai
"We address the challenge of enhancing automated theorem proving in complex mathematical domains, specifically focusing on geometry. The primary problem lies in the difficulty of effectively combining symbolic reasoning with geometric intuitions derived from diagrammatic information. Current theorem provers often struggle to navigate the combinatorial explosion of possible inferences when relying solely on axiomatic systems. Our method introduces a novel approach that integrates geometric reasoning via deep neural networks with traditional logic-based inference. Specifically, we train a graph neural network to predict relevant geometric relationships (e.g., parallelism, congruence) from diagrams associated with geometric theorems. These predictions are then incorporated as weighted hints within a resolution-based theorem prover. The weights are dynamically adjusted based on the network's confidence scores. We evaluate our system on a benchmark dataset of challenging geometry theorems, demonstrating a significant improvement in proof success rate compared to state-of-the-art automated theorem provers operating without diagrammatic information. Specifically, we observe a 25% increase in theorems proven within a fixed time limit, suggesting the potential of our hybrid approach for tackling complex mathematical problems.",ai
"We address the challenge of training machine learning models on sensitive data without revealing the underlying individual records. Specifically, we focus on scenarios where data resides in a distributed environment and cannot be centrally aggregated due to privacy constraints. This paper introduces a novel federated learning framework that integrates differential privacy and secure aggregation techniques to guarantee strong privacy guarantees while maintaining model utility. Our method employs a differentially private stochastic gradient descent algorithm within each participating client, perturbed by calibrated noise. Furthermore, we implement a secure aggregation protocol based on additive secret sharing to protect the gradients exchanged between clients and the central server, mitigating the risk of information leakage during the aggregation phase. We rigorously analyze the privacy loss using differential privacy accounting techniques and derive bounds on the overall privacy budget. Empirical evaluations conducted on several benchmark datasets demonstrate that our framework achieves competitive model accuracy compared to non-private federated learning, while provably limiting the information disclosure about individual data points. Our results highlight the feasibility of training high-performance machine learning models in a privacy-preserving manner, offering a practical solution for applications with strict data protection requirements.",ai
"The rapid advancement of large language models (LLMs) has intensified concerns about the robustness of their safety alignment. While existing jailbreak studies explore both single-turn and multi-turn strategies, most implicitly assume a static safety boundary and fail to account for how contextual interactions dynamically influence model behavior, leading to limited stability and generalization. Motivated by this gap, we propose MEEA (Mere Exposure Effect Attack), a psychology-inspired, fully automated black-box framework for evaluating multi-turn safety robustness, grounded in the mere exposure effect. MEEA leverages repeated low-toxicity semantic exposure to induce a gradual shift in a model's effective safety threshold, enabling progressive erosion of alignment constraints over sustained interactions. Concretely, MEEA constructs semantically progressive prompt chains and optimizes them using a simulated annealing strategy guided by semantic similarity, toxicity, and jailbreak effectiveness. Extensive experiments on both closed-source and open-source models, including GPT-4, Claude-3.5, and DeepSeek-R1, demonstrate that MEEA consistently achieves higher attack success rates than seven representative baselines, with an average Attack Success Rate (ASR) improvement exceeding 20%. Ablation studies further validate the necessity of both annealing-based optimization and contextual exposure mechanisms. Beyond improved attack effectiveness, our findings indicate that LLM safety behavior is inherently dynamic and history-dependent, challenging the common assumption of static alignment boundaries and highlighting the need for interaction-aware safety evaluation and defense mechanisms. Our code is available at: https://github.com/Carney-lsz/MEEA",human
"We propose an orthogonal approximate message passing (OAMP) algorithm for signal estimation in the rectangular spiked matrix model with general rotationally invariant (RI) noise. We establish a rigorous state evolution that precisely characterizes the algorithm's high-dimensional dynamics and enables the construction of iteration-wise optimal denoisers. Within this framework, we accommodate spectral initializations under minimal assumptions on the empirical noise spectrum. In the rectangular setting, where a single rank-one component typically generates multiple informative outliers, we further propose a procedure for combining these outliers under mild non-Gaussian signal assumptions. For general RI noise models, the predicted performance of the proposed optimal OAMP algorithm agrees with replica-symmetric predictions for the associated Bayes-optimal estimator, and we conjecture that it is statistically optimal within a broad class of iterative estimation methods.",human
"We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game. The game runs in the direction opposite to that of the network, and the input of the network serves as the terminal reward of the game. In fact, evaluating the network is the same as running the Shapley-Bellman backward recursion for the value of the game. Using the expression of the value of the game as an expected total payoff with respect to the path measure induced by the transition probabilities and a pair of optimal policies, we derive a discrete Feynman-Kac-type path-integral formula for the network output. This game-theoretic representation can be used to derive bounds on the output from bounds on the input, leveraging the monotonicity of Shapley operators, and to verify robustness properties using policies as certificates. Moreover, training the neural network becomes an inverse game problem: given pairs of terminal rewards and corresponding values, one seeks transition probabilities and rewards of a game that reproduces them. Finally, we show that a similar approach applies to neural networks with Softplus activation functions, where the ReLU net game is replaced by its entropic regularization.",human
"Large Language Models (LLMs) exhibit remarkable capabilities in natural language understanding and reasoning, but suffer from hallucination: the generation of factually incorrect content. While numerous methods have been developed to reduce hallucinations, their impact on creative generations remains unexplored. This gap is particularly critical for AI-assisted scientific discovery, which requires both factual accuracy and creative hypothesis generation. We investigate how three hallucination-reduction techniques: Chain of Verification (CoVe), Decoding by Contrasting Layers (DoLa), and Retrieval-Augmented Generation (RAG), affect creativity in LLMs. Evaluating multiple model families (LLaMA, Qwen, Mistral) at varying scales (1B - 70B parameters) on two creativity benchmarks (NeoCoder and CS4), we find that these methods have opposing effects on divergent creativity. CoVe enhances divergent thinking, DoLa suppresses it, and RAG shows minimal impact. Our findings provide guidance for selecting appropriate hallucination-reduction methods in scientific applications, where the balance between factual accuracy and creative exploration is crucial.",human
"--- We address the challenge of sparse reward environments in natural language generation tasks, specifically focusing on the problem of generating coherent and informative summaries from lengthy source documents. Traditional reinforcement learning (RL) approaches often struggle due to the infrequency of positive rewards, leading to inefficient exploration and suboptimal policy learning. We propose a novel hierarchical reinforcement learning framework, termed Hierarchical Abstractive Summarization Network (HASN), which decomposes the summarization process into two levels: a high-level policy network responsible for selecting salient phrases from the source document, and a low-level generation network that transforms these phrases into a concise and fluent summary. The high-level policy is trained using a proximal policy optimization (PPO) variant augmented with an intrinsic curiosity module to incentivize exploration of under-represented segments of the source document. The low-level generation network is pre-trained on a large corpus of text and fine-tuned using RL to align with the high-level policy's selections. Experimental results on the CNN/DailyMail dataset demonstrate that HASN significantly outperforms existing RL-based summarization models and achieves comparable performance to state-of-the-art supervised methods, particularly in terms of ROUGE scores and human evaluation metrics for coherence and informativeness. The improved exploration strategy and hierarchical architecture contribute to more effective learning in the sparse reward setting.",ai
"The increasing number of cyber threats and rapidly evolving tactics, as well as the high volume of data in recent years, have caused classical machine learning, rules, and signature-based defence strategies to fail, rendering them unable to keep up. An alternative, Quantum Machine Learning (QML), has recently emerged, making use of computations based on quantum mechanics. It offers better encoding and processing of high-dimensional structures for certain problems. This survey provides a comprehensive overview of QML techniques relevant to the domain of security, such as Quantum Neural Networks (QNNs), Quantum Support Vector Machines (QSVMs), Variational Quantum Circuits (VQCs), and Quantum Generative Adversarial Networks (QGANs), and discusses the contributions of this paper in relation to existing research in the field and how it improves over them. It also maps these methods across supervised, unsupervised, and generative learning paradigms, and to core cybersecurity tasks, including intrusion and anomaly detection, malware and botnet classification, and encrypted-traffic analytics. It also discusses their application in the domain of cloud computing security, where QML can enhance secure and scalable operations. Many limitations of QML in the domain of cybersecurity have also been discussed, along with the directions for addressing them.",human
"Recent advancements in language models have spurred interest in their capacity to represent and reason with knowledge. However, extracting reliable and structured knowledge from these models remains a significant challenge. This work addresses the problem of inducing explicit knowledge graphs from pre-trained language models, specifically focusing on relational knowledge encoded within their parameters. We introduce a novel method, Knowledge Graph Distillation via Attentive Probing (KGDAP), which leverages contextualized probing and attention mechanisms to identify and extract salient relational triples from the model's internal representations. KGDAP first generates a large set of candidate triples using pattern-based extraction from the model's generated text. Subsequently, an attention-guided probing module scores each triple's plausibility based on the model's attention weights when processing relevant context. These scores are then used to construct a high-confidence knowledge graph. Empirical evaluation on benchmark relation extraction datasets demonstrates that KGDAP achieves competitive performance compared to existing knowledge extraction methods, while requiring significantly less fine-tuning data. Furthermore, our analysis reveals that the distilled knowledge graphs exhibit higher precision and coverage compared to graphs obtained through traditional pattern-based extraction alone, suggesting that KGDAP effectively captures and structures relational knowledge implicitly stored within the language model.",ai
"This paper investigates the challenge of robust optimization under distribution shift, focusing on scenarios where the underlying data distribution deviates from the training distribution during deployment. We address the limitations of traditional robust optimization methods that often rely on predefined uncertainty sets, which can lead to overly conservative solutions or fail to capture complex distributional shifts. We propose a novel distributionally robust optimization (DRO) framework based on kernel mean embedding (KME) discrepancy. This KME-DRO approach constructs ambiguity sets centered around the training distribution, parameterized by the KME of the potential shifted distribution. Crucially, the radius of the ambiguity set is adaptively learned from a validation dataset representing the expected distribution shift. We derive a tractable reformulation of the KME-DRO problem, enabling efficient computation of robust solutions. We validate the efficacy of our method on several benchmark datasets, including image classification and regression tasks, under various types of distributional shifts. Empirical results demonstrate that the proposed KME-DRO framework significantly outperforms existing robust optimization techniques, achieving superior out-of-distribution performance while maintaining competitive in-distribution accuracy. Furthermore, our method exhibits greater robustness to adversarial attacks compared to standard training and alternative DRO approaches.",ai
"Graph Neural Networks (GNNs) have demonstrated significant efficacy in modeling relational data for various downstream tasks. However, many existing GNN architectures suffer from limitations in capturing long-range dependencies and effectively aggregating information across diverse node neighborhoods within large, complex graphs. This paper introduces a novel GNN framework, Graph Propagation with Attentive Contextualization (GPAC), designed to address these limitations. GPAC incorporates a multi-hop attentive propagation mechanism that dynamically weights the influence of distant nodes based on their relevance to the target node's context. Furthermore, we propose a contextualization module that leverages node attributes and local graph structure to refine the attention weights, enabling the network to differentiate between informative and noisy connections. We evaluate GPAC on a suite of graph-based benchmarks, including node classification, link prediction, and graph classification tasks. Experimental results demonstrate that GPAC consistently outperforms state-of-the-art GNN models, achieving significant gains in accuracy and F1-score. Specifically, we observe an average improvement of 5.2% in node classification accuracy on benchmark datasets. The ablation studies validate the effectiveness of both the attentive propagation and contextualization components, highlighting their contributions to the overall performance of the proposed framework. Our findings suggest that GPAC provides a more robust and effective approach for learning representations on complex graphs.",ai
"Today, a lot of research on language models is focused on large, general-purpose models. However, many NLP pipelines only require models with a well-defined, small set of capabilities. While large models are capable of performing the tasks of those smaller models, they are simply not fast enough to process large amounts of data or offer real-time responses. Furthermore, they often use unnecessarily large amounts of energy, leading to sustainability concerns and problems when deploying them on battery-powered devices. In our work, we show how to train small models for such efficiency-critical applications. As opposed to many off-the-shelf NLP pipelines, our models use modern training techniques such as distillation, and offer support for low-resource languages. We call our models TiME (Tiny Monolingual Encoders) and comprehensively evaluate them on a range of common NLP tasks, observing an improved trade-off between benchmark performance on one hand, and throughput, latency and energy consumption on the other. Along the way, we show that distilling monolingual models from multilingual teachers is possible, and likewise distilling models with absolute positional embeddings from teachers with relative positional embeddings.",human
"We investigate the problem of sample inefficiency in reinforcement learning (RL) within sparse reward environments, specifically focusing on tasks requiring temporally extended exploration. Traditional RL algorithms often struggle to learn effective policies in such settings due to the lack of immediate feedback. To address this challenge, we propose a novel hierarchical RL framework incorporating a learned intrinsic reward signal based on information gain. Our method, termed Hierarchical Information Maximization for Exploration (HIME), consists of a high-level manager tasked with setting subgoals, and a low-level worker trained to achieve these subgoals. The manager receives an intrinsic reward proportional to the reduction in entropy of the state distribution after the worker executes a subgoal. This encourages the manager to select subgoals that lead to novel and informative states, promoting directed exploration. We evaluate HIME on a suite of challenging sparse reward navigation tasks. Empirical results demonstrate that HIME significantly outperforms several state-of-the-art RL baselines, including both intrinsic motivation-based and imitation learning-based approaches, achieving higher success rates and faster convergence. Ablation studies validate the efficacy of the information gain-based intrinsic reward and the hierarchical structure in facilitating efficient exploration and learning in sparse reward domains.",ai
"Intracranial recordings have opened a unique opportunity to simultaneously measure activity across multiregional networks in the human brain. Recent works have focused on developing transformer-based neurofoundation models of such recordings that can generalize across subjects and datasets. However, these recordings exhibit highly complex spatiotemporal interactions across diverse spatial scales, from the single-channel scale to the scale of brain regions. As such, there remain critical open questions regarding how best to encode spatial information and how to design self-supervision tasks that enable the learning of brain network patterns and enhance downstream decoding performance using such high-dimensional, multiregional recordings. To allow for exploring these questions, we propose a new spatiotemporal transformer model of multiregional neural activity and a corresponding self-supervised masked latent reconstruction task, designed to enable flexibility in the spatial scale used for token encoding and masking. Applying this model on publicly available multiregional intracranial electrophysiology (iEEG) data, we demonstrate that adjusting the spatial scale for both token encoding and masked reconstruction significantly impacts downstream decoding. Further, we find that spatial encoding at larger scales than channel-level encoding, which is commonly used in existing iEEG transformer models, improves downstream decoding performance. Finally, we demonstrate that our method allows for region-level token encoding while also maintaining accurate channel-level neural reconstruction. Taken together, our modeling framework enables exploration of the spatial scales used for token encoding and masking, reveals their importance towards self-supervised pretraining of neurofoundation models of multiregional human brain activity, and enhances downstream decoding performance.",human
"In the high-cost simulation-driven design domain, translating ambiguous design requirements into a mathematical optimization formulation is a bottleneck for optimizing product performance. This process is time-consuming and heavily reliant on expert knowledge. While large language models (LLMs) offer potential for automating this task, existing approaches either suffer from poor formalization that fails to accurately align with the design intent or rely on solver feedback for data filtering, which is unavailable due to the high simulation costs. To address this challenge, we propose APF, a framework for solver-independent, automated problem formulation via LLMs designed to automatically convert engineers' natural language requirements into executable optimization models. The core of this framework is an innovative pipeline for automatically generating high-quality data, which overcomes the difficulty of constructing suitable fine-tuning datasets in the absence of high-cost solver feedback with the help of data generation and test instance annotation. The generated high-quality dataset is used to perform supervised fine-tuning on LLMs, significantly enhancing their ability to generate accurate and executable optimization problem formulations. Experimental results on antenna design demonstrate that APF significantly outperforms the existing methods in both the accuracy of requirement formalization and the quality of resulting radiation efficiency curves in meeting the design goals.",human
"Current mainstream post-training quantization methods for large language models typically apply a uniform quantization strategy across all network layers, overlooking the substantial differences in algorithmic suitability among layers. To address this limitation, we propose CKA Guided Modular Quantization, a fine-tuning-free, plug-and-play framework for algorithmic heterogeneous quantization. Our method independently evaluates multiple PTQ algorithms on each layer and employs Linear Centered Kernel Alignment (CKA) as a metric to automatically select the optimal quantization strategy per layer. The individually optimized strategies are then integrated to construct a hybrid quantized model. Experiments demonstrate that our approach consistently outperforms both uniform quantization baselines and state-of-the-art mixed-precision methods across mainstream LLMs including LLaMA and Qwen ,in terms of perplexity (PPL) and downstream task performance.",human
"Clinical communication is central to patient outcomes, yet large-scale human annotation of patient-provider conversation remains labor-intensive, inconsistent, and difficult to scale. Existing approaches based on large language models typically rely on single-task models that lack adaptability, interpretability, and reliability, especially when applied across various communication frameworks and clinical domains. In this study, we developed a Multi-framework Structured Agentic AI system for Clinical Communication (MOSAIC), built on a LangGraph-based architecture that orchestrates four core agents, including a Plan Agent for codebook selection and workflow planning, an Update Agent for maintaining up-to-date retrieval databases, a set of Annotation Agents that applies codebook-guided retrieval-augmented generation (RAG) with dynamic few-shot prompting, and a Verification Agent that provides consistency checks and feedback. To evaluate performance, we compared MOSAIC outputs against gold-standard annotations created by trained human coders. We developed and evaluated MOSAIC using 26 gold standard annotated transcripts for training and 50 transcripts for testing, spanning rheumatology and OB/GYN domains. On the test set, MOSAIC achieved an overall F1 score of 0.928. Performance was highest in the Rheumatology subset (F1 = 0.962) and strongest for Patient Behavior (e.g., patients asking questions, expressing preferences, or showing assertiveness). Ablations revealed that MOSAIC outperforms baseline benchmarking.",human
"We address the challenge of integrating symbolic reasoning with subsymbolic learning in complex, partially observable environments. Traditional automated reasoning systems struggle with noisy, incomplete data prevalent in real-world scenarios, while purely data-driven learning methods lack the ability to generalize beyond their training distribution or provide explainable decision-making. We propose a novel neuro-symbolic architecture, termed Differentiable Reasoner with Attentive grounding (DRA), that combines probabilistic logic programming with attention-based neural networks. DRA utilizes a neural network to ground high-level symbolic predicates from raw sensory input, employing an attention mechanism to focus on relevant aspects of the input. These grounded predicates are then fed into a probabilistic logic program, enabling reasoning and inference under uncertainty. We train DRA end-to-end using a differentiable approximation of logical inference, allowing the neural network to learn representations that are amenable to symbolic reasoning. We evaluate DRA on a simulated robotic navigation task involving object recognition and path planning under noisy sensor readings. Experimental results demonstrate that DRA significantly outperforms both purely symbolic and purely subsymbolic baselines, achieving higher success rates and improved generalization to novel environments. Furthermore, we show that the attention mechanism provides insights into the reasoning process, enhancing the explainability of the system's decisions.",ai
"Analyzing and visualizing scientific ensemble datasets with high dimensionality and complexity poses significant challenges. Dimensionality reduction techniques and autoencoders are powerful tools for extracting features, but they often struggle with such high-dimensional data. This paper presents an enhanced autoencoder framework that incorporates a clustering loss, based on the soft silhouette score, alongside a contrastive loss to improve the visualization and interpretability of ensemble datasets. First, EfficientNetV2 is used to generate pseudo-labels for the unlabeled portions of the scientific ensemble datasets. By jointly optimizing the reconstruction, clustering, and contrastive objectives, our method encourages similar data points to group together while separating distinct clusters in the latent space. UMAP is subsequently applied to this latent representation to produce 2D projections, which are evaluated using the silhouette score. Multiple types of autoencoders are evaluated and compared based on their ability to extract meaningful features. Experiments on two scientific ensemble datasets - channel structures in soil derived from Markov chain Monte Carlo, and droplet-on-film impact dynamics - show that models incorporating clustering or contrastive loss marginally outperform the baseline approaches.",human
"Transformer models have achieved state-of-the-art results across a wide range of natural language processing (NLP) tasks, yet their computational complexity and memory requirements pose significant challenges, particularly when processing long sequences. This paper addresses the problem of improving the efficiency of transformer models without sacrificing performance. We propose a novel sparse attention mechanism, termed ""Adaptive Sparse Transformer"" (AST), which learns to selectively attend to the most relevant tokens in a sequence. AST employs a differentiable gating mechanism, parameterized by a lightweight feed-forward network, to dynamically determine which attention heads attend to which tokens. This adaptive sparsity reduces the computational cost of the attention mechanism, allowing for faster processing and reduced memory footprint. We evaluate AST on several benchmark NLP tasks, including machine translation (WMT'14 English-German), text summarization (CNN/DailyMail), and long-range arena (LRA). Our results demonstrate that AST achieves comparable or superior performance to dense transformer models while significantly reducing computational cost and memory usage. Specifically, AST achieves a 20% reduction in FLOPs and a 15% reduction in memory consumption on the WMT'14 English-German task, with a BLEU score comparable to the baseline transformer. Furthermore, experiments on LRA showcase the efficacy of AST in handling long sequences, achieving state-of-the-art results in several tasks.",ai
"The 6G wireless aims at the Tb/s peak data rates are expected, a sub-millisecond latency, massive Internet of Things/vehicle connectivity, which requires sustainable access to audio over the air and energy-saving functionality. Cognitive Radio Networks CCNs help in alleviating the problem of spectrum scarcity, but classical sensing and allocation are still energy-consumption intensive, and sensitive to rapid spectrum variations. Our framework which centers on AI driven green CRN aims at integrating deep reinforcement learning (DRL) with transfer learning, energy harvesting (EH), reconfigurable intelligent surfaces (RIS) with other light-weight genetic refinement operations that optimally combine sensing timelines, transmit power, bandwidth distribution and RIS phase selection. Compared to two baselines, the utilization of MATLAB + NS-3 under dense loads, a traditional CRN with energy sensing under fixed policies, and a hybrid CRN with cooperative sensing under heuristic distribution of resource, there are (25-30%) fewer energy reserves used, sensing AUC greater than 0.90 and +6-13 p.p. higher PDR. The integrated framework is easily scalable to large IoT and vehicular applications, and it provides a feasible and sustainable roadmap to 6G CRNs. Index Terms--Cognitive Radio Networks (CRNs), 6G, Green Communication, Energy Efficiency, Deep Reinforcement Learning (DRL), Spectrum Sensing, RIS, Energy Harvesting, QoS, IoT.",human
"Robust optimization (RO) seeks to find solutions that are feasible and near-optimal under uncertainty. A persistent challenge in RO lies in effectively managing the inherent trade-off between robustness and optimality, especially when dealing with high-dimensional uncertainty sets. This work addresses this challenge by introducing a novel data-driven approach to construct uncertainty sets using kernel density estimation (KDE) combined with a distributionally robust optimization (DRO) framework. Specifically, we leverage KDE to approximate the probability distribution of uncertain parameters from historical data, and then define an ambiguity set based on confidence regions derived from the KDE. We formulate a DRO problem using this data-driven ambiguity set and solve it via a sample average approximation (SAA). Theoretical analysis provides bounds on the out-of-sample performance and assesses the convergence rate of the SAA. Empirically, we evaluate our method on benchmark portfolio optimization and facility location problems under uncertain demand. Results demonstrate that our KDE-based DRO approach achieves a superior balance between robustness against uncertainty and nominal performance compared to existing RO methods that rely on pre-defined uncertainty sets such as ellipsoidal or box constraints. Moreover, our approach exhibits improved computational efficiency compared to alternative data-driven RO techniques.",ai
"Graph Neural Networks (GNNs) have demonstrated significant efficacy in learning representations for graph-structured data across diverse domains. However, many existing GNN architectures struggle to effectively capture long-range dependencies and complex relational patterns within graphs, often resulting in suboptimal performance on tasks requiring reasoning over distant nodes. This paper introduces a novel GNN architecture, termed Adaptive Path Aggregation Network (APAN), designed to explicitly address this limitation. APAN leverages a learnable path selection mechanism that dynamically identifies and aggregates information from relevant paths between nodes during message passing. This selection mechanism is guided by an attention mechanism that considers node attributes, edge features, and path structural information to discern the most salient connections. We evaluate APAN on several benchmark graph classification and node classification datasets, including those characterized by long-range dependencies and hierarchical structures. Experimental results demonstrate that APAN consistently outperforms state-of-the-art GNNs, achieving significant improvements in accuracy and generalization performance. Ablation studies further validate the importance of the adaptive path selection component in capturing complex graph relationships and improving downstream task performance. These findings suggest that APAN offers a promising approach for learning effective representations on graphs with intricate dependencies.",ai
"Real-time deployment of prostate MRI segmentation on clinical workstations is often bottlenecked by computational load and memory footprint. Deep learning-based prostate gland segmentation approaches remain challenging due to anatomical variability. To bridge this efficiency gap while still maintaining reliable segmentation accuracy, we propose KLO-Net, a dynamic K-Nearest Neighbor attention U-Net with Cross Stage Partial, i.e., CSP, encoder for efficient prostate gland segmentation from MRI scan. Unlike the regular K-NN attention mechanism, the proposed dynamic K-NN attention mechanism allows the model to adaptively determine the number of attention connections for each spatial location within a slice. In addition, CSP blocks address the computational load to reduce memory consumption. To evaluate the model's performance, comprehensive experiments and ablation studies are conducted on two public datasets, i.e., PROMISE12 and PROSTATEx, to validate the proposed architecture. The detailed comparative analysis demonstrates the model's advantage in computational efficiency and segmentation quality.",human
"Implicit Neural Representations (INRs) have emerged as a powerful paradigm for parameterizing physical fields, yet they often suffer from spectral bias and the computational expense of non-convex optimization. We introduce the Vekua Layer (VL), a differentiable spectral method grounded in the classical theory of Generalized Analytic Functions. By restricting the hypothesis space to the kernel of the governing differential operator -- specifically utilizing Harmonic and Fourier-Bessel bases -- the VL transforms the learning task from iterative gradient descent to a strictly convex least-squares problem solved via linear projection. We evaluate the VL against Sinusoidal Representation Networks (SIRENs) on homogeneous elliptic Partial Differential Equations (PDEs). Our results demonstrate that the VL achieves machine precision () on exact reconstruction tasks and exhibits superior stability in the presence of incoherent sensor noise (), effectively acting as a physics-informed spectral filter. Furthermore, we show that the VL enables ""holographic"" extrapolation of global fields from partial boundary data via analytic continuation, a capability absent in standard coordinate-based approximations.",human
"Machine unlearning aims to erase requested data from trained models without full retraining. For Reasoning Multimodal Large Language Models (RMLLMs), this is uniquely challenging: intermediate chain-of-thought steps can still leak sensitive information even when final answers are forgotten, and overly aggressive interventions easily damage general reasoning ability. Yet no benchmark jointly evaluates how well unlearning methods suppress reasoning-level leakage while preserving reasoning competence. We address this gap with RMLLMU-Bench, the first benchmark for RMLLM unlearning that extends standard forgetting metrics with dedicated measures of reasoning leakage and reasoning retention. A systematic evaluation on RMLLMU-Bench reveals that existing unlearning methods for MLLMs and Large (Language) Reasoning Models (LRMs) either leave substantial leakage in the reasoning process or severely degrade reasoning performance. To address these gaps, we propose R-MUSE (Reasoning-preserving MLLM Unlearning via Subspace guidance and Adaptive Steering), a training-free and inference-time intervention framework that steers internal representations to forget both answers and reasoning traces while explicitly preserving general reasoning. Experiments on RMLLMU-Bench demonstrate that R-MUSE achieves a substantially better balance between effective forgetting and reasoning retention.",human
"Culture is the bedrock of human interaction; it dictates how we perceive and respond to everyday interactions. As the field of human-computer interaction grows via the rise of generative Large Language Models (LLMs), the cultural alignment of these models become an important field of study. This work, using the VSM13 International Survey and Hofstede's cultural dimensions, identifies the cultural alignment of popular LLMs (DeepSeek-V3, V3.1, GPT-5, GPT-4.1, GPT-4, Claude Opus 4, Llama 3.1, and Mistral Large). We then use cultural prompting, or using system prompts to shift the cultural alignment of a model to a desired country, to test the adaptability of these models to other cultures, namely China, France, India, Iran, Japan, and the United States. We find that the majority of the eight LLMs tested favor the United States when the culture is not specified, with varying results when prompted for other cultures. When using cultural prompting, seven of the eight models shifted closer to the expected culture. We find that models had trouble aligning with Japan and China, despite two of the models tested originating with the Chinese company DeepSeek.",human
"We investigate the problem of improving the sample efficiency of reinforcement learning (RL) agents in sparse reward environments, specifically focusing on scenarios where successful task completion requires a precise sequence of actions. Traditional RL methods often struggle in these settings due to the lack of informative feedback signals during exploration. We propose a novel approach, Hierarchical Imitation-Augmented Reinforcement Learning (HIAL), which integrates imitation learning (IL) from expert demonstrations with a hierarchical RL architecture. HIAL first trains a high-level policy to select subgoals based on demonstration data, effectively guiding exploration towards promising regions of the state space. Subsequently, low-level policies are trained using RL to achieve these subgoals. This decomposition facilitates learning by providing intermediate rewards and simplifying the credit assignment problem. We evaluate HIAL on a simulated robotic manipulation task involving precise object assembly. Our results demonstrate that HIAL significantly outperforms both standard RL algorithms (e.g., PPO, DQN) and pure imitation learning baselines in terms of sample efficiency and final task performance. Furthermore, ablation studies confirm the benefits of both the hierarchical structure and the imitation-augmented exploration strategy, highlighting the synergistic effects of combining these techniques. The improved sample efficiency and performance of HIAL suggest its potential for tackling complex real-world tasks with sparse rewards.",ai
"Large Language Models (LLMs) have transformed artificial intelligence, offering profound opportunities for educational applications. However, their ability to provide fine-grained educational feedback for K-12 English writing remains underexplored. In this paper, we challenge the error analysis and pedagogical skills of LLMs by introducing the problem of Fine-grained Error Analysis for English Learners and present the Fine-grained Error ANalysis for English Learners (FEANEL) Benchmark. The benchmark comprises 1,000 essays written by elementary and secondary school students, and a well-developed English writing error taxonomy. Each error is annotated by language education experts and categorized by type, severity, and explanatory feedback, using a part-of-speech-based taxonomy they co-developed. We evaluate state-of-the-art LLMs on the FEANEL Benchmark to explore their error analysis and pedagogical abilities. Experimental results reveal significant gaps in current LLMs' ability to perform fine-grained error analysis, highlighting the need for advancements in particular methods for educational applications.",human
"The deployment of reinforcement learning (RL) agents in real-world applications is often hindered by performance degradation caused by mismatches between training and deployment environments. Distributionally robust RL (DR-RL) addresses this issue by optimizing worst-case performance over an uncertainty set of transition dynamics. However, existing work typically relies on substantial prior knowledge-such as access to a generative model or a large offline dataset-and largely focuses on tabular methods that do not scale to complex domains. We overcome these limitations by proposing an online DR-RL algorithm with general function approximation that learns an optimal robust policy purely through interaction with the environment, without requiring prior models or offline data, enabling deployment in high-dimensional tasks. We further provide a theoretical analysis establishing a near-optimal sublinear regret bound under a total variation uncertainty set, demonstrating the sample efficiency and effectiveness of our method.",human
"**Abstract:** Coordination in multi-agent systems (MAS) presents a persistent challenge, particularly in dynamic environments with incomplete information. Existing approaches often rely on centralized planning or predefined communication protocols, which can be computationally expensive or brittle in the face of unforeseen circumstances. This paper addresses the problem of decentralized task allocation and execution in MAS operating under uncertainty and communication constraints. We propose a novel approach combining reinforcement learning (RL) with a message-passing protocol that adaptively learns efficient communication strategies alongside optimal action policies. Specifically, agents are trained to optimize both their individual rewards and the utility of their messages to other agents, encouraging the emergence of informative and context-aware communication. We demonstrate the efficacy of our method in a simulated resource gathering environment where agents must coordinate to collect resources of varying value while limited by communication range and noisy observations. Experimental results indicate that our learned communication protocols significantly outperform fixed communication strategies and achieve comparable performance to centralized coordination schemes, all while maintaining full decentralization. Furthermore, the learned policies exhibit robustness to variations in environment dynamics and agent populations, suggesting a potential for generalization to real-world MAS applications.",ai
"This paper investigates sequence-to-sequence Transformer models for automatic speech recognition (ASR) error correction in low-resource Burmese, focusing on different feature integration strategies including IPA and alignment information. To our knowledge, this is the first study addressing ASR error correction specifically for Burmese. We evaluate five ASR backbones and show that our ASR Error Correction (AEC) approaches consistently improve word- and character-level accuracy over baseline outputs. The proposed AEC model, combining IPA and alignment features, reduced the average WER of ASR models from 51.56 to 39.82 before augmentation (and 51.56 to 43.59 after augmentation) and improving chrF++ scores from 0.5864 to 0.627, demonstrating consistent gains over the baseline ASR outputs without AEC. Our results highlight the robustness of AEC and the importance of feature design for improving ASR outputs in low-resource settings.",human
"We address the challenge of scalable and efficient automated reasoning within complex knowledge graphs. Existing approaches often struggle with the exponential growth of the search space when traversing large graphs, leading to computational bottlenecks. To mitigate this, we propose a novel framework integrating reinforcement learning (RL) with symbolic reasoning. Our method, termed RL-Guided Reasoning (RLGR), leverages RL to learn effective traversal policies that prioritize promising paths within the knowledge graph. Specifically, an agent is trained to navigate the graph, selecting relations based on a reward function that promotes reaching target entities given a query. We then utilize the learned policies to guide a modified version of backward chaining, effectively pruning the search space while maintaining completeness. We evaluate RLGR on benchmark knowledge graph completion datasets, including FB15k-237 and WN18RR. Empirical results demonstrate that RLGR achieves state-of-the-art performance in link prediction tasks, surpassing existing path-ranking and embedding-based methods. Furthermore, RLGR exhibits a significant reduction in inference time compared to traditional symbolic reasoning algorithms, highlighting its scalability for large-scale knowledge graphs. The approach offers a promising direction for combining the strengths of both RL and symbolic reasoning within automated reasoning systems.",ai
"We address the challenge of enhancing the inferential capabilities of large language models (LLMs) in complex reasoning tasks requiring multi-hop inference and logical deduction. Existing approaches often struggle to maintain coherence and accuracy across extended reasoning chains, leading to error accumulation and flawed conclusions. We introduce a novel framework, (GARIR), which integrates a dynamic knowledge graph representation within the LLM's reasoning process. GARIR iteratively constructs and refines a graph capturing entities, relationships, and inferred facts relevant to the problem. The LLM leverages this graph for both premise selection and conclusion generation, enabling more informed and contextually grounded inferences. Crucially, GARIR incorporates a self-assessment module that identifies potential inconsistencies and triggers iterative refinement steps, re-evaluating existing graph nodes and edges based on newly inferred information. We evaluate GARIR on a suite of challenging reasoning benchmarks, including ReClor, ProofWriter, and a novel synthetic dataset designed to test multi-hop logical deduction. Our results demonstrate that GARIR significantly outperforms existing LLM-based reasoning methods, achieving state-of-the-art performance and exhibiting improved robustness to noisy or incomplete input data. Ablation studies highlight the importance of both the graph-based representation and the iterative refinement mechanism for achieving optimal reasoning accuracy.",ai
"We investigate the problem of efficient exploration in sparse-reward reinforcement learning environments. Standard exploration strategies often struggle in such settings, resulting in protracted training times and suboptimal policies. To address this, we propose a novel intrinsic motivation framework based on the concept of ""learning progress surprise"" (LPS). Our method quantifies surprise as the discrepancy between predicted and observed improvements in a learned model of the environment's dynamics. This surprise signal is then used to incentivize exploration towards regions of the state space where the agent is rapidly improving its understanding of the environment. We implement LPS within a proximal policy optimization (PPO) architecture and evaluate its performance across a suite of challenging simulated robotic navigation and manipulation tasks characterized by sparse rewards. Our experimental results demonstrate that the LPS-driven agent significantly outperforms baseline exploration methods, including random exploration and count-based exploration, achieving higher success rates and faster convergence to optimal policies. Furthermore, we analyze the emergent exploration behavior of the LPS agent, showing that it effectively prioritizes learning in areas critical for solving the underlying task. These findings highlight the potential of learning progress surprise as a powerful intrinsic motivation signal for efficient exploration in reinforcement learning.",ai
"Prior studies investigating the internal workings of LLMs have uncovered sparse subnetworks, often referred to as circuits, that are responsible for performing specific tasks. Additionally, it has been shown that model performance improvement through fine-tuning often results from the strengthening of existing circuits in the model. Taken together, these findings suggest the possibility of intervening directly on such circuits to make precise, task-targeted updates. Motivated by these findings, we propose a novel method called Constructive Circuit Amplification which identifies pivotal tokens from model reasoning traces as well as model components responsible for the desired task, and updates only those components. Applied to mathematical reasoning, it improves accuracy by up to +11.4% across multiple models while modifying as little as 1.59% of model components, with minimal impact on other abilities as measured by MMLU, TriviaQA, and TruthfulQA. These results demonstrate that targeted capabilities can be reliably enhanced by selectively updating a sparse set of model components.",human
"Traditional animation production involves complex pipelines and significant manual labor cost. While recent video generation models such as Sora, Kling, and CogVideoX achieve impressive results on natural video synthesis, they exhibit notable limitations when applied to animation generation. Recent efforts, such as AniSora, demonstrate promising performance by fine-tuning image-to-video models for animation styles, yet analogous exploration in the text-to-video setting remains limited. In this work, we present PTTA, a pure text-to-animation framework for high-quality animation creation. We first construct a small-scale but high-quality paired dataset of animation videos and textual descriptions. Building upon the pretrained text-to-video model HunyuanVideo, we perform fine-tuning to adapt it to animation-style generation. Extensive visual evaluations across multiple dimensions show that the proposed approach consistently outperforms comparable baselines in animation video synthesis.",human
"The rapid growth of AI conference submissions has created an overwhelming reviewing burden. To alleviate this, recent venues such as ICLR 2026 introduced a reviewer nomination policy: each submission must nominate one of its authors as a reviewer, and any paper nominating an irresponsible reviewer is desk-rejected. We study this new policy from the perspective of author welfare. Assuming each author carries a probability of being irresponsible, we ask: how can authors (or automated systems) nominate reviewers to minimize the risk of desk rejections? We formalize and analyze three variants of the desk-rejection risk minimization problem. The basic problem, which minimizes expected desk rejections, is solved optimally by a simple greedy algorithm. We then introduce hard and soft nomination limit variants that constrain how many papers may nominate the same author, preventing widespread failures if one author is irresponsible. These formulations connect to classical optimization frameworks, including minimum-cost flow and linear programming, allowing us to design efficient, principled nomination strategies. Our results provide the first theoretical study for reviewer nomination policies, offering both conceptual insights and practical directions for authors to wisely choose which co-author should serve as the nominated reciprocal reviewer.",human
"Biological foundation models (BioFMs), pretrained on large-scale biological sequences, have recently shown strong potential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models often rely on millions to billions of training sequences and billions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessibility, particularly for academic labs. To address these challenges, we investigate the feasibility of data pruning for BioFM pretraining and propose a post-hoc influence-guided data pruning framework tailored to biological domains. Our approach introduces a subset-based self-influence formulation that enables efficient estimation of sample importance at low computational cost, and builds upon it two simple yet effective selection strategies, namely Top-k Influence (Top I) and Coverage-Centric Influence (CCI). We empirically validate our method on two representative BioFMs, RNA-FM and ESM-C. For RNA, our framework consistently outperforms random selection baselines under an extreme pruning rate of over 99 percent, demonstrating its effectiveness. Furthermore, we show the generalizability of our framework on protein-related tasks using ESM-C. In particular, our coreset even outperforms random subsets that are ten times larger in both RNA and protein settings, revealing substantial redundancy in biological sequence datasets. These findings underscore the potential of influence-guided data pruning to substantially reduce the computational cost of BioFM pretraining, paving the way for more efficient, accessible, and sustainable biological AI research.",human
"**Abstract** We address the problem of automated reasoning over complex knowledge graphs with incomplete or noisy information. Traditional approaches often struggle with scalability and robustness in the face of uncertainty. This paper introduces a novel graph neural network (GNN) architecture, termed Reasoning-Augmented Graph Transformer (RAGT), specifically designed to iteratively refine entity and relation representations through explicit reasoning steps. RAGT leverages a Transformer-based attention mechanism to dynamically weigh the importance of neighboring entities and relations, enabling the propagation of information across multiple hops within the graph. Furthermore, we incorporate a differentiable rule mining module, which identifies and encodes logical relationships from the observed data to further guide the reasoning process. We evaluate RAGT on several benchmark knowledge graph completion datasets, including WN18RR and FB15k-237. Experimental results demonstrate that RAGT significantly outperforms existing GNN-based and rule-based methods in terms of link prediction accuracy, achieving state-of-the-art performance. Ablation studies validate the effectiveness of both the attention mechanism and the rule mining module in contributing to the improved reasoning capabilities of the model. The proposed RAGT architecture offers a promising direction for enhancing automated reasoning over complex knowledge graphs in challenging real-world scenarios.",ai
"We investigate the problem of synthesizing logical forms for complex queries over knowledge graphs, addressing limitations in existing methods that struggle with compositional reasoning and the efficient exploration of large search spaces. Current approaches often rely on heuristic search or sequence-to-sequence models, facing challenges with scalability and generalization to unseen query structures. We propose a novel approach, (DNR-GPE), which combines differentiable neural reasoning with a guided graph path exploration strategy. DNR-GPE employs a graph neural network to encode the knowledge graph and a neural reasoning module to iteratively refine query representations based on evidence gathered from path traversal. Crucially, we introduce a reinforcement learning framework to train an agent that efficiently explores paths within the knowledge graph, focusing on relevant relations and entities. Experimental results on the ComplexWebQuestions and MetaQA datasets demonstrate that DNR-GPE significantly outperforms state-of-the-art baselines in terms of accuracy and efficiency. Specifically, we observe improvements of up to 8% in hit rate at rank 1 while simultaneously reducing the computational cost associated with reasoning. Furthermore, analysis reveals that the learned path exploration strategy effectively prioritizes informative paths, enabling faster convergence and improved generalization performance.",ai
"Image data collected in the wild often contains private information such as faces and license plates, and responsible data release must ensure that this information stays hidden. At the same time, released data should retain its usefulness for model-training. The standard method for private information obfuscation in images is Gaussian blurring. In this work, we show that practical implementations of Gaussian blurring are reversible enough to break privacy. We then take a closer look at the privacy-utility tradeoffs offered by three other obfuscation algorithms -- pixelization, pixelization and noise addition (DP-Pix), and cropping. Privacy is evaluated by reversal and discrimination attacks, while utility by the quality of the learnt representations when the model is trained on data with obfuscated faces. We show that the most popular industry-standard method, Gaussian blur is the least private of the four -- being susceptible to reversal attacks in its practical low-precision implementations. In contrast, pixelization and pixelization plus noise addition, when used at the right level of granularity, offer both privacy and utility for a number of computer vision tasks. We make our proposed methods together with suggested parameters available in a software package called Privacy Blur.",human
"We introduce MixtureKit, a modular open-source framework for constructing, training, and analyzing Mixture-of-Experts (MoE) models from arbitrary pre-trained or fine-tuned models. MixtureKit currently supports three complementary methods: (i) , which uses a single router per transformer block to select experts, (ii) (Branch-Train-Mix), which introduces separate routers for each specified sub-layer enabling fine-grained token routing, and (iii) (Branch-Train-Stitch), which keeps experts fully intact and introduces trainable stitch layers for controlled information exchange between hub and experts. MixtureKit automatically modifies the model configuration, patches decoder and causal LM classes, and saves a unified checkpoint ready for inference or fine-tuning. We further provide a visualization interface to inspect per-token routing decisions, expert weight distributions, and layer-wise contributions. Experiments with multilingual code-switched data (e.g. Arabic-Latin) show that a BTX-based model trained using MixtureKit can outperform baseline dense models on multiple benchmarks. We release MixtureKit as a practical foundation for research and development of MoE-based systems across diverse domains.",human
"Multiobjective reinforcement learning (MORL) poses significant challenges due to the inherent conflicts between objectives and the difficulty of adapting to dynamic environments. Traditional methods often struggle to generalize effectively, particularly in large and complex state-action spaces. To address these limitations, we introduce the Latent Causal Diffusion Model (LacaDM), a novel approach designed to enhance the adaptability of MORL in discrete and continuous environments. Unlike existing methods that primarily address conflicts between objectives, LacaDM learns latent temporal causal relationships between environmental states and policies, enabling efficient knowledge transfer across diverse MORL scenarios. By embedding these causal structures within a diffusion model-based framework, LacaDM achieves a balance between conflicting objectives while maintaining strong generalization capabilities in previously unseen environments. Empirical evaluations on various tasks from the MOGymnasium framework demonstrate that LacaDM consistently outperforms the state-of-art baselines in terms of hypervolume, sparsity, and expected utility maximization, showcasing its effectiveness in complex multiobjective tasks.",human
"We address the challenge of training machine learning models on sensitive data while preserving individual privacy. Existing approaches, such as federated learning and differential privacy, often suffer from performance degradation or limited applicability in complex model architectures. This work introduces a novel framework, Privacy-Preserving Knowledge Distillation with Adversarial Regularization (PPKD-AR), which leverages knowledge distillation to transfer learned information from a private teacher model to a public student model. The teacher model is trained on the sensitive dataset with differentially private stochastic gradient descent (DP-SGD), ensuring formal privacy guarantees. To mitigate the utility loss associated with DP-SGD, we introduce an adversarial regularization term during the student model's training. This term encourages the student model to learn representations that are indistinguishable from those of the teacher model while simultaneously preventing the student from memorizing sensitive information from the private dataset. We evaluate PPKD-AR on image classification tasks using MNIST and CIFAR-10 datasets. Our results demonstrate that PPKD-AR achieves significantly improved performance compared to standard DP-SGD baselines with comparable privacy budgets. Specifically, PPKD-AR improves the test accuracy by up to 15% while maintaining strong privacy guarantees. Furthermore, we show that the adversarial regularization effectively reduces the risk of privacy leakage from the student model, as measured by membership inference attacks. These findings suggest that PPKD-AR offers a promising approach for training high-performance machine learning models in privacy-sensitive settings.",ai
"LLMs have shown the capacity to improve their performance on reasoning tasks through reflecting on their mistakes, and acting with these reflections in mind. However, continual reflections of the same LLM onto itself exhibit degeneration of thought, where the LLM continues to repeat the same errors again and again even with the knowledge that its wrong. To address this problem, we instead introduce multi-agent with multi-persona debators as the method to generate reflections. Through out extensive experimentation, we've found that the leads to better diversity of in the reflections generated by the llm agent. We demonstrate an accuracy of 47% EM HotPot QA (question answering) and 82.7% on HumanEval (programming), both performances surpassing reflection with a single llm.",human
"We address the challenge of learning effective node representations in graph-structured data, particularly in scenarios with limited labeled examples and complex graph topologies. Graph Neural Networks (GNNs) have shown promise in this domain, but often struggle with over-smoothing and difficulty in capturing long-range dependencies. To mitigate these limitations, we propose a novel GNN architecture, Graph Attention with Spectral Propagation (GASP), which incorporates a spectral graph convolution layer within an attention-based message passing framework. GASP leverages the eigenvectors of the graph Laplacian to propagate information globally across the graph, addressing the over-smoothing problem by emphasizing lower-frequency components in the node embeddings. Simultaneously, the attention mechanism allows for adaptive weighting of neighbor information based on node features, enabling the model to capture complex relationships and focus on salient features. We evaluate GASP on a variety of benchmark graph datasets, including node classification tasks on Cora, Citeseer, and Pubmed. Experimental results demonstrate that GASP consistently outperforms existing GNN architectures, achieving significant improvements in node classification accuracy, particularly in low-label regimes. Furthermore, ablation studies validate the efficacy of both the spectral propagation and attention mechanisms in enhancing the representational power of the network. The proposed GASP architecture offers a robust and scalable solution for learning node representations in complex graph-structured data.",ai
"Clinical MRI encompasses diverse imaging protocols--spanning anatomical targets (cardiac, brain, knee), contrasts (T1, T2, mapping), sampling patterns (Cartesian, radial, spiral, kt-space), and acceleration factors--yet current deep learning reconstructions are typically protocol-specific, hindering generalization and deployment. We introduce Scalable Deep Unrolled Model (SDUM), a universal framework combining a Restormer-based reconstructor, a learned coil sensitivity map estimator (CSME), sampling-aware weighted data consistency (SWDC), universal conditioning (UC) on cascade index and protocol metadata, and progressive cascade expansion training. SDUM exhibits foundation-model-like scaling behavior: reconstruction quality follows PSNR log(parameters) with correlation () up to 18 cascades, demonstrating predictable performance gains with model depth. A single SDUM trained on heterogeneous data achieves state-of-the-art results across all four CMRxRecon2025 challenge tracks--multi-center, multi-disease, 5T, and pediatric--without task-specific fine-tuning, surpassing specialized baselines by up to ~dB. On CMRxRecon2024, SDUM outperforms the winning method PromptMR+ by ~dB; on fastMRI brain, it exceeds PC-RNN by ~dB. Ablations validate each component: SWDC ~dB over standard DC, per-cascade CSME ~dB, UC ~dB. These results establish SDUM as a practical path toward universal, scalable MRI reconstruction.",human
"Graph Neural Networks (GNNs) have demonstrated efficacy in learning representations for graph-structured data across diverse applications. However, the susceptibility of GNNs to adversarial attacks, particularly graph structure perturbations, remains a significant concern. Existing defense mechanisms often suffer from scalability issues or require substantial prior knowledge of the attack strategy. This work addresses the problem of robust GNN learning in the presence of adversarial edge manipulations. We propose a novel framework, termed Graph Structure Denoising via Spectral Filtering (GSDF), that leverages spectral graph theory to identify and mitigate the impact of adversarial edges. GSDF employs a low-pass spectral filter to smooth the graph adjacency matrix, effectively attenuating high-frequency noise introduced by adversarial perturbations. The filtered adjacency matrix is then used to train a GNN model, promoting robustness to structural variations. Empirical evaluation on benchmark graph datasets demonstrates that GSDF achieves significant improvements in node classification accuracy under various adversarial attack scenarios, outperforming state-of-the-art defense methods. Moreover, GSDF exhibits superior scalability compared to computationally expensive methods such as adversarial training, making it a practical solution for large-scale graph analysis. Our findings highlight the potential of spectral filtering as a powerful tool for enhancing the robustness of GNNs against adversarial attacks.",ai
"Recent advances in Natural Language Processing (NLP) have been significantly driven by the Transformer architecture, demonstrating state-of-the-art performance across a wide range of tasks. However, challenges persist in effectively capturing long-range dependencies and contextual nuances, particularly when dealing with lengthy input sequences. This paper investigates a novel approach to enhance Transformer-based models for improved contextual understanding and long-range dependency modeling. We introduce a Hierarchical Attention Transformer (HAT) architecture, which incorporates a multi-layered attention mechanism operating at different levels of abstraction. The HAT model first aggregates local context through standard self-attention within fixed-size segments. Subsequently, a higher-level attention layer operates across these segment representations, enabling the model to capture inter-segment dependencies and global contextual information. We evaluate the HAT architecture on benchmark datasets for long document summarization (PubMed) and question answering (HotpotQA). Experimental results demonstrate that the HAT model outperforms baseline Transformer models and existing hierarchical attention mechanisms. Specifically, we observe a 2.5% improvement in ROUGE-L score on the PubMed summarization task and a 1.8% increase in F1 score on the HotpotQA dataset, indicating enhanced ability to handle long-range dependencies and complex contextual reasoning. These findings suggest that the proposed HAT architecture provides a promising direction for advancing Transformer-based models in NLP.",ai
"We investigate the problem of improving the robustness of neural text classifiers against adversarial attacks in low-resource scenarios. Specifically, we focus on text classification tasks where labeled data is scarce and adversarial examples can significantly degrade model performance. Current adversarial training methods often require substantial computational resources and large datasets, rendering them impractical in such settings. We propose a novel robust optimization framework, termed Language Model Guided Adversarial Training (LMGAT), that leverages a pre-trained language model to generate more realistic and diverse adversarial examples. LMGAT utilizes the language model's contextual understanding to constrain the adversarial perturbation space, focusing on semantically plausible alterations. This reduces the risk of generating nonsensical or easily detectable adversarial instances, thereby enhancing the effectiveness of the adversarial training process. We evaluate LMGAT on several benchmark text classification datasets under low-resource conditions. Our results demonstrate that LMGAT significantly outperforms existing adversarial training methods in terms of both adversarial robustness and clean accuracy. Furthermore, we show that LMGAT requires fewer labeled examples than traditional approaches to achieve comparable robustness levels, making it a more practical solution for robust text classification in low-resource scenarios. We provide an ablation study demonstrating the impact of key components of the LMGAT framework.",ai
"Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.",human
"## Abstract We address the problem of sample inefficiency in reinforcement learning (RL) when applied to complex, high-dimensional environments with sparse rewards. Traditional RL algorithms often require an impractically large number of interactions to converge to a satisfactory policy. To mitigate this issue, we propose a novel approach termed ""Guided Exploration via Latent Space Dynamics"" (GELS-D), which leverages a learned latent space representation of the environment to guide exploration and facilitate knowledge transfer. GELS-D employs a Variational Autoencoder (VAE) to encode high-dimensional observations into a lower-dimensional latent space, capturing the underlying structure of the environment. Within this latent space, a dynamics model is trained to predict future latent states given an action. This model is then used to generate intrinsic rewards for the agent, encouraging exploration of regions of the latent space that are both novel and potentially reachable. We evaluate GELS-D on a suite of challenging benchmark environments, including robotic manipulation and locomotion tasks with sparse rewards. Results demonstrate that GELS-D significantly improves sample efficiency compared to state-of-the-art RL algorithms, achieving up to a 4x reduction in the number of environment interactions required to reach a target performance level. Furthermore, ablation studies confirm the importance of both the latent space representation and the dynamics model in guiding effective exploration.",ai
"**Abstract:** We address the problem of synthesizing inductive invariants for verifying safety properties of parameterized concurrent programs. Existing techniques often struggle with complex data structures and intricate control flow, leading to scalability issues. We propose a novel approach leveraging a counterexample-guided inductive synthesis (CEGIS) framework integrated with symbolic execution and abstract interpretation. Our method iteratively refines candidate invariants by analyzing counterexamples generated from symbolic execution of the program. These counterexamples are then abstracted using predicate abstraction, guiding the search for stronger invariants. A key contribution lies in a new abstraction refinement strategy based on weakest preconditions, enabling the efficient discovery of invariants that relate program variables across multiple processes. We evaluate our approach on a benchmark suite of parameterized concurrent programs, demonstrating significant improvements in both the success rate and runtime compared to state-of-the-art invariant generation tools. Specifically, our system successfully synthesized invariants for 85% of the benchmarks, achieving an average speedup of 2.3x over the next best performing tool. These results suggest that our CEGIS-based approach, combined with targeted abstraction refinement, provides a powerful means for automatically verifying complex concurrent systems.",ai
"Vision--Language Models (VLMs) show significant promise for Medical Visual Question Answering (VQA), yet their deployment in clinical settings is hindered by severe vulnerability to adversarial attacks. Standard adversarial training, while effective for simpler tasks, often degrades both generalization performance and the quality of generated clinical reasoning. We introduce SafeMed-R1, a hybrid defense framework that ensures robust performance while preserving high-quality, interpretable medical reasoning. SafeMed-R1 employs a two-stage approach: at training time, we integrate Adversarial Training with Group Relative Policy Optimization (AT-GRPO) to explicitly robustify the reasoning process against worst-case perturbations; at inference time, we augment the model with Randomized Smoothing to provide certified -norm robustness guarantees. We evaluate SafeMed-R1 on the OmniMedVQA benchmark across eight medical imaging modalities comprising over 88,000 samples. Our experiments reveal that standard fine-tuned VLMs, despite achieving 95\% accuracy on clean inputs, collapse to approximately 25\% under PGD attacks. In contrast, SafeMed-R1 maintains 84.45\% accuracy under the same adversarial conditions, representing a 59 percentage point improvement in robustness. Furthermore, we demonstrate that models trained with explicit chain-of-thought reasoning exhibit superior adversarial robustness compared to instruction-only variants, suggesting a synergy between interpretability and security in medical AI systems.",human
"We address the challenge of robust causal effect estimation in observational studies with high-dimensional confounders and potential hidden confounding. Traditional methods often struggle with model misspecification or require strong assumptions about confounder selection. We propose a novel approach, Instrumental Bayesian Causal Forests (IBCF), which leverages instrumental variables (IVs) within a Bayesian Causal Forest (BCF) framework. IBCF employs a two-stage least squares (2SLS) procedure within each tree-building iteration of the BCF, utilizing the IV to predict the treatment variable, thereby mitigating the impact of observed confounders. The residuals from this first-stage prediction, along with the original covariates, are then used for outcome prediction in the second stage. This iterative partitioning and averaging allows for non-linear effect estimation and reduces bias due to hidden confounding conditional on the IV validity assumption. Through extensive simulations across various causal structures and confounder complexities, we demonstrate that IBCF outperforms existing methods such as standard BCF, doubly robust estimators, and linear IV regression, particularly when faced with model misspecification and strong confounding. Empirically, we also apply IBCF to a real-world healthcare dataset and show improved performance in estimating the effect of a medical intervention compared to benchmark models, providing more reliable insights for decision-making.",ai
"Computational point-of-care (POC) sensors enable rapid, low-cost, and accessible diagnostics in emergency, remote and resource-limited areas that lack access to centralized medical facilities. These systems can utilize neural network-based algorithms to accurately infer a diagnosis from the signals generated by rapid diagnostic tests or sensors. However, neural network-based diagnostic models are subject to hallucinations and can produce erroneous predictions, posing a risk of misdiagnosis and inaccurate clinical decisions. To address this challenge, here we present an autonomous uncertainty quantification technique developed for POC diagnostics. As our testbed, we used a paper-based, computational vertical flow assay (xVFA) platform developed for rapid POC diagnosis of Lyme disease, the most prevalent tick-borne disease globally. The xVFA platform integrates a disposable paper-based assay, a handheld optical reader and a neural network-based inference algorithm, providing rapid and cost-effective Lyme disease diagnostics in under 20 min using only 20 uL of patient serum. By incorporating a Monte Carlo dropout (MCDO)-based uncertainty quantification approach into the diagnostics pipeline, we identified and excluded erroneous predictions with high uncertainty, significantly improving the sensitivity and reliability of the xVFA in an autonomous manner, without access to the ground truth diagnostic information of patients. Blinded testing using new patient samples demonstrated an increase in diagnostic sensitivity from 88.2% to 95.7%, indicating the effectiveness of MCDO-based uncertainty quantification in enhancing the robustness of neural network-driven computational POC sensing systems.",human
"**Abstract:** Accurate and efficient segmentation of anatomical structures in medical imaging is crucial for diagnosis, treatment planning, and disease monitoring. However, the inherent complexity of medical images, characterized by low contrast, noise, and inter-patient variability, presents a significant challenge to automated segmentation approaches. This work addresses the problem of robust and precise segmentation of multiple organs in abdominal CT scans. We propose a novel deep learning framework based on a cascade of 3D convolutional neural networks (CNNs). The framework incorporates a coarse-to-fine strategy, where an initial network performs a global localization of the organs followed by subsequent networks refining the segmentation boundaries at higher resolution. Furthermore, we introduce a spatially-aware attention mechanism that emphasizes relevant anatomical regions, mitigating the effects of noisy or ambiguous features. The proposed method was evaluated on a publicly available dataset of abdominal CT scans containing annotations for multiple organs. Quantitative results demonstrate a significant improvement in segmentation accuracy, achieving an average Dice Similarity Coefficient (DSC) of 0.89 across all organs, outperforming state-of-the-art methods by a margin of 3%. Qualitative analysis further validates the robustness and generalization capability of the proposed framework in handling challenging image artifacts and anatomical variations. These results suggest that our approach offers a promising solution for automated multi-organ segmentation in medical imaging.",ai
"Psychological defenses are strategies, often automatic, that people use to manage distress. Rigid or overuse of defenses is negatively linked to mental health and shapes what speakers disclose and how they accept or resist help. However, defenses are complex and difficult to reliably measure, particularly in clinical dialogues. We introduce PsyDefConv, a dialogue corpus with help seeker utterances labeled for defense level, and DMRS Co-Pilot, a four-stage pipeline that provides evidence-based pre-annotations. The corpus contains 200 dialogues and 4709 utterances, including 2336 help seeker turns, with labeling and Cohen's kappa 0.639. In a counterbalanced study, the co-pilot reduced average annotation time by 22.4%. In expert review, it averaged 4.62 for evidence, 4.44 for clinical plausibility, and 4.40 for insight on a seven-point scale. Benchmarks with strong language models in zero-shot and fine-tuning settings demonstrate clear headroom, with the best macro F1-score around 30% and a tendency to overpredict mature defenses. Corpus analyses confirm that mature defenses are most common and reveal emotion-specific deviations. We will release the corpus, annotations, code, and prompts to support research on defensive functioning in language.",human
"**Transformer Architectures for Enhanced Natural Language Processing Tasks** Transformer-based architectures have achieved state-of-the-art performance across a wide range of Natural Language Processing (NLP) tasks. However, challenges remain in efficiently processing long sequences, mitigating the quadratic computational complexity associated with self-attention, and improving performance on tasks requiring nuanced contextual understanding. This work investigates novel modifications to the standard transformer architecture to address these limitations. We propose a hybrid attention mechanism that combines global attention with localized convolutions, thereby reducing computational cost while preserving long-range dependencies. Furthermore, we introduce a dynamic routing strategy for attention weights, enabling the model to selectively attend to relevant information and filter out noise. Experiments conducted on benchmark datasets for machine translation, text summarization, and question answering demonstrate significant improvements over existing transformer variants. Specifically, our proposed architecture achieves a 2.5 BLEU score increase on the WMT'14 English-German translation task and a 1.8 ROUGE-L score increase on the CNN/DailyMail summarization dataset, while simultaneously reducing computational time by approximately 15% compared to the standard transformer model. These results highlight the efficacy of our proposed approach in enhancing the efficiency and performance of transformers for diverse NLP applications.",ai
"We present a novel methodology for the automated detection of pulmonary nodules in computed tomography (CT) scans, addressing the critical challenge of early lung cancer diagnosis. The proposed approach leverages a multi-stage convolutional neural network (CNN) architecture, initially employing a 3D U-Net variant for robust lung segmentation, thereby reducing the computational burden on subsequent stages and mitigating false positive detections outside the lung parenchyma. This segmented region of interest is then processed by a refined Faster R-CNN model, pre-trained on ImageNet and fine-tuned using a curated dataset of annotated CT scans. Crucially, the Faster R-CNN is augmented with a contextual feature embedding module that integrates information from adjacent slices in the axial plane, improving the model's ability to differentiate between true nodules and spurious structures such as vessels and bronchioles. Evaluation on the LIDC-IDRI database demonstrates a significant improvement in sensitivity at 0.25 false positives per scan, achieving a score of 0.88, compared to a baseline Faster R-CNN model without contextual feature integration, which achieves 0.81. The results indicate the efficacy of the proposed multi-stage approach with contextual awareness for enhancing nodule detection performance in medical imaging.",ai
"Semantic distance measurement is a fundamental problem in computational linguistics, providing a quantitative characterization of similarity or relatedness between text segments, and underpinning tasks such as text retrieval and text classification. From a mathematical perspective, a semantic distance can be viewed as a metric defined on a space of texts or on a representation space derived from them. However, most classical semantic distance methods are essentially fixed, making them difficult to adapt to specific data distributions and task requirements. In this paper, a semantic distance measure based on multi-kernel Gaussian processes (MK-GP) was proposed. The latent semantic function associated with texts was modeled as a Gaussian process, with its covariance function given by a combined kernel combining MatÃ©rn and polynomial components. The kernel parameters were learned automatically from data under supervision, rather than being hand-crafted. This semantic distance was instantiated and evaluated in the context of fine-grained sentiment classification with large language models under an in-context learning (ICL) setup. The experimental results demonstrated the effectiveness of the proposed measure.",human
"Sparse neural systems are gaining traction for efficient continual learning due to their modularity and low interference. Architectures such as Sparse Distributed Memory Multi-Layer Perceptrons (SDMLP) construct task-specific subnetworks via Top-K activation and have shown resilience against catastrophic forgetting. However, their rigid modularity limits cross-task knowledge reuse and leads to performance degradation under high sparsity. We propose Selective Subnetwork Distillation (SSD), a structurally guided continual learning framework that treats distillation not as a regularizer but as a topology-aligned information conduit. SSD identifies neurons with high activation frequency and selectively distills knowledge within previous Top-K subnetworks and output logits, without requiring replay or task labels. This enables structural realignment while preserving sparse modularity. Experiments on Split CIFAR-10, CIFAR-100, and MNIST demonstrate that SSD improves accuracy, retention, and representation coverage, offering a structurally grounded solution for sparse continual learning.",human
"Equivariance is a powerful prior for learning physical dynamics, yet exact group equivariance can degrade performance if the symmetries are broken. We propose object-centric world models built with geometric algebra neural networks, providing a soft geometric inductive bias. Our models are evaluated using simulated environments of 2d rigid body dynamics with static obstacles, where we train for next-step predictions autoregressively. For long-horizon rollouts we show that the soft inductive bias of our models results in better performance in terms of physical fidelity compared to non-equivariant baseline models. The approach complements recent soft-equivariance ideas and aligns with the view that simple, well-chosen priors can yield robust generalization. These results suggest that geometric algebra offers an effective middle ground between hand-crafted physics and unstructured deep nets, delivering sample-efficient dynamics models for multi-object scenes.",human
"The matrix exponential is a fundamental operator in scientific computing and system simulation, with applications ranging from control theory and quantum mechanics to modern generative machine learning. While PadÃ© approximants combined with scaling and squaring have long served as the standard, recent Taylor-based methods, which utilize polynomial evaluation schemes that surpass the classical Paterson--Stockmeyer technique, offer superior accuracy and reduced computational complexity. This paper presents an optimized Taylor-based algorithm for the matrix exponential, specifically designed for the high-throughput requirements of generative AI flows. We provide a rigorous error analysis and develop a dynamic selection strategy for the Taylor order and scaling factor to minimize computational effort under a prescribed error tolerance. Extensive numerical experiments demonstrate that our approach provides significant acceleration and maintains high numerical stability compared to existing state-of-the-art implementations. These results establish the proposed method as a highly efficient tool for large-scale generative modeling.",human
"The proliferation of Large Language Models (LLMs) raises a critical question about what it means to be human when we share an increasingly symbiotic relationship with persuasive and creative machines. This paper examines patterns of human-AI coevolution in creative writing, investigating how human craft and agency are adapting alongside machine capabilities. We challenge the prevailing notion of stylistic homogenization by examining diverse patterns in longitudinal writing data. Using a large-scale corpus spanning the pre- and post-LLM era, we observe patterns suggestive of a ""Dual-Track Evolution"": thematic convergence around AI-related topics, coupled with structured stylistic differentiation. Our analysis reveals three emergent adaptation patterns: authors showing increased similarity to AI style, those exhibiting decreased similarity, and those maintaining stylistic stability while engaging with AI-related themes. This Creative Archetype Map illuminates how authorship is coevolving with AI, contributing to discussions about human-AI collaboration, detection challenges, and the preservation of creative diversity.",human
"We address the challenge of constructing structured knowledge representations from unstructured text data, a persistent bottleneck in automated knowledge acquisition. Current approaches often rely on handcrafted ontologies or struggle to capture nuanced relationships beyond simple co-occurrence. We introduce a novel method, Hierarchical Relational Embedding (HiRE), which integrates distributed semantic representations with a probabilistic graphical model to infer hierarchical relationships between entities extracted from text corpora. HiRE leverages pre-trained language models to generate initial entity embeddings, subsequently refined through a relational graph convolutional network that propagates information based on observed textual relationships. The inferred relationships are then subjected to a hierarchical clustering algorithm, guided by a novel metric that balances semantic similarity and relational strength, resulting in a tree-structured knowledge representation. We evaluate HiRE on benchmark datasets for relation extraction and knowledge graph construction, demonstrating significant improvements in both link prediction accuracy and ontological coherence compared to state-of-the-art baselines. Specifically, HiRE achieves a 15% increase in mean average precision for relation extraction and a 10% improvement in normalized discounted cumulative gain for ontological similarity assessment. These results indicate that HiRE effectively captures complex relational patterns and facilitates the construction of semantically rich and structurally sound knowledge representations.",ai
"**Abstract:** Privacy-preserving machine learning (PPML) addresses the challenge of training and deploying machine learning models without compromising the confidentiality of sensitive data. This work investigates the application of federated learning (FL) combined with differential privacy (DP) to mitigate privacy risks in distributed datasets. We focus on the problem of vertical federated learning (VFL), where multiple parties possess distinct feature sets for the same entities and aim to collaboratively train a model without directly sharing their data. Our proposed method, FedDiff, leverages a secure aggregation protocol in conjunction with a novel adaptive clipping mechanism for DP noise injection. This adaptive clipping is crucial for balancing privacy guarantees and model utility, especially when dealing with heterogeneous data distributions across participants. We implement FedDiff and evaluate its performance on a real-world medical dataset, demonstrating its efficacy in achieving a reasonable trade-off between model accuracy and privacy protection, as measured by the Îµ-DP parameter. Experimental results indicate that FedDiff consistently outperforms existing DP-based VFL approaches, yielding a significant improvement in model performance while maintaining comparable privacy levels. Furthermore, we analyze the impact of varying data heterogeneity and privacy budgets on the utility of the trained models. These findings provide valuable insights into the practical deployment of PPML solutions in real-world scenarios involving sensitive data.",ai
"Recent advances in large language models (LLMs) show impressive performance in open-ended story generation, but fine-grained stylistic control remains limited. Existing methods often rely on shallow cues (e.g., names or topics) to simulate authorial style, without robust evaluation. In this work, we present a training framework for style-conditioned story generation using Group Relative Policy Optimization (GRPO) and a custom multi-reward setup. The style reward is derived from a fine-tuned sentence transformer using authorship verification (AV) signals, combined with content and completeness scores to stabilize long-form narrative generation. We conduct experiments using fiction by Mark Twain, a prominent 19th-century American author, with The Adventures of Huckleberry Finn serving as the reference style exemplar. Our 8B model outperforms larger baselines such as GPT-4o and Claude Sonnet 4 in AV-style metrics, achieving a style score of 0.628 and competitive content quality. Results demonstrate the feasibility of agentic stylistic generation with moderate model size and task-specific training. While the output is clearly style-aligned, narrative completeness remains a challenge, indicating future work is needed to better model global coherence and story resolution.",human
"Disclaimer: Samples in this paper may be harmful and cause discomfort. Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks, especially under adversarial triggers that late, opaque training-free detoxification methods struggle to handle. We propose SGM, a white-box neuron-level multimodal intervention that acts like safety glasses for toxic neurons: it selectively recalibrates a small set of toxic expert neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without any parameter updates. We establish MM-TOXIC-QA, a multimodal toxicity evaluation framework, and compare SGM with existing detoxification techniques. Experiments on open-source MLLMs show that SGM mitigates toxicity in standard and adversarial conditions, cutting harmful rates from 48.2\% to 2.5\% while preserving fluency and multimodal reasoning. SGM is extensible, and its combined defenses, denoted as SGM*, integrate with existing detoxification methods for stronger safety performance, providing an interpretable, low-cost solution for toxicity-controlled multimodal generation.",human
"In Data Science, entities are typically represented by single valued measurements. Symbolic Data Analysis extends this framework to more complex structures, such as intervals and histograms, that express internal variability. We propose an extension of multiclass Fisher's Discriminant Analysis to interval-valued data, using Moore's interval arithmetic and the Mallows' distance. Fisher's objective function is generalised to consider simultaneously the contributions of the centres and the ranges of intervals and is numerically maximised. The resulting discriminant directions are then used to classify interval-valued observations.To support visual assessment, we adapt the class map, originally introduced for conventional data, to classifiers that assign labels through minimum distance rules. We also extend the silhouette plot to this setting and use stacked mosaic plots to complement the visual display of class assignments. Together, these graphical tools provide insight into classifier performance and the strength of class membership. Applications to real datasets illustrate the proposed methodology and demonstrate its value in interpreting classification results for interval-valued data.",human
"Large Language Model agents face fundamental challenges in adapting to novel tasks due to limitations in tool availability and experience reuse. Existing approaches either rely on predefined tools with limited coverage or build tools from scratch without leveraging past experiences, leading to inefficient exploration and suboptimal performance. We introduce SMITH (Shared Memory Integrated Tool Hub), a unified cognitive architecture that seamlessly integrates dynamic tool creation with cross-task experience sharing through hierarchical memory organization. SMITH organizes agent memory into procedural, semantic, and episodic components, enabling systematic capability expansion while preserving successful execution patterns. Our approach formalizes tool creation as iterative code generation within controlled sandbox environments and experience sharing through episodic memory retrieval with semantic similarity matching. We further propose a curriculum learning strategy based on agent-ensemble difficulty re-estimation. Extensive experiments on the GAIA benchmark demonstrate SMITH's effectiveness, achieving 81.8% Pass@1 accuracy and outperforming state-of-the-art baselines including Alita (75.2%) and Memento (70.9%). Our work establishes a foundation for building truly adaptive agents that continuously evolve their capabilities through principled integration of tool creation and experience accumulation.",human
"We investigate the problem of enhancing automated reasoning capabilities in complex, multi-step inference tasks. Many existing approaches rely on explicitly pre-defined rules or extensive training data, limiting their generalization to unseen scenarios or requiring significant computational resources. We propose a novel framework, termed *Neural Logic Weaver (NLW)*, which combines neural network-based representation learning with symbolic logic manipulation. NLW utilizes a graph neural network to encode complex relationships within a knowledge graph and learns to probabilistically generate logical inference rules based on observed patterns. These generated rules are then compiled into a differentiable logic program, enabling end-to-end training with respect to task-specific objectives. We evaluated NLW on a series of benchmark knowledge graph completion and question answering tasks. Our results demonstrate that NLW achieves significant improvements in accuracy and generalization compared to state-of-the-art rule-based and neural reasoning models. Specifically, NLW outperforms existing methods by an average of 15% in link prediction tasks on unseen knowledge graph entities and relations, and demonstrates robust performance in answering complex reasoning questions requiring multiple inference steps. These findings suggest that NLW provides a promising approach for bridging the gap between statistical learning and symbolic reasoning, enabling more robust and adaptable automated reasoning systems.",ai
"Large Language Models (LLMs) have demonstrated remarkable capabilities across various natural language processing tasks. This research introduces a novel ""Prompting-in-a-Series"" algorithm, termed PICEPR (Psychology-Informed Contents Embeddings for Personality Recognition), featuring two pipelines: (a) Contents and (b) Embeddings. The approach demonstrates how a modularised decoder-only LLM can summarize or generate content, which can aid in classifying or enhancing personality recognition functions as a personality feature extractor and a generator for personality-rich content. We conducted various experiments to provide evidence to justify the rationale behind the PICEPR algorithm. Meanwhile, we also explored closed-source models such as from OpenAI and from Google, along with open-source models like from Mistral AI, to compare the quality of the generated content. The PICEPR algorithm has achieved a new state-of-the-art performance for personality recognition by 5-15\% improvement. The work repository and models' weight can be found at https://research.jingjietan.com/?q=PICEPR.",human
"Infographic Visual Question Answering (InfographicVQA) evaluates a model's ability to read and reason over data-rich, layout-heavy visuals that combine text, charts, icons, and design elements. Compared with scene-text or natural-image VQA, infographics require stronger integration of OCR, layout understanding, and numerical and semantic reasoning. We introduce ViInfographicVQA, the first benchmark for Vietnamese InfographicVQA, comprising over 6747 real-world infographics and 20409 human-verified question-answer pairs across economics, healthcare, education, and more. The benchmark includes two evaluation settings. The Single-image task follows the traditional setup in which each question is answered using a single infographic. The Multi-image task requires synthesizing evidence across multiple semantically related infographics and is, to our knowledge, the first Vietnamese evaluation of cross-image reasoning in VQA. We evaluate a range of recent vision-language models on this benchmark, revealing substantial performance disparities, with the most significant errors occurring on Multi-image questions that involve cross-image integration and non-span reasoning. ViInfographicVQA contributes benchmark results for Vietnamese InfographicVQA and sheds light on the limitations of current multimodal models in low-resource contexts, encouraging future exploration of layout-aware and cross-image reasoning methods.",human
"Ensuring content safety in large language models (LLMs) is essential for their deployment in real-world applications. However, existing safety guardrails are predominantly tailored for high-resource languages, leaving a significant portion of the world's population underrepresented who communicate in low-resource languages. To address this, we introduce CREST (CRoss-lingual Efficient Safety Transfer), a parameter-efficient multilingual safety classification model that supports 100 languages with only 0.5B parameters. By training on a strategically chosen subset of only 13 high-resource languages, our model utilizes cluster-based cross-lingual transfer from a few to 100 languages, enabling effective generalization to both unseen high-resource and low-resource languages. This approach addresses the challenge of limited training data in low-resource settings. We conduct comprehensive evaluations across six safety benchmarks to demonstrate that CREST outperforms existing state-of-the-art guardrails of comparable scale and achieves competitive results against models with significantly larger parameter counts (2.5B parameters and above). Our findings highlight the limitations of language-specific guardrails and underscore the importance of developing universal, language-agnostic safety systems that can scale effectively to serve global populations.",human
"We address the critical challenge of training machine learning models on sensitive data while preserving individual privacy. Specifically, we consider scenarios where data owners are unwilling to directly share their raw data with a centralized training entity. Our research investigates a novel federated learning framework enhanced with differential privacy mechanisms. This framework leverages a client-level differentially private stochastic gradient descent (DP-SGD) algorithm, adapted to minimize the impact on model utility in non-IID data distributions, a common characteristic of federated learning environments. We introduce a dynamically adjusted clipping norm for DP-SGD, mitigating the negative effects of gradient explosion induced by heterogeneous data. Empirical evaluation on benchmark datasets, including CIFAR-10 and MNIST, demonstrates that our proposed method achieves significantly improved trade-offs between privacy and accuracy compared to standard DP-SGD approaches in federated settings. Specifically, we observe a 5-8% accuracy gain at equivalent privacy budgets (Îµ â‰¤ 10, Î´ = 10^-5), indicating enhanced model utility without compromising privacy guarantees. Further, we provide a rigorous privacy analysis using RÃ©nyi Differential Privacy, deriving tight bounds on the privacy loss incurred during the training process. Our results highlight the potential of our approach for practical privacy-preserving machine learning deployments in decentralized data environments.",ai
"Graph Neural Networks (GNNs) have demonstrated remarkable success in various domains, particularly those involving relational data represented as graphs. However, many real-world graphs are characterized by heterogeneity, encompassing diverse node and edge types with complex inter-type relationships. Existing GNN models often struggle to effectively capture and utilize this heterogeneous information, leading to suboptimal performance. This work introduces a novel Heterogeneous Graph Attention Network with Type-Aware Aggregation (HetGAT-TAA) to address this limitation. HetGAT-TAA leverages type embeddings to encode the distinct characteristics of each node and edge type. Crucially, it incorporates a type-aware attention mechanism that dynamically weights the importance of neighboring nodes based on both their feature representations and their type relationships. Furthermore, it employs a hierarchical aggregation scheme, first aggregating information within each type separately, and then combining these type-specific aggregations into a comprehensive node representation. We evaluate HetGAT-TAA on several benchmark datasets for node classification and link prediction tasks on heterogeneous graphs. Our experimental results demonstrate that HetGAT-TAA significantly outperforms state-of-the-art GNN models, achieving improvements of up to 8% in node classification accuracy and 5% in link prediction AUC, highlighting the effectiveness of type-aware aggregation in capturing complex relationships within heterogeneous graphs.",ai
"## Cooperative Task Allocation via Decentralized Reinforcement Learning with Communication Constraints We address the challenge of cooperative task allocation in multi-agent systems operating under communication constraints, where agents must collectively decide which tasks to perform to maximize a global reward. This problem is particularly difficult when agents possess limited communication bandwidth, hindering their ability to share information and coordinate effectively. We propose a novel decentralized reinforcement learning algorithm that combines a Graph Neural Network (GNN) for state representation learning with a proximal policy optimization (PPO) framework for policy learning. The GNN enables agents to aggregate information from their local neighborhood, accounting for communication limitations by weighting messages based on the available bandwidth and perceived value of information. This learned weighting allows agents to prioritize critical information sharing, mitigating the negative impacts of communication bottlenecks. Experimental results on a simulated resource allocation environment demonstrate that our approach significantly outperforms traditional decentralized PPO and alternative GNN-based methods under various communication constraints. Specifically, our algorithm achieves a 15-25% improvement in cumulative reward compared to baseline methods when communication bandwidth is severely limited, highlighting its robustness and efficiency in challenging cooperative scenarios. Further analysis reveals that the learned communication patterns adapt dynamically to the task requirements and network topology, enabling effective coordination even with sparse communication.",ai
"We address the challenge of training machine learning models on sensitive data while providing formal privacy guarantees. Existing methods often suffer from either significant utility degradation or limitations in scalability and applicability to complex model architectures. We propose a novel differentially private training framework based on a two-stage approach combining gradient perturbation and model parameter aggregation. Specifically, we employ a calibrated Gaussian mechanism to perturb gradients during stochastic gradient descent, followed by a novel aggregation technique that leverages a hierarchical Bayesian model to estimate and remove systematic biases introduced by the noise injection. This Bayesian aggregation step allows us to reduce the effective noise level without violating differential privacy. We evaluate our method on image classification (CIFAR-10) and language modeling (Penn Treebank) tasks using deep neural networks. Empirical results demonstrate that our approach significantly outperforms state-of-the-art differentially private training algorithms in terms of model accuracy, achieving comparable performance to non-private training under moderate privacy budgets (Îµ â‰¤ 8). Furthermore, our framework exhibits improved robustness to hyperparameter tuning and scales effectively to larger datasets and more complex model architectures. Our findings suggest that the proposed combination of gradient perturbation and Bayesian aggregation provides a promising avenue for practical privacy-preserving machine learning.",ai
"Large Language Models (LLMs) have become integral to software engineering workflows, yet their effectiveness degrades significantly in multi-turn conversations. Recent studies demonstrate an average 39% performance drop when instructions are delivered across multiple turns, with models making premature assumptions and failing to course correct (Laban et al., 2025). This degradation is particularly problematic in exploratory programming tasks where developers need to investigate alternative approaches without committing to a single path. Current solutions force users into a false dichotomy: continue in a context-polluted conversation where the LLM becomes increasingly confused, or start fresh and lose all accumulated context. We present ContextBranch, a conversation management system that applies version control semantics to LLM interactions. ContextBranch provides four core primitives--checkpoint, branch, switch, and inject--enabling users to capture conversation state, explore alternatives in isolation, and selectively merge insights. We evaluate ContextBranch through a controlled experiment with 30 software engineering scenarios featuring intentionally polluting explorations. Branched conversations achieved higher response quality compared to linear conversations, with large improvements in focus and context awareness. Benefits were concentrated in complex scenarios involving conceptually distant explorations. Branching reduced context size by 58.1% (31.0 to 13.0 messages), eliminating irrelevant exploratory content. Our work establishes conversation branching as a fundamental primitive for AI-assisted exploratory work, demonstrating that isolation prevents context pollution when exploring alternatives.",human
"We address the problem of identifying causal effects in natural language processing (NLP) tasks where observational data is confounded by latent variables. Existing methods often rely on strong assumptions about the functional form of causal relationships or require interventions, which are often impractical in real-world NLP scenarios. This work introduces a novel framework, Causal-BERT, leveraging recent advances in representation learning and causal discovery. Causal-BERT utilizes a pre-trained BERT model to generate contextualized representations of textual data, subsequently employing the Greedy Equivalence Search (GES) algorithm to infer a causal graph among observed variables and latent confounders. We then apply the adjustment set criterion, identified from the inferred graph, to estimate the average treatment effect (ATE) of interventions on specific linguistic features (e.g., sentiment polarity) on downstream NLP tasks (e.g., text classification). Experiments on benchmark datasets demonstrate that Causal-BERT significantly reduces bias in causal effect estimation compared to baseline methods that ignore confounding, achieving an average improvement of 8-12% in ATE accuracy. Furthermore, our method offers insights into the underlying causal mechanisms influencing model behavior, enabling more robust and interpretable NLP systems.",ai
"We investigate the challenge of decentralized task allocation in dynamic multi-agent systems where agents possess heterogeneous capabilities and experience resource constraints. Traditional approaches often rely on centralized coordination or restrictive assumptions about agent knowledge. We propose a novel reinforcement learning framework, termed ""Adaptive Cooperative Specialization (ACS)"", that facilitates emergent role specialization and efficient task allocation through decentralized decision-making. ACS combines a multi-agent deep Q-network with a communication channel enabling agents to implicitly share information about their individual skill proficiencies and resource limitations. Agents learn to specialize in specific tasks based on their observed performance and available resources, dynamically adjusting their strategy in response to environmental changes and the actions of other agents. Experimental results in a simulated resource gathering environment demonstrate that ACS significantly outperforms benchmark algorithms, including auction-based methods and independent learning approaches, in terms of both task completion rate and resource utilization. Furthermore, we analyze the emergent specialization patterns, highlighting the framework's ability to adapt to diverse agent capabilities and resource distributions, leading to more robust and scalable solutions for decentralized task allocation.",ai
"We investigate the problem of emergent communication in multi-agent systems operating within complex, partially observable environments. Specifically, we address the challenge of coordinating action selection and communication policies amongst agents with heterogeneous capabilities and objectives. We propose a novel decentralized learning framework, Comms-Aware Policy Optimization (CAPO), which integrates a differentiable communication channel directly into the policy optimization process. CAPO employs a shared attention mechanism to dynamically filter and prioritize incoming messages, allowing agents to selectively focus on relevant information during decision-making. The framework further incorporates a communication penalty term that encourages efficient communication strategies while discouraging redundant or uninformative messages. We evaluate CAPO on a suite of challenging cooperative navigation and resource allocation tasks. Empirical results demonstrate that CAPO significantly outperforms existing methods, including independent learners and those employing naive message broadcasting, in terms of both overall task performance and communication efficiency. Ablation studies highlight the importance of the attention mechanism and the communication penalty in fostering effective communication protocols. These findings suggest that CAPO provides a promising approach for developing cooperative multi-agent systems capable of learning sophisticated and efficient communication strategies.",ai
"The Science Consultant Agent is a web-based Artificial Intelligence (AI) tool that helps practitioners select and implement the most effective modeling strategy for AI-based solutions. It operates through four core components: Questionnaire, Smart Fill, Research-Guided Recommendation, and Prototype Builder. By combining structured questionnaires, literature-backed solution recommendations, and prototype generation, the Science Consultant Agent accelerates development for everyone from Product Managers and Software Developers to Researchers. The full pipeline is illustrated in Figure 1.",human
"Graph Neural Networks (GNNs) have demonstrated effectiveness in learning representations for graph-structured data. However, many existing GNN architectures struggle to effectively capture long-range dependencies between nodes, limiting their performance on tasks requiring reasoning over extended graph distances. We address this limitation by introducing a novel GNN architecture, the Attentive Long-Range Graph Neural Network (ALR-GNN), which incorporates a multi-head attention mechanism directly into the message passing process. ALR-GNN leverages attention to selectively aggregate information from distant nodes within the graph, weighting contributions based on their relevance to the target node. Furthermore, we introduce a learnable positional encoding scheme specifically designed for graph structures, enabling the model to better differentiate nodes based on their location within the graph topology. We evaluate the performance of ALR-GNN on a suite of graph-based reasoning tasks, including synthetic graph traversal and molecular property prediction. Experimental results demonstrate that ALR-GNN significantly outperforms existing GNN architectures, achieving state-of-the-art performance on these benchmarks. Ablation studies confirm the importance of both the multi-head attention mechanism and the graph positional encodings in enabling effective long-range dependency modeling.",ai
"We address the problem of identifying causal effects from observational data when confounding is present and the causal graph is partially unknown. Specifically, we focus on scenarios where the set of potential confounders is large, and traditional methods relying on complete causal structure knowledge or exhaustive adjustment become computationally intractable or statistically unreliable. We propose a novel method, CAusal Inference via Sparse Optimization (CISSO), which leverages sparsity-inducing regularization to simultaneously learn a sparse set of instrumental variables (IVs) and estimate the treatment effect. CISSO formulates causal inference as a bilevel optimization problem, where the outer level aims to minimize the variance of the treatment effect estimator, and the inner level identifies valid IVs based on the orthogonality condition to the treatment error. We employ an alternating direction method of multipliers (ADMM) algorithm to efficiently solve the resulting optimization problem. Empirical evaluation on synthetic datasets demonstrates that CISSO accurately identifies causal effects even with high-dimensional confounders and outperforms existing IV selection methods in terms of both bias and variance. Furthermore, application to a real-world healthcare dataset shows CISSOâ€™s ability to uncover potentially causal relationships that were previously masked by unobserved confounding.",ai
"We address the challenge of sample-efficient reinforcement learning in environments with sparse and delayed rewards. Conventional reinforcement learning algorithms often struggle in such settings due to the difficulty of exploring the state space and attributing credit to past actions. This work introduces a novel hierarchical reinforcement learning framework that combines intrinsic motivation with a learned option discovery mechanism. Specifically, we propose a two-level architecture: a meta-controller that selects high-level ""options"" designed to explore the environment and discover potentially rewarding states, and a set of lower-level option policies trained to execute the chosen option. Options are learned via a variational information bottleneck objective that encourages them to be both informative about the environment dynamics and concise in their representation. This encourages the emergence of temporally extended actions focused on distinct regions of the state space. We evaluate our approach on several challenging benchmark tasks characterized by sparse rewards and long horizons. Empirical results demonstrate that our method significantly outperforms several state-of-the-art reinforcement learning algorithms in terms of both sample efficiency and asymptotic performance, achieving higher cumulative rewards and exhibiting improved exploration capabilities. Furthermore, analysis of the learned options reveals that they effectively capture meaningful sub-goals within the environment, facilitating efficient navigation and reward discovery.",ai
"Out-of-distribution (OOD) detection is essential for the safe deployment of neural networks, as it enables the identification of samples outside the training domain. We present FOODER, a real-time, privacy-preserving radar-based framework that integrates OOD-based facial authentication with facial expression recognition. FOODER operates using low-cost frequency-modulated continuous-wave (FMCW) radar and exploits both range-Doppler and micro range-Doppler representations. The authentication module employs a multi-encoder multi-decoder architecture with Body Part (BP) and Intermediate Linear Encoder-Decoder (ILED) components to classify a single enrolled individual as in-distribution while detecting all other faces as OOD. Upon successful authentication, an expression recognition module is activated. Concatenated radar representations are processed by a ResNet block to distinguish between dynamic and static facial expressions. Based on this categorization, two specialized MobileViT networks are used to classify dynamic expressions (smile, shock) and static expressions (neutral, anger). This hierarchical design enables robust facial authentication and fine-grained expression recognition while preserving user privacy by relying exclusively on radar data. Experiments conducted on a dataset collected with a 60 GHz short-range FMCW radar demonstrate that FOODER achieves an AUROC of 94.13% and an FPR95 of 18.12% for authentication, along with an average expression recognition accuracy of 94.70%. FOODER outperforms state-of-the-art OOD detection methods and several transformer-based architectures while operating efficiently in real time.",human
"Visual analytics now plays a central role in decision-making across diverse disciplines, but it can be unreliable: the knowledge or insights derived from the analysis may not accurately reflect the underlying data. In this dissertation, we improve the reliability of visual analytics with a focus on dimensionality reduction (DR). DR techniques enable visual analysis of high-dimensional data by reducing it to two or three dimensions, but they inherently introduce errors that can compromise the reliability of visual analytics. To this end, I investigate reliability challenges that practitioners face when using DR for visual analytics. Then, I propose technical solutions to address these challenges, including new evaluation metrics, optimization strategies, and interaction techniques. We conclude the thesis by discussing how our contributions lay the foundation for achieving more reliable visual analytics practices.",human
"We address the problem of automatically proving theorems in first-order logic with equality, focusing on improving the efficiency of equational reasoning within saturation-based theorem provers. Existing approaches often suffer from combinatorial explosion due to the unrestricted application of paramodulation, leading to the generation of numerous redundant or irrelevant clauses. To mitigate this, we introduce a novel ordering-based term selection heuristic, termed ""Weighted E-Matching with Age Preference"" (WEMAP), designed to prioritize paramodulation inferences involving simpler, older terms that are more likely to lead to the refutation. WEMAP integrates term weight, term age, and a variant of E-matching to guide the selection of both the ""from"" and ""into"" terms in paramodulation steps. We implemented WEMAP within the Vampire theorem prover and evaluated its performance on a comprehensive benchmark suite of first-order logic problems with equality, drawn from the TPTP library. Empirical results demonstrate that WEMAP significantly reduces the search space explored by Vampire, leading to a substantial increase in the number of problems solved within a given time limit compared to the default term selection strategy and other state-of-the-art heuristics. Specifically, WEMAP improves the solve rate by approximately 15% across the tested benchmarks, highlighting the effectiveness of the proposed ordering-based approach for enhancing equational reasoning.",ai
"We address the challenge of sample-efficient reinforcement learning in environments with sparse and delayed rewards, specifically focusing on scenarios where exploration via intrinsic motivation is insufficient to consistently discover reward-generating states. Our approach, termed ""Curriculum-Guided Reinforcement Learning"" (CGRL), leverages a sequence of progressively more complex environments, constructed to gradually expose the agent to the target task. These intermediate environments are designed by analyzing the state-space connectivity graph of the original environment and introducing artificial reward signals that guide the agent towards regions of high potential reward in the target task. We propose a novel algorithm for automatically generating this curriculum based on estimating the ""reachability"" of rewarding states and defining surrogate tasks that prioritize exploration in under-explored regions exhibiting high reward potential. We empirically evaluate CGRL on several challenging benchmark tasks with sparse rewards, demonstrating a significant improvement in sample efficiency and overall performance compared to state-of-the-art intrinsic motivation and hierarchical reinforcement learning methods. Specifically, we observe a 30-50% reduction in training episodes required to achieve comparable performance, and in several cases, CGRL is able to solve tasks where baseline methods fail to discover any rewards within a reasonable training horizon. These results suggest that curriculum learning, when guided by a structured analysis of environment structure, can significantly accelerate learning in complex, reward-sparse environments.",ai
"We investigate the problem of automating complex reasoning tasks that require integrating information across multiple, disparate knowledge sources. Specifically, we focus on improving the efficiency and accuracy of deductive reasoning in scenarios where the knowledge base is large and contains both symbolic facts and probabilistic relationships. Traditional logic-based approaches often suffer from combinatorial explosion, while purely probabilistic methods can struggle with representing and enforcing logical constraints. We introduce a novel hybrid reasoning framework, Logic-Guided Probabilistic Inference (LGPI), which combines symbolic logic programming with probabilistic graphical models. LGPI leverages answer set programming (ASP) to encode logical constraints and derive potential inference paths. These paths are then used to construct a probabilistic model, represented as a factor graph, which incorporates both the symbolic derivations and probabilistic evidence. Inference is performed via belief propagation, guided by the logical structure derived from the ASP solver. Empirical evaluations on benchmark knowledge graphs and simulated reasoning tasks demonstrate that LGPI significantly outperforms state-of-the-art methods in terms of both inference speed and accuracy, particularly in scenarios with complex logical dependencies and noisy data. Our results suggest that LGPI offers a promising approach for automating reasoning over large, heterogeneous knowledge bases.",ai
"We address the challenge of effectively representing complex relational knowledge for enhanced reasoning capabilities in machine learning systems. Existing approaches often struggle to capture intricate dependencies and hierarchical structures inherent in real-world datasets, leading to limitations in downstream tasks such as knowledge graph completion and question answering. We introduce a novel Knowledge Representation Learning (KRL) framework, termed Hierarchical Relational Embedding Networks (HREN), which leverages a multi-level attention mechanism to capture both local and global relational dependencies. HREN employs a hierarchical architecture where entities and relations are embedded at different levels of granularity. Lower levels capture fine-grained semantic information, while higher levels abstract and aggregate this information to represent more complex concepts and relationships. Attention mechanisms are used to selectively weight different levels of granularity based on the specific context of a given query. We evaluate HREN on several benchmark knowledge graph datasets (e.g., FB15k-237, WN18RR) and demonstrate significant improvements in link prediction accuracy compared to state-of-the-art KRL methods. Ablation studies confirm the effectiveness of the hierarchical architecture and attention mechanism. Furthermore, qualitative analysis reveals that HREN learns more interpretable embeddings, facilitating improved understanding of the learned knowledge representation.",ai
"Hierarchical representations provide powerful and principled approaches for analyzing many musical genres. Such representations have been broadly studied in music theory, for instance via Schenkerian analysis (SchA). Hierarchical music analyses, however, are highly cost-intensive; the analysis of a single piece of music requires a great deal of time and effort from trained experts. The representation of hierarchical analyses in a computer-readable format is a further challenge. Given recent developments in hierarchical deep learning and increasing quantities of computer-readable data, there is great promise in extending such work for an automatic hierarchical representation framework. This paper thus introduces a novel approach, AutoSchA, which extends recent developments in graph neural networks (GNNs) for hierarchical music analysis. AutoSchA features three key contributions: 1) a new graph learning framework for hierarchical music representation, 2) a new graph pooling mechanism based on node isolation that directly optimizes learned pooling assignments, and 3) a state-of-the-art architecture that integrates such developments for automatic hierarchical music analysis. We show, in a suite of experiments, that AutoSchA performs comparably to human experts when analyzing Baroque fugue subjects.",human
"Knowledge Base Question Answering (KBQA) challenges models to bridge the gap between natural language and strict knowledge graph schemas by generating executable logical forms. While Large Language Models (LLMs) have advanced this field, current approaches often struggle with a dichotomy of failure: they either generate hallucinated queries without verifying schema existence or exhibit rigid, template-based reasoning that mimics synthesized traces without true comprehension of the environment. To address these limitations, we present , a framework that shifts the paradigm from text imitation to interaction optimization via Reinforcement Learning. Treating KBQA as a multi-turn decision process, our model learns to navigate the knowledge base using a list of actions, leveraging Group Relative Policy Optimization (GRPO) to refine its strategies based on concrete execution feedback rather than static supervision. Furthermore, we introduce , a data synthesis method that resolves cold-start challenges by strictly aligning reasoning traces with ground-truth action sequences. Extensive experiments on WebQSP, GrailQA, and GraphQuestions demonstrate that KBQA-R1 achieves state-of-the-art performance, effectively grounding LLM reasoning in verifiable execution.",human
"As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME. To that end, this paper proposes an intelligent mission coordination methodology that integrates digital mission models with Reinforcement Learning (RL), that specifically addresses the need for adaptive task allocation and reconfiguration. More specifically, we are leveraging a Digital Engineering (DE) based infrastructure that is composed of a high-fidelity digital mission model and agent-based simulation; and then we formulate the mission tactics management problem as a Markov Decision Process (MDP), and employ an RL agent trained via Proximal Policy Optimization. By leveraging the simulation as a sandbox, we map the system states to actions, refining the policy based on realized mission outcomes. The utility of the RL-based intelligent mission coordinator is demonstrated through an aerial firefighting case study. Our findings indicate that the RL-based intelligent mission coordinator not only surpasses baseline performance but also significantly reduces the variability in mission performance. Thus, this study serves as a proof of concept demonstrating that DE-enabled mission simulations combined with advanced analytical tools offer a mission-agnostic framework for improving ME practice; which can be extended to more complicated fleet design and selection problems in the future from a mission-first perspective.",human
"## Decentralized Task Allocation with Dynamic Communication Topology in Multi-Agent Systems We address the problem of decentralized task allocation in multi-agent systems operating within environments characterized by dynamic communication topologies. Traditional approaches often assume static or predictable communication networks, a constraint that limits their applicability in real-world scenarios involving agent mobility, environmental interference, or network failures. We propose a novel algorithm, Decentralized Adaptive Task Allocation with Topology Awareness (DATATA), which integrates a belief propagation-based inference mechanism with an adaptive task assignment strategy. DATATA agents maintain local beliefs about task utilities and the current communication topology, iteratively refining these beliefs through message passing with neighboring agents. A key feature of DATATA is its ability to dynamically adjust the task assignment strategy based on the inferred reliability and connectivity of the communication network, enabling agents to prioritize information from more trustworthy sources. We evaluate DATATA through extensive simulations across a range of dynamic communication topologies, including those exhibiting intermittent connectivity and varying levels of noise. Results demonstrate that DATATA significantly outperforms existing decentralized task allocation algorithms in terms of overall task completion rate, average task utility, and resilience to communication failures. Furthermore, the algorithm exhibits improved scalability with an increasing number of agents and tasks, suggesting its potential for deployment in large-scale, distributed environments.",ai
"Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term ""internal RL"", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.",human
"We present a comprehensive zero-training temporal drift analysis of transformer-based sentiment models validated on authentic social media data from major real-world events. Through systematic evaluation across three transformer architectures and rigorous statistical validation on 12,279 authentic social media posts, we demonstrate significant model instability with accuracy drops reaching 23.4% during event-driven periods. Our analysis reveals maximum confidence drops of 13.0% (Bootstrap 95% CI: [9.1%, 16.5%]) with strong correlation to actual performance degradation. We introduce four novel drift metrics that outperform embedding-based baselines while maintaining computational efficiency suitable for production deployment. Statistical validation across multiple events confirms robust detection capabilities with practical significance exceeding industry monitoring thresholds. This zero-training methodology enables immediate deployment for real-time sentiment monitoring systems and provides new insights into transformer model behavior during dynamic content periods.",human
"The purpose of this project is to assess how well defenders can detect DNS-over-HTTPS (DoH) file exfiltration, and which evasion strategies can be used by attackers. While providing a reproducible toolkit to generate, intercept and analyze DoH exfiltration, and comparing Machine Learning vs threshold-based detection under adversarial scenarios. The originality of this project is the introduction of an end-to-end, containerized pipeline that generates configurable file exfiltration over DoH using several parameters (e.g., chunking, encoding, padding, resolver rotation). It allows for file reconstruction at the resolver side, while extracting flow-level features using a fork of DoHLyzer. The pipeline contains a prediction side, which allows the training of machine learning models based on public labelled datasets and then evaluates them side-by-side with threshold-based detection methods against malicious and evasive DNS-Over-HTTPS traffic. We train Random Forest, Gradient Boosting and Logistic Regression classifiers on a public DoH dataset and benchmark them against evasive DoH exfiltration scenarios. The toolkit orchestrates traffic generation, file capture, feature extraction, model training and analysis. The toolkit is then encapsulated into several Docker containers for easy setup and full reproducibility regardless of the platform it is run on. Future research regarding this project is directed at validating the results on mixed enterprise traffic, extending the protocol coverage to HTTP/3/QUIC request, adding a benign traffic generation, and working on real-time traffic evaluation. A key objective is to quantify when stealth constraints make DoH exfiltration uneconomical and unworthy for the attacker.",human
"Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.",human
"We investigate the challenge of emergent communication in cooperative multi-agent systems where agents must coordinate their actions to achieve a shared goal without explicit pre-programmed communication protocols. Specifically, we address the issue of semantic instability observed in such systems, wherein learned communication protocols exhibit sensitivity to minor perturbations, leading to suboptimal performance and hindering transfer learning. Our proposed method, termed *Robust Communication through Differentiable Self-Supervision (RCDS)*, introduces a novel auxiliary objective that encourages agents to develop communication strategies that are robust to small variations in both their input and output communication channels. This objective is realized through a differentiable self-supervision loss that minimizes the distance between the intended message and the reconstructed message after undergoing simulated noise injection. Experimental results on a cooperative navigation task and a referential game demonstrate that RCDS significantly improves the stability and generalization capabilities of emergent communication protocols. Agents trained with RCDS exhibit enhanced resilience to noise in communication channels and demonstrate improved performance on unseen task variations compared to baseline methods. Furthermore, we observe that the learned communication representations exhibit greater semantic coherence and interpretability.",ai
"Modern cloud platforms increasingly host large-scale deep learning (DL) workloads, demanding high-throughput, low-latency GPU scheduling. However, the growing heterogeneity of GPU clusters and limited visibility into application characteristics pose major challenges for existing schedulers, which often rely on offline profiling or application-specific assumptions. We present RLTune, an application-agnostic reinforcement learning (RL)-based scheduling framework that dynamically prioritizes and allocates DL jobs on heterogeneous GPU clusters. RLTune integrates RL-driven prioritization with MILP-based job-to-node mapping to optimize system-wide objectives such as job completion time (JCT), queueing delay, and resource utilization. Trained on large-scale production traces from Microsoft Philly, Helios, and Alibaba, RLTune improves GPU utilization by up to 20%, reduces queueing delay by up to 81%, and shortens JCT by as much as 70 percent. Unlike prior approaches, RLTune generalizes across diverse workloads without requiring per-job profiling, making it practical for cloud providers to deploy at scale for more efficient, fair, and sustainable DL workload management.",human
"The PRO-CTCAE is an NCI-developed patient-reported outcome system for capturing symptomatic adverse events in oncology trials. It comprises a large library drawn from the CTCAE vocabulary, and item selection for a given trial is typically guided by expected toxicity profiles from prior data. Selecting too many PRO-CTCAE items can burden patients and reduce compliance, while too few may miss important safety signals. We present an automated method to select a minimal yet comprehensive PRO-CTCAE subset based on historical safety data. Each candidate PRO-CTCAE symptom term is first mapped to its corresponding MedDRA Preferred Terms (PTs), which are then encoded into Safeterm, a high-dimensional semantic space capturing clinical and contextual diversity in MedDRA terminology. We score each candidate PRO item for relevance to the historical list of adverse event PTs and combine relevance and incidence into a utility function. Spectral analysis is then applied to the combined utility and diversity matrix to identify an orthogonal set of medical concepts that balances relevance and diversity. Symptoms are rank-ordered by importance, and a cut-off is suggested based on the explained information. The tool is implemented as part of the Safeterm trial-safety app. We evaluate its performance using simulations and oncology case studies in which PRO-CTCAE was employed. This automated approach can streamline PRO-CTCAE design by leveraging MedDRA semantics and historical data, providing an objective and reproducible method to balance signal coverage against patient burden.",human
"As agentic AI systems increasingly operate autonomously, establishing trust through verifiable evaluation becomes critical. Yet existing benchmarks lack the transparency and auditability needed to assess whether agents behave reliably. We present DrawingBench, a verification framework for evaluating the trustworthiness of agentic LLMs through spatial reasoning tasks that require generating sequences of low-level GUI actions. Unlike opaque evaluations, DrawingBench provides transparent, rule-based assessment: 8 objective criteria enable reproducible scoring, while action-level inspection allows stakeholders to audit agent behavior. Our framework comprises 250 diverse prompts across 20 categories and 4 difficulty levels, deterministic evaluation metrics, and an external oversight mechanism through multi-turn feedback that enables human control over agent refinement. Evaluating four state-of-the-art LLMs (Claude-4 Sonnet, GPT-4.1, GPT-4.1-mini, Gemini-2.5 Flash) across 1,000 tests, we establish both capabilities and limitations: models achieved 92.8% perfect performance with structured external feedback driving significant improvements (average +3.2%, up to +32.8% for complex scenes), but systematic error patterns emerged in tool state management and long-horizon planning. Notably, specification clarity proved more important than task complexity -- models achieved 100% perfect performance when given explicit, verifiable criteria. These findings demonstrate that transparent evaluation frameworks can establish trust in agentic systems, with external oversight proving more reliable than self-correction for guiding agent behavior. Our open-source framework provides a template for trustworthy agent assessment. Code and data: https://github.com/hyunjun1121/DrawingBench",human
"We address the challenge of training machine learning models on sensitive data while preserving individual privacy. Specifically, we focus on learning language models under differential privacy (DP), a rigorous mathematical framework for quantifying privacy guarantees. A significant bottleneck in DP-SGD (Differentially Private Stochastic Gradient Descent) is the high computational cost associated with per-sample gradient clipping, particularly for large transformer-based language models. We propose a novel method, PATE-Adaptive-SGD (PAS), which combines the strengths of Private Aggregation of Teacher Ensembles (PATE) and DP-SGD. PAS leverages a teacher ensemble trained on non-private data to generate noisy labels for the student model, which is then trained using DP-SGD, adaptively adjusting the clipping norm based on the teacher ensemble's predictions. This allows for significantly reduced clipping norms compared to standard DP-SGD, leading to improved utility under the same privacy budget. Our experiments on text classification and next-word prediction tasks demonstrate that PAS achieves substantial performance gains over existing DP-SGD baselines, particularly in the low-privacy regime (Îµ < 10), while maintaining comparable computational efficiency. We further analyze the impact of various hyperparameters on the privacy-utility tradeoff, providing practical guidelines for deploying PAS in real-world scenarios. Our results demonstrate the potential of leveraging teacher-student frameworks and adaptive clipping techniques to train high-utility, privacy-preserving language models.",ai
"Transformer networks have revolutionized numerous Natural Language Processing (NLP) tasks, achieving state-of-the-art performance across diverse benchmarks. However, the computational demands of training and deploying these models, particularly for long sequences, remain a significant challenge. Current methods often rely on quadratic or near-quadratic complexity with respect to sequence length, limiting their applicability to resource-constrained environments and hindering the processing of lengthy documents. This work investigates a novel approach to enhance the efficiency of transformer models through a combination of learned sparse attention and hierarchical decomposition. We introduce a sparse attention mechanism based on trainable masks, allowing the model to selectively attend to the most relevant parts of the input sequence, thereby reducing the computational burden of the attention calculation. Furthermore, we propose a hierarchical architecture that recursively decomposes the input sequence into smaller, manageable chunks, enabling parallel processing and mitigating the long-range dependency problem. Experimental results on several benchmark datasets, including text summarization and question answering, demonstrate that our proposed method achieves comparable performance to full attention transformers while significantly reducing computational complexity. Specifically, we observe a reduction in training time by up to 30% and memory usage by up to 25% compared to standard transformer architectures, without a substantial decrease in accuracy. The findings suggest that the proposed approach offers a promising direction for developing more efficient and scalable transformer models for a wide range of NLP applications.",ai
"We investigate the problem of enhancing automated theorem proving within first-order logic by leveraging learned inference guidance. Existing theorem provers often rely on hand-engineered heuristics that may prove suboptimal for specific problem domains. To address this, we propose a novel method integrating a graph neural network (GNN) architecture, trained via reinforcement learning, to predict the utility of available inference rules at each step of a proof search. The GNN operates directly on the proof state graph, capturing complex relationships between clauses and terms. The reward signal for the reinforcement learning agent is derived from the success or failure of the theorem prover in completing a proof within a predefined time limit. We evaluate our approach on a diverse set of problems from the TPTP library, comparing its performance against state-of-the-art automated theorem provers using standard heuristics. Experimental results demonstrate that our learned inference guidance significantly improves the success rate and reduces proof lengths, particularly in domains where traditional heuristics struggle. Specifically, our method achieves a 15% increase in solved problems within the given time limit compared to the baseline prover using its default strategy, indicating the efficacy of learning to dynamically adapt inference selection based on the problem structure.",ai
"Long Chain-of-Thought (CoT) reasoning has significantly advanced the capabilities of Large Language Models (LLMs), but this progress is accompanied by substantial memory and latency overhead from the extensive Key-Value (KV) cache. Although KV cache quantization is a promising compression technique, existing low-bit quantization methods often exhibit severe performance degradation on complex reasoning tasks. Fixed-precision quantization struggles to handle outlier channels in the key cache, while current mixed-precision strategies fail to accurately identify components requiring high-precision representation. We find that an effective low-bit KV cache quantization strategy must consider two factors: a key channel's intrinsic quantization difficulty and its relevance to the query. Based on this insight, we propose MixKVQ, a novel plug-and-play method that introduces a lightweight, query-aware algorithm to identify and preserve critical key channels that need higher precision, while applying per-token quantization for value cache. Experiments on complex reasoning datasets demonstrate that our approach significantly outperforms existing low-bit methods, achieving performance comparable to a full-precision baseline at a substantially reduced memory footprint.",human
"This paper addresses the challenge of automated pulmonary embolism (PE) detection in computed tomography pulmonary angiography (CTPA) scans. Manual interpretation of CTPA images is a time-consuming and resource-intensive process prone to inter-observer variability. Current automated methods often struggle with the subtle appearance of small PEs and the complex anatomical context of the pulmonary vasculature. We propose a novel multi-scale convolutional neural network (CNN) architecture incorporating attention mechanisms for enhanced PE detection. The network leverages a three-dimensional (3D) U-Net backbone to capture volumetric information from CTPA scans, followed by a series of attention-guided feature aggregation modules designed to emphasize relevant PE features at varying scales. This multi-scale approach aims to improve sensitivity to both large, centrally located PEs and smaller, more peripheral emboli. We evaluated our method on a retrospective dataset of 500 CTPA scans, achieving an average AUC of 0.94 for PE detection, demonstrating a significant improvement over baseline CNN models (AUC=0.89). Furthermore, qualitative analysis reveals that the attention maps generated by our model effectively highlight regions of interest containing PEs, providing valuable interpretability for clinicians. These results suggest that the proposed attention-guided multi-scale CNN architecture offers a promising solution for automated PE detection in CTPA imaging.",ai
"Video Large Language Models (VideoLLMs) have shown remarkable progress in video understanding. However, these models still struggle to effectively perceive and exploit rich temporal information in videos when responding to user queries. Therefore, they often generate descriptions of events that are temporal inconsistent or causally implausible, causing severe hallucination issues. While most prior studies have focused on spatial hallucinations (e.g. object mismatches), temporal reasoning in video understanding remains relatively underexplored. To address this issue, we propose Self-Diagnostic Contrastive Decoding (SEASON), a training-free method that adaptively enhances temporal and spatial faithfulness for each output token. It achieves this by dynamically diagnosing each token's hallucination tendency and applying adaptive contrastive decoding against its corresponding temporal and spatial negatives. Extensive experiments demonstrate that SEASON outperforms all existing training-free hallucination mitigation approaches on three hallucination examination benchmarks, while further improves VideoLLMs across four general video understanding benchmarks. The code will be released upon acceptance.",human
"We address the problem of decentralized learning in multi-agent systems (MAS) where agents interact with a shared environment and aim to optimize individual reward functions without explicit inter-agent communication. Specifically, we focus on scenarios with non-stationary environments induced by the concurrent learning of other agents, leading to instability and poor convergence. To mitigate this issue, we propose a novel decentralized reinforcement learning algorithm based on implicit influence regularization. Our method encourages agents to learn policies that are robust to changes in the policies of other agents, effectively promoting a more stable learning dynamic. This is achieved by incorporating a regularizer into the agent's objective function that penalizes large deviations in its policy's performance when subjected to adversarial perturbations of other agents' policies. We empirically evaluate our approach on a suite of challenging cooperative and competitive MAS benchmark environments. Our results demonstrate that our method consistently outperforms existing state-of-the-art decentralized learning algorithms in terms of both convergence speed and asymptotic performance. Further analysis reveals that the implicit influence regularization promotes the emergence of more cooperative and robust agent behaviors, leading to improved overall system performance in non-stationary environments.",ai
"We address the challenge of sample inefficiency in reinforcement learning (RL) within sparse-reward environments. Specifically, we consider Markov Decision Processes (MDPs) where the agent receives informative feedback (i.e., non-zero reward) only after a long sequence of actions. To mitigate this issue, we introduce a novel hierarchical reinforcement learning framework predicated on intrinsically motivated exploration. Our method, termed Intrinsic Reward-Augmented Policy Optimization (IRAPO), learns a high-level policy for subgoal selection and a low-level policy for subgoal achievement. Subgoals are defined adaptively based on state-space visitation frequency, with infrequently visited states receiving higher intrinsic reward. This intrinsic reward signal is used to augment the sparse extrinsic reward, guiding the agent towards unexplored regions of the state space. Furthermore, we employ a curriculum learning strategy, gradually reducing the impact of the intrinsic reward as the agent gains experience with the environment. We demonstrate empirically that IRAPO significantly outperforms state-of-the-art RL algorithms, including both on-policy and off-policy methods, across a suite of challenging sparse-reward navigation and manipulation tasks. We observe a substantial improvement in sample efficiency and final performance, indicating that IRAPO effectively balances exploration and exploitation in these complex environments.",ai
"It is widely believed that complex machine learning models generally encode features through linear representations, but these features exist in superposition, making them challenging to recover. We study the following fundamental setting for learning features in superposition from black-box query access: we are given query access to a function \[ f(x)=\sum_{i=1}^n a_i\,Ïƒ_i(v_i^\top x), \] where each unit vector encodes a feature direction and is an arbitrary response function and our goal is to recover the and the function . In learning-theoretic terms, superposition refers to the overcomplete regime, when the number of features is larger than the underlying dimension (i.e. ), which has proven especially challenging for typical algorithmic approaches. Our main result is an efficient query algorithm that, from noisy oracle access to , identifies all feature directions whose responses are non-degenerate and reconstructs the function . Crucially, our algorithm works in a significantly more general setting than all related prior results -- we allow for essentially arbitrary superpositions, only requiring that are not nearly identical for , and general response functions . At a high level, our algorithm introduces an approach for searching in Fourier space by iteratively refining the search space to locate the hidden directions .",human
"Human activity recognition (HAR) requires extracting accurate spatial-temporal features with human movements. A mmWave radar point cloud-based HAR system suffers from sparsity and variable-size problems due to the physical features of the mmWave signal. Existing works usually borrow the preprocessing algorithms for the vision-based systems with dense point clouds, which may not be optimal for mmWave radar systems. In this work, we proposed a graph representation with a discrete dynamic graph neural network (DDGNN) to explore the spatial-temporal representation of human movement-related features. Specifically, we designed a star graph to describe the high-dimensional relative relationship between a manually added static center point and the dynamic mmWave radar points in the same and consecutive frames. We then adopted DDGNN to learn the features residing in the star graph with variable sizes. Experimental results demonstrated that our approach outperformed other baseline methods using real-world HAR datasets. Our system achieved an overall classification accuracy of 94.27\%, which gets the near-optimal performance with a vision-based skeleton data accuracy of 97.25\%. We also conducted an inference test on Raspberry Pi~4 to demonstrate its effectiveness on resource-constraint platforms. \sh{ We provided a comprehensive ablation study for variable DDGNN structures to validate our model design. Our system also outperformed three recent radar-specific methods without requiring resampling or frame aggregators.",human
"Accurate and efficient discrete video tokenization is essential for long video sequences processing. Yet, the inherent complexity and variable information density of videos present a significant bottleneck for current tokenizers, which rigidly compress all content at a fixed rate, leading to redundancy or information loss. Drawing inspiration from Shannon's information theory, this paper introduces InfoTok, a principled framework for adaptive video tokenization. We rigorously prove that existing data-agnostic training methods are suboptimal in representation length, and present a novel evidence lower bound (ELBO)-based algorithm that approaches theoretical optimality. Leveraging this framework, we develop a transformer-based adaptive compressor that enables adaptive tokenization. Empirical results demonstrate state-of-the-art compression performance, saving 20% tokens without influence on performance, and achieving 2.3x compression rates while still outperforming prior heuristic adaptive approaches. By allocating tokens according to informational richness, InfoTok enables a more compressed yet accurate tokenization for video representation, offering valuable insights for future research.",human
"Transformer architectures have achieved state-of-the-art performance across a diverse range of Natural Language Processing (NLP) tasks, but their computational complexity, particularly quadratic with respect to sequence length, presents a significant obstacle for processing long documents. This limitation hinders their applicability to tasks such as summarization, question answering on extensive texts, and long-form content generation. This paper addresses the challenge of scaling transformer models to handle increased input lengths while maintaining competitive accuracy and efficiency. We propose a novel sparse attention mechanism, Longformer-Adaptive Attention (LFAA), which dynamically selects relevant context based on learned importance scores at each layer. LFAA combines global attention to task-specific tokens with a sliding window attention pattern, enabling effective information propagation across the entire sequence. We evaluate LFAA on several benchmark datasets including the Long Range Arena (LRA) and document-level summarization tasks. Experimental results demonstrate that LFAA achieves comparable or superior performance to existing sparse attention mechanisms and full attention transformers, while requiring significantly less computational resources and memory, particularly for long sequences. Furthermore, LFAA exhibits improved generalization capabilities on out-of-distribution data, showcasing its robustness and potential for practical deployment.",ai
"We address the challenge of coordinating cooperative agents in complex, partially observable environments where explicit communication is either unavailable or unreliable. The problem lies in effectively inferring agent intentions and adapting strategies to maximize team performance without direct information exchange. We propose a novel decentralized Partially Observable Markov Decision Process (Dec-POMDP) framework leveraging Implicit Communication through Action Embedding (ICAE). ICAE learns a latent representation of each agent's actions conditioned on its local observation history. This embedding is then used to predict the likely actions of other agents, influencing individual policy decisions. Specifically, we utilize a recurrent neural network architecture to encode observation histories and generate action embeddings, coupled with a learned attention mechanism to weigh the relevance of other agents' inferred actions. Empirical evaluation on a challenging grid-world navigation task and a simulated multi-robot warehouse environment demonstrates that ICAE significantly outperforms existing decentralized reinforcement learning algorithms, including those employing explicit communication protocols under noisy channels. Furthermore, ICAE exhibits improved robustness to variations in team size and environmental dynamics. These results suggest that learning implicit communication strategies via action embedding provides a viable and effective approach for coordinating cooperative agents in complex decentralized settings.",ai
"We investigate the problem of automated pulmonary nodule detection in computed tomography (CT) scans, a critical task for early lung cancer diagnosis. Manual review of large CT datasets is time-consuming and prone to inter-observer variability, necessitating robust and efficient automated solutions. We propose a novel multi-scale convolutional neural network (CNN) architecture incorporating both global contextual information and fine-grained nodule features. The network employs a coarse-to-fine approach: an initial 3D CNN identifies candidate regions, followed by a series of progressively higher-resolution 2D CNNs that refine nodule predictions and reduce false positives. Crucially, our architecture incorporates a novel attention mechanism that emphasizes diagnostically relevant features at each scale, guiding the network's focus towards subtle nodule characteristics. Evaluated on the LIDC-IDRI dataset, our method achieves a sensitivity of 92.3% at 4 false positives per scan, surpassing the performance of several established methods. Furthermore, ablation studies demonstrate the efficacy of the multi-scale approach and the attention mechanism in improving detection accuracy. These results suggest the potential of the proposed system for assisting radiologists in the efficient and accurate screening of lung cancer.",ai
"This paper investigates the problem of distributionally robust optimization (DRO) for stochastic learning models under moment ambiguity. Specifically, we address the scenario where only partial information regarding the data distribution is available, limited to the first and second moments. We propose a novel DRO framework that leverages a Wasserstein ambiguity set centered around an empirical distribution, parameterized by a radius that controls the degree of robustness. To mitigate the computational intractability often associated with DRO problems, we derive a tractable reformulation via Lagrangian duality, resulting in a convex optimization problem. Furthermore, we develop a data-driven algorithm for adaptively tuning the Wasserstein radius based on cross-validation, balancing in-sample performance and out-of-sample robustness. We analyze the statistical properties of our estimator, providing generalization error bounds that explicitly quantify the trade-off between robustness and sample complexity. Empirical results on synthetic and real-world datasets demonstrate the effectiveness of the proposed approach, showcasing its superior performance compared to traditional empirical risk minimization and existing DRO methods under various distributional shifts. Our findings suggest that the proposed moment-based DRO framework offers a practical and robust solution for learning under uncertainty, particularly relevant in applications where data distributions are non-stationary or subject to adversarial perturbations.",ai
"The advent of sixth-generation (6G) places intelligence at the core of wireless architecture, fusing perception, communication, and computation into a single closed-loop. This paper argues that large artificial intelligence models (LAMs) can endow base stations with perception, reasoning, and acting capabilities, thus transforming them into intelligent base station agents (IBSAs). We first review the historical evolution of BSs from single-functional analog infrastructure to distributed, software-defined, and finally LAM-empowered IBSA, highlighting the accompanying changes in architecture, hardware platforms, and deployment. We then present an IBSA architecture that couples a perception-cognition-execution pipeline with cloud-edge-end collaboration and parameter-efficient adaptation. Subsequently,we study two representative scenarios: (i) cooperative vehicle-road perception for autonomous driving, and (ii) ubiquitous base station support for low-altitude uncrewed aerial vehicle safety monitoring and response against unauthorized drones. On this basis, we analyze key enabling technologies spanning LAM design and training, efficient edge-cloud inference, multi-modal perception and actuation, as well as trustworthy security and governance. We further propose a holistic evaluation framework and benchmark considerations that jointly cover communication performance, perception accuracy, decision-making reliability, safety, and energy efficiency. Finally, we distill open challenges on benchmarks, continual adaptation, trustworthy decision-making, and standardization. Together, this work positions LAM-enabled IBSAs as a practical path toward integrated perception, communication, and computation native, safety-critical 6G systems.",human
"Securely training machine learning models on sensitive data presents significant challenges. While federated learning (FL) offers a promising paradigm, its susceptibility to inference attacks that leak individual-level information remains a critical concern. This work addresses the problem of privacy leakage in FL settings, specifically focusing on membership inference attacks (MIAs). We propose a novel defense mechanism, Privacy-Augmented Gradient Perturbation (PAGP), which leverages differential privacy (DP) principles to inject calibrated noise directly into the gradients aggregated at the server. Unlike standard DP-SGD approaches, PAGP dynamically adjusts the noise scale based on the magnitude and variance of individual client updates, minimizing disruption to model convergence. We theoretically analyze the privacy guarantees of PAGP using RÃ©nyi Differential Privacy (RDP) accounting. Empirically, we evaluate PAGP across diverse datasets (CIFAR-10, MNIST, and a real-world medical dataset) and model architectures (Convolutional Neural Networks and Multi-Layer Perceptrons). Our results demonstrate that PAGP significantly reduces the success rate of MIAs compared to standard DP-SGD and gradient clipping baselines, while maintaining comparable or improved model accuracy and training efficiency. Furthermore, ablation studies validate the effectiveness of the dynamic noise scaling mechanism in preserving utility. PAGP offers a practical and effective approach to enhancing privacy in FL without compromising model performance.",ai
"Graph Neural Networks (GNNs) have demonstrated significant efficacy in learning representations for graph-structured data across diverse domains. However, many existing GNN architectures suffer from limitations in capturing long-range dependencies and global graph properties due to their reliance on local neighborhood aggregation. This work addresses the problem of effectively incorporating global information into GNN learning by proposing a novel architecture, Global Attention Graph Neural Network (GAGNN). GAGNN leverages a multi-head self-attention mechanism operating on the entire graph structure to identify and incorporate globally relevant nodes and edges into node representations. This attention mechanism allows the network to dynamically weigh the importance of distant nodes based on their relevance to the target node, mitigating the limitations of local aggregation. Empirical evaluations on a suite of benchmark graph classification and node classification datasets demonstrate that GAGNN consistently outperforms existing GNN models, including standard GCNs, GraphSAGE, and GATs. Specifically, GAGNN achieves state-of-the-art performance on datasets requiring reasoning about long-range relationships and global graph characteristics. These results highlight the importance of global attention mechanisms in enhancing the representational power of GNNs.",ai
"We present a novel approach to automated lesion detection and segmentation in chest X-ray images using a multi-scale convolutional neural network (CNN) architecture. The accurate identification and delineation of pulmonary abnormalities from radiographic images remains a challenging task, often requiring significant radiologist expertise and time. Our proposed method addresses this challenge by leveraging a deeply supervised network trained on a large-scale, publicly available chest X-ray dataset, augmented with synthetic lesion data to improve robustness and generalization. The network incorporates a hierarchical feature extraction mechanism, enabling the capture of both fine-grained textural information and global contextual cues, crucial for differentiating subtle lesion characteristics from normal lung tissue. Furthermore, we introduce a novel loss function that combines pixel-wise cross-entropy with a region-based Dice loss, optimizing for both classification accuracy and segmentation quality. Empirical evaluation demonstrates that our method achieves state-of-the-art performance compared to existing techniques, yielding an average Dice similarity coefficient of 0.78 and a sensitivity of 0.85 on a held-out test set comprising diverse lesion types. These results suggest the potential for our approach to significantly improve the efficiency and accuracy of radiological diagnosis in clinical settings.",ai
"This paper investigates the problem of training natural language processing models that are robust to adversarial attacks in the input text, specifically focusing on semantic perturbations. Existing adversarial training methods often rely on computationally expensive inner-loop optimization to generate adversarial examples, hindering scalability and generalization. We propose a novel framework based on Distributionally Robust Optimization (DRO) leveraging a Wasserstein ambiguity set to model the uncertainty in the input distribution introduced by adversarial perturbations. Our method learns a model that minimizes the worst-case expected loss within the Wasserstein ball, effectively hedging against potential adversarial attacks. We develop a computationally efficient algorithm to approximate the DRO objective, utilizing a stochastic gradient descent approach with a novel projection operator that enforces the Wasserstein constraint. Empirical evaluations on text classification and natural language inference tasks demonstrate that our approach achieves superior robustness compared to state-of-the-art adversarial training methods, as measured by performance on both white-box and black-box attacks. Furthermore, our method exhibits improved generalization performance on clean data compared to standard adversarial training, indicating a more stable and reliable training process. The results highlight the efficacy of Wasserstein DRO for enhancing the robustness of NLP models against semantic adversarial attacks.",ai
"Graph Neural Networks (GNNs) have demonstrated efficacy in learning representations of structured data across diverse domains. However, the performance of GNNs remains sensitive to the choice of network architecture, particularly with respect to the depth and aggregation schemes employed. This sensitivity arises from the potential for over-smoothing, where node representations converge to indistinguishable values as the network depth increases, and from suboptimal aggregation strategies that fail to effectively capture relevant neighborhood information. In this work, we address these limitations by introducing a novel Adaptive Graph Convolutional Network (AGCN) architecture. AGCN dynamically adjusts the aggregation weights based on node feature similarity and graph structural information, enabling the network to selectively emphasize relevant neighbor contributions. Furthermore, AGCN incorporates a self-attention mechanism to modulate the influence of different layers, mitigating the over-smoothing problem. We evaluate AGCN on a suite of benchmark graph datasets spanning node classification and graph classification tasks. Our experimental results demonstrate that AGCN consistently outperforms existing GNN architectures, achieving state-of-the-art performance in several datasets. Ablation studies confirm the effectiveness of both the adaptive aggregation and self-attention components in enhancing the network's representational capacity and robustness.",ai
"We introduce a novel approach for long context summarisation, highlight-guided generation, that leverages sentence-level information as a content plan to improve the traceability and faithfulness of generated summaries. Our framework applies self-planning methods to identify important content and then generates a summary conditioned on the plan. We explore both an end-to-end and two-stage variants of the approach, finding that the two-stage pipeline performs better on long and information-dense documents. Experiments on long-form summarisation datasets demonstrate that our method consistently improves factual consistency while preserving relevance and overall quality. On GovReport, our best approach has improved ROUGE-L by 4.1 points and achieves about 35% gains in SummaC scores. Qualitative analysis shows that highlight-guided summarisation helps preserve important details, leading to more accurate and insightful summaries across domains.",human
"We address the problem of robust causal effect estimation in the presence of unobserved confounding and selection bias. Existing methods often rely on strong parametric assumptions or instrumental variables, which may be difficult to justify in practice. We propose a novel approach based on adversarial learning and variational inference to learn a latent representation that effectively deconfounds the observed data and mitigates selection bias. The method, termed Variational Adversarial Deconfounding with Selection Correction (VADSC), employs a variational autoencoder to infer a latent confounder representation. An adversarial objective encourages independence between the latent representation and the observed treatment assignment, while a selection correction term, derived from a propensity model, aims to re-weight the data to account for selection bias. We evaluate VADSC on synthetic datasets designed to mimic real-world confounding and selection scenarios, as well as a semi-synthetic benchmark using observational data from a medical database. The empirical results demonstrate that VADSC consistently outperforms existing state-of-the-art methods, including inverse probability weighting, targeted maximum likelihood estimation, and methods based on generative adversarial networks, in terms of bias reduction and mean squared error for average treatment effect estimation, particularly when the degree of confounding and selection bias is substantial. This suggests VADSC offers a more robust and reliable approach for causal inference in observational studies.",ai
"Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.",human
"Graph Neural Networks (GNNs) have emerged as powerful tools for learning representations of graph-structured data, but challenges persist in handling noisy or incomplete graphs, particularly in scenarios with limited labeled data. This work addresses the problem of robust node classification in sparsely labeled, noisy graphs using a novel approach called Graph Denoising with Contrastive Regularization (GDCR). GDCR incorporates a denoising autoencoder framework within a GNN architecture to learn robust node embeddings by reconstructing cleaner graph structures from noisy inputs. Crucially, we introduce a contrastive regularization term that encourages the learned embeddings of semantically similar nodes to be close in the embedding space while pushing dissimilar nodes apart, even in the presence of noise. This is achieved by generating positive and negative node pairs based on both the original graph structure and the reconstructed, denoised graph. We evaluate GDCR on several benchmark datasets with varying levels of noise and label sparsity. Empirical results demonstrate that GDCR consistently outperforms state-of-the-art GNN models, including those designed for handling noisy graphs, achieving significant improvements in node classification accuracy, particularly in highly noisy and sparsely labeled settings. Ablation studies further validate the effectiveness of the denoising autoencoder and the contrastive regularization components of GDCR.",ai
"We investigate the efficacy of Transformer-based architectures for addressing challenges in natural language processing, specifically focusing on improving performance in low-resource machine translation and contextualized sentiment analysis. Existing methods often struggle with limited training data or fail to capture nuanced contextual information essential for accurate sentiment prediction. Our approach leverages a pre-trained Transformer model, fine-tuned with a novel multi-task learning objective that incorporates auxiliary language modeling and sentiment-aware contrastive learning. This facilitates knowledge transfer from high-resource languages and enhances the model's sensitivity to subtle semantic cues. Experimental results on benchmark datasets for low-resource English-to-Romani translation and the Stanford Sentiment Treebank demonstrate significant improvements over baseline Transformer models and state-of-the-art methods. Specifically, we observe BLEU score increases of up to 8 points in the low-resource translation task and a 2% improvement in sentiment classification accuracy. Ablation studies confirm the contribution of the multi-task learning objective and the effectiveness of contrastive learning in capturing contextual sentiment. These findings suggest that Transformer models, when augmented with appropriate training strategies, can effectively address limitations in data scarcity and contextual understanding within NLP applications.",ai
"Fine-scale forest monitoring is essential for understanding canopy structure and its dynamics, which are key indicators of carbon stocks, biodiversity, and forest health. Deep learning is particularly effective for this task, as it integrates spectral, temporal, and spatial signals that jointly reflect the canopy structure. To address this need, we introduce THREASURE-Net, a novel end-to-end framework for Tree Height Regression And Super-Resolution. The model is trained on Sentinel-2 time series using reference height metrics derived from LiDAR HD data at multiple spatial resolutions over Metropolitan France to produce annual height maps. We evaluate three model variants, producing tree-height predictions at 2.5 m, 5 m, and 10 m resolution. THREASURE-Net does not rely on any pretrained model nor on reference very high resolution optical imagery to train its super-resolution module; instead, it learns solely from LiDAR-derived height information. Our approach outperforms existing state-of-the-art methods based on Sentinel data and is competitive with methods based on very high resolution imagery. It can be deployed to generate high-precision annual canopy-height maps, achieving mean absolute errors of 2.62 m, 2.72 m, and 2.88 m at 2.5 m, 5 m, and 10 m resolution, respectively. These results highlight the potential of THREASURE-Net for scalable and cost-effective structural monitoring of temperate forests using only freely available satellite data. The source code for THREASURE-Net is available at: https://github.com/Global-Earth-Observation/threasure-net.",human
"We address the problem of automating complex, multi-step logical reasoning over knowledge graphs (KGs) with incomplete information, specifically focusing on challenges posed by noisy and missing relations. Existing path-finding algorithms often struggle with such KGs, producing unreliable inference chains. We introduce a novel approach, *Probabilistic Relational Reasoning with Attentive Node Selection (PRRANS)*, which combines probabilistic path scoring with an attention mechanism to selectively prioritize nodes during reasoning. PRRANS learns to estimate the likelihood of a given relation holding between two entities by aggregating evidence from multiple paths, incorporating uncertainty derived from observed data and prior knowledge. Furthermore, the attention mechanism dynamically focuses on the most relevant nodes within the KG based on the specific reasoning task, mitigating the impact of spurious connections. Experiments conducted on benchmark KG completion datasets, including WN18RR and FB15k-237, demonstrate that PRRANS significantly outperforms state-of-the-art path-finding and embedding-based methods in terms of link prediction accuracy (MRR and Hits@k). Ablation studies confirm the effectiveness of both the probabilistic scoring and the attentive node selection components. PRRANS offers a robust and interpretable solution for automated reasoning on real-world, incomplete knowledge graphs.",ai
"Real-world image captions often lack contextual depth, omitting crucial details such as event background, temporal cues, outcomes, and named entities that are not visually discernible. This gap limits the effectiveness of image understanding in domains like journalism, education, and digital archives, where richer, more informative descriptions are essential. To address this, we propose a multimodal pipeline that augments visual input with external textual knowledge. Our system retrieves semantically similar images using BEIT-3 (Flickr30k-384 and COCO-384) and SigLIP So-384, reranks them using ORB and SIFT for geometric alignment, and extracts contextual information from related articles via semantic search. A fine-tuned Qwen3 model with QLoRA then integrates this context with base captions generated by Instruct BLIP (Vicuna-7B) to produce event-enriched, context-aware descriptions. Evaluated on the OpenEvents v1 dataset, our approach generates significantly more informative captions compared to traditional methods, showing strong potential for real-world applications requiring deeper visual-textual understanding",human
"In this paper, we propose FakeRadar, a novel deepfake video detection framework designed to address the challenges of cross-domain generalization in real-world scenarios. Existing detection methods typically rely on manipulation-specific cues, performing well on known forgery types but exhibiting severe limitations against emerging manipulation techniques. This poor generalization stems from their inability to adapt effectively to unseen forgery patterns. To overcome this, we leverage large-scale pretrained models (e.g. CLIP) to proactively probe the feature space, explicitly highlighting distributional gaps between real videos, known forgeries, and unseen manipulations. Specifically, FakeRadar introduces Forgery Outlier Probing, which employs dynamic subcluster modeling and cluster-conditional outlier generation to synthesize outlier samples near boundaries of estimated subclusters, simulating novel forgery artifacts beyond known manipulation types. Additionally, we design Outlier-Guided Tri-Training, which optimizes the detector to distinguish real, fake, and outlier samples using proposed outlier-driven contrastive learning and outlier-conditioned cross-entropy losses. Experiments show that FakeRadar outperforms existing methods across various benchmark datasets for deepfake video detection, particularly in cross-domain evaluations, by handling the variety of emerging manipulation techniques.",human
"We investigate a novel approach to robust optimization in machine learning, specifically addressing the problem of distributional robustness against adversarial perturbations of the input data. Traditional robust optimization often relies on fixed uncertainty sets, which may not accurately reflect the true data distribution shift. This can lead to overly conservative solutions with diminished performance on clean data. We propose a data-driven robust optimization framework that dynamically learns the uncertainty set from the observed data distribution using a kernel density estimation approach. The uncertainty set is parameterized by a bandwidth parameter that controls the size of the neighborhood around each data point. We formulate the robust optimization problem as a minimax problem where the inner maximization is solved approximately using gradient ascent within the learned uncertainty set. We develop an efficient algorithm based on stochastic gradient descent for training the model and simultaneously optimizing the bandwidth parameter of the kernel density estimate. Empirically, we demonstrate the efficacy of our method on several benchmark datasets for image classification, showing significant improvements in robustness against adversarial attacks while maintaining competitive performance on clean data compared to existing robust optimization techniques. Specifically, our approach achieves a relative improvement of 5-10% in adversarial accuracy under strong PGD attacks, while exhibiting a negligible drop in clean accuracy. These results suggest that dynamically learning the uncertainty set leads to more adaptive and effective robust optimization solutions.",ai
"Graph Neural Networks (GNNs) have demonstrated remarkable efficacy in learning representations of graph-structured data for diverse tasks, yet performance degradation remains a challenge when dealing with noisy or incomplete graphs. This work addresses the problem of robust node classification in the presence of adversarial edge perturbations, where malicious modifications to the graph structure aim to mislead the GNN. We propose a novel adversarial training framework, NodeAttack-Defense GNN (NAD-GNN), which incorporates a differentiable adversarial edge attacker and a corresponding defense mechanism within the GNN learning process. The attacker generates perturbations to the graph structure by strategically adding and removing edges, while the defense mechanism learns to mitigate the impact of these perturbations by adaptively re-weighting node features based on their vulnerability to adversarial attacks. NAD-GNN is trained end-to-end, enabling the GNN to learn representations that are intrinsically robust to structural noise. Empirical evaluations on several benchmark datasets, including Cora, Citeseer, and PubMed, demonstrate that NAD-GNN significantly outperforms existing adversarial training methods and other robust GNN architectures in terms of node classification accuracy under various adversarial attack scenarios. Specifically, NAD-GNN achieves an average improvement of 5-10% in classification accuracy compared to state-of-the-art defense strategies. These results highlight the effectiveness of NAD-GNN in enhancing the robustness of GNNs against adversarial edge perturbations.",ai
"We address the challenge of accurate and efficient automated diagnosis of pulmonary diseases from chest X-ray images. Current diagnostic workflows often rely on manual interpretation, which is susceptible to inter-observer variability and can be time-consuming, particularly in resource-constrained environments. We propose a novel deep learning framework, termed Context-Aware Lung Segmentation and Classification Network (CALS-Net), which integrates a spatially-aware segmentation module with a hierarchical classification module. The segmentation module leverages a U-Net architecture incorporating attention mechanisms to precisely delineate lung boundaries and identify regions of interest. The classification module then processes these segmented regions through a convolutional neural network ensemble, employing a multi-scale feature extraction strategy to capture both local and global contextual information. CALS-Net was evaluated on a large, publicly available dataset of chest X-ray images with diverse pulmonary pathologies. The results demonstrate that CALS-Net achieves a classification accuracy of 92.7%, surpassing state-of-the-art methods by a significant margin (p < 0.01). Furthermore, the segmentation module exhibits a Dice coefficient of 0.95 for lung boundary delineation, indicating high accuracy in anatomical localization. The robust performance of CALS-Net suggests its potential as a valuable tool for assisting clinicians in the diagnosis of pulmonary diseases, ultimately improving patient outcomes.",ai
"We address the problem of identifying causal effects in observational data when the underlying causal graph is unknown and may contain unobserved confounders. Existing methods often rely on strong assumptions about functional form or causal sufficiency, which are frequently violated in practice. We propose a novel approach, Causal Structure Learning via Conditional Independence Testing and Score-based Optimization (CSL-CISO), that combines constraint-based structure learning with score-based causal discovery. First, conditional independence tests, utilizing a kernel-based conditional independence criterion, are employed to learn a partially directed acyclic graph (PDAG) representing the equivalence class of observationally equivalent causal structures. Second, a score-based optimization procedure, augmented with intervention calculus, is applied to refine the PDAG, explicitly searching for causal effects robust to potential unobserved confounding. Specifically, we optimize a score function that penalizes violations of causal faithfulness and favors structures that explain observed data patterns with minimal causal assumptions. We evaluate CSL-CISO on both synthetic datasets, where the ground truth causal graph is known, and benchmark real-world datasets. Our results demonstrate that CSL-CISO significantly improves the accuracy of causal effect estimation compared to state-of-the-art algorithms, particularly in the presence of latent variables and non-linear relationships. Furthermore, CSL-CISO exhibits improved robustness to sample size limitations and noise in the data.",ai
"We address the problem of effectively capturing long-range dependencies in graph-structured data, a persistent challenge in graph neural network (GNN) architectures. Traditional GNNs often rely on neighborhood aggregation, limiting their ability to propagate information across distant nodes within a graph. This limitation hinders performance in tasks where global context and non-local interactions are crucial. To mitigate this, we propose a novel Graph Transformer Network (GTN) architecture incorporating a learnable graph diffusion process. Our method employs attention mechanisms not only to aggregate feature information from neighboring nodes, but also to dynamically re-weight edges within the graph based on node attributes, effectively constructing task-specific diffusion pathways. Furthermore, we introduce a hierarchical pooling strategy that summarizes graph-level representations at multiple scales, facilitating the capture of both local and global structural patterns. We evaluate our GTN on a suite of benchmark graph classification datasets, including social network analysis and chemical compound classification tasks. Experimental results demonstrate that our approach achieves significant improvements in classification accuracy compared to state-of-the-art GNN models, particularly on graphs characterized by complex and sparse connectivity. Specifically, we observe an average increase of 3-5% in macro-F1 score across the tested datasets, suggesting that the learnable diffusion process and hierarchical pooling effectively address the limitations of existing neighborhood aggregation schemes.",ai
"Human behaviors are often guided or constrained by social norms, which are defined as shared, commonsense rules. For example, underlying an action ``"" are social norms that inform our conduct, such as ``''. Current AI systems that assess valence (i.e., support or oppose) of human actions by leveraging large-scale data training not grounded on explicit norms may be difficult to explain, and thus untrustworthy. Emulating human assessors by considering social norms can help AI models better understand and predict valence. While multiple norms come into play, conflicting norms can create tension and directly influence human behavior. For example, when deciding whether to ``'', one may balance against . In this paper, we introduce , a novel ethical assessment approach, to enhance valence prediction and explanation by generating conflicting social norms behind human actions, which strengthens the moral reasoning capabilities of language models by using a contrastive learning strategy. Extensive experiments demonstrate that our method outperforms strong baseline approaches, and human evaluations confirm that the generated social norms provide plausible explanations for the assessment of human behaviors.",human
"Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-UniversitÃ¤t WÃ¼rzburg in cooperation with the Technische UniversitÃ¤t Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.",human
"We investigate the problem of robust natural language processing, specifically focusing on improving model generalization across diverse and potentially adversarial input variations. Existing pre-trained language models often exhibit significant performance degradation when deployed in real-world scenarios characterized by noisy, out-of-domain, or subtly perturbed inputs. We propose a novel robust optimization framework, Contextual Perturbation with Adversarial Augmentation (CPAA), that integrates adversarial training with context-aware data augmentation. CPAA generates adversarial examples guided by a novel perturbation budget that scales with the contextual importance of each token, derived from attention mechanisms. Simultaneously, we augment the training data with synthetically generated examples utilizing back-translation and paraphrasing techniques, conditioned on the original input context. This dual approach aims to improve model resilience to both targeted adversarial attacks and naturally occurring variations in input data. Experiments on several benchmark datasets for text classification and natural language inference demonstrate that CPAA consistently outperforms standard training and existing adversarial training methods, achieving substantial gains in robustness metrics such as adversarial accuracy and out-of-domain performance. Furthermore, ablation studies validate the efficacy of both the contextual perturbation budget and the context-aware data augmentation strategies. The results highlight the potential of CPAA to enhance the reliability and generalizability of language models in practical applications.",ai
"The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.",human
"This article establishes a comprehensive theoretical framework demonstrating that SiLU (Sigmoid Linear Unit) activation networks achieve exponential approximation rates for smooth functions with explicit and improved complexity control compared to classical ReLU-based constructions. We develop a novel hierarchical construction beginning with an efficient approximation of the square function more compact in depth and size than comparable ReLU realizations, such as those given by Yarotsky. This construction yields an approximation error decaying as using networks of depth . We then extend this approach through functional composition to establish sharp approximation bounds for deep SiLU networks in approximating Sobolev-class functions, with total depth and size .",human
"The increasing use of generative models such as diffusion models for synthetic data augmentation has greatly reduced the cost of data collection and labeling in downstream perception tasks. However, this new data source paradigm may introduce important security concerns. This work investigates backdoor propagation in such emerging generative data supply chains, namely Data-Chain Backdoor (DCB). Specifically, we find that open-source diffusion models can become hidden carriers of backdoors. Their strong distribution-fitting ability causes them to memorize and reproduce backdoor triggers during generation, which are subsequently inherited by downstream models, resulting in severe security risks. This threat is particularly concerning under clean-label attack scenarios, as it remains effective while having negligible impact on the utility of the synthetic data. Furthermore, we discover an Early-Stage Trigger Manifestation (ESTM) phenomenon: backdoor trigger patterns tend to surface more explicitly in the early, high-noise stages of the diffusion model's reverse generation process before being subtly integrated into the final samples. Overall, this work reveals a previously underexplored threat in generative data pipelines and provides initial insights toward mitigating backdoor risks in synthetic data generation.",human
"### Abstract We address the problem of efficiently representing and reasoning with complex, hierarchical knowledge structures in dynamic environments. Existing knowledge representation formalisms often struggle with the trade-off between expressiveness, computational tractability, and adaptability to evolving information. We propose a novel hybrid approach, termed Adaptive Semantic Networks (ASN), which integrates aspects of description logics, probabilistic graphical models, and neural embeddings. ASN utilizes description logics for defining core domain ontologies and reasoning about logical relationships, probabilistic graphical models for managing uncertainty and dependencies within the knowledge base, and neural embeddings to capture semantic similarity and facilitate rapid knowledge retrieval. The system dynamically adjusts the granularity of representation based on contextual relevance and the frequency of information access, transitioning between computationally expensive, precise logical reasoning and efficient, approximate similarity-based inference. Empirical evaluation on a benchmark dataset of real-world knowledge graphs demonstrates that ASN achieves a significant improvement in both reasoning accuracy and query processing time compared to state-of-the-art methods, particularly in scenarios involving incomplete or noisy data. Furthermore, the adaptive nature of ASN allows it to maintain performance as the knowledge base grows and evolves, mitigating the scalability issues prevalent in traditional knowledge representation systems.",ai
"In context learning (ICL) underpins recent advances in large language models (LLMs), although its role and performance in causal reasoning remains unclear. Causal reasoning demands multihop composition and strict conjunctive control, and reliance on spurious lexical relations of the input could provide misleading results. We hypothesize that, due to their ability to project the input into a latent space, encoder and encoder decoder architectures are better suited for said multihop conjunctive reasoning versus decoder only models. To do this, we compare fine-tuned versions of all the aforementioned architectures with zero and few shot ICL in both natural language and non natural language scenarios. We find that ICL alone is insufficient for reliable causal reasoning, often overfocusing on irrelevant input features. In particular, decoder only models are noticeably brittle to distributional shifts, while finetuned encoder and encoder decoder models can generalize more robustly across our tests, including the non natural language split. Both architectures are only matched or surpassed by decoder only architectures at large scales. We conclude by noting that for cost effective, short horizon robust causal reasoning, encoder or encoder decoder architectures with targeted finetuning are preferable.",human
"Graph Neural Networks (GNNs) have emerged as a powerful paradigm for learning representations of graph-structured data, demonstrating significant performance across various applications. However, training deeper GNNs often faces challenges, including over-smoothing and vanishing gradients, hindering their ability to capture long-range dependencies and complex relational patterns. This work addresses the limitations of existing GNN architectures by introducing a novel Graph Residual Connection with Adaptive Feature Aggregation (GRCA). GRCA leverages learnable parameters to dynamically adjust the contribution of residual connections, allowing the network to selectively propagate information from previous layers based on the specific input graph and task. Furthermore, an adaptive feature aggregation mechanism is incorporated to combine node features from different layers, mitigating the over-smoothing problem by preserving localized information. We evaluate GRCA on a diverse set of benchmark datasets, including node classification on citation networks (Cora, Citeseer, PubMed) and graph classification on bioinformatics datasets (PROTEINS, MUTAG). Empirical results demonstrate that GRCA consistently outperforms state-of-the-art GNN models, achieving significant improvements in accuracy and F1-score. Ablation studies validate the effectiveness of the adaptive feature aggregation and residual connection mechanisms in enhancing the representation learning capabilities of GNNs.",ai
"We address the problem of identifying causal effects in observational data when unmeasured confounding exists and instrumental variables are weak and potentially invalid. Existing methods often require strong assumptions about the absence of certain confounding paths or the presence of truly valid instruments, which are difficult to verify in practice. We propose a novel approach, Causal Effect Estimation with Robust Instrumental Variable Selection (CEERIVS), which combines instrumental variable (IV) methods with robust statistical techniques to mitigate the impact of weak and invalid instruments. CEERIVS operates in two phases: first, a sparsity-inducing regularized regression identifies a set of candidate instruments, prioritizing those exhibiting strong associations with the treatment and minimal direct effects on the outcome. Second, a robust IV estimation procedure, based on a generalized method of moments (GMM) framework with a data-driven weighting matrix, is applied to estimate the causal effect, downweighting the influence of potentially invalid instruments based on their estimated exogeneity. We evaluate CEERIVS on both synthetic datasets with varying degrees of confounding and instrument validity and on real-world datasets concerning the effects of education on income and air pollution on respiratory health. Our results demonstrate that CEERIVS outperforms existing methods, including standard IV regression and sensitivity analysis approaches, in recovering the true causal effect, particularly when instruments are weak and invalid. Furthermore, CEERIVS provides a more robust and reliable estimation of causal effects in complex observational settings.",ai
"We address the challenge of sample inefficiency in reinforcement learning (RL) for continuous control tasks with sparse rewards. Traditional policy gradient methods often struggle to learn effective policies in such environments due to the infrequent and noisy reward signals. We propose a novel approach, termed ""Hierarchical Reinforcement Learning with Intrinsic Curiosity-Driven Exploration (HRL-ICDE),"" which integrates hierarchical RL with an intrinsic curiosity module to facilitate efficient exploration and learning. Our method decomposes the control problem into a two-level hierarchy: a high-level manager learning to set abstract goals for a low-level worker, and a low-level worker learning to achieve these goals. The intrinsic curiosity module provides an intrinsic reward signal to the worker, incentivizing exploration of novel states and overcoming the sparsity of the extrinsic reward. The manager then learns to set goals that maximize both the extrinsic and intrinsic rewards achieved by the worker. We evaluate HRL-ICDE on several benchmark continuous control tasks with sparse rewards. Our experimental results demonstrate that HRL-ICDE significantly outperforms state-of-the-art RL algorithms, including those that rely on solely extrinsic reward and those that implement flat curiosity, in terms of sample efficiency and final performance. Furthermore, we provide an ablation study to validate the effectiveness of each component of our proposed method.",ai
"We address the challenge of robust causal effect estimation in the presence of unobserved confounding and selection bias, a pervasive problem in observational studies. Traditional causal inference methods often rely on strong assumptions about the absence of unobserved confounding or the validity of the selection process, assumptions that are frequently violated in practice. To mitigate these limitations, we propose a novel framework leveraging instrumental variables (IVs) and adversarial learning. Our method, termed Adversarial Instrumental Variable Balancing (AIVB), simultaneously learns a representation that balances observed covariates across the IV-induced groups while minimizing the influence of unobserved confounders. This is achieved through an adversarial objective that penalizes discrepancies in the distribution of the learned representation between the IV-induced groups, while simultaneously promoting the prediction of treatment assignment based on the same representation. We demonstrate the efficacy of AIVB through extensive simulations and on real-world datasets related to healthcare and economics. Our results show that AIVB consistently outperforms state-of-the-art methods in terms of bias reduction and mean squared error for causal effect estimation, particularly when dealing with strong unobserved confounding and complex selection mechanisms. Further analysis reveals that AIVB is less sensitive to the choice of IVs compared to traditional IV methods.",ai
"Diffusion models have shown strong potential for solving inverse problems such as single-image super-resolution, where a high-resolution image is recovered from a low-resolution observation using a pretrained unconditional prior. Conditioning methods, including Diffusion Posterior Sampling (DPS) and Manifold Constrained Gradient (MCG), can substantially improve reconstruction quality, but they introduce additional hyperparameters that require careful tuning. In this work, we conduct an empirical ablation study on FFHQ super-resolution to identify the dominant factors affecting performance when applying conditioning to pretrained diffusion models, and show that the conditioning step size has a significantly greater impact than the diffusion step count, with step sizes in the range of [2.0, 3.0] yielding the best overall performance in our experiments.",human
"We investigate the problem of sample inefficiency in reinforcement learning (RL) within sparse reward environments, focusing on scenarios where successful task completion requires precise sequential actions. Existing methods often struggle to explore such environments effectively, leading to slow learning rates and suboptimal policies. We propose a novel hierarchical reinforcement learning approach, leveraging intrinsic motivation and goal-conditioned learning to address this challenge. Our method, termed ""Hierarchical Goal-Conditioned Exploration"" (HGCE), decomposes the task into a hierarchy of sub-goals, where a high-level policy learns to select sub-goals, and a low-level policy learns to achieve them. Intrinsic rewards are provided for discovering and achieving novel sub-goals, encouraging exploration of the state space. Furthermore, we introduce a state abstraction technique to improve generalization across similar sub-goals. We empirically evaluate HGCE on a suite of challenging simulated manipulation tasks with sparse rewards. Results demonstrate that HGCE significantly outperforms state-of-the-art RL algorithms, including proximal policy optimization (PPO) and hindsight experience replay (HER), in terms of sample efficiency and asymptotic performance. HGCE achieves a 3-5x improvement in sample efficiency and learns policies that achieve higher success rates on complex manipulation tasks. These findings suggest that hierarchical goal-conditioned exploration provides a promising avenue for addressing sample inefficiency in sparse reward RL.",ai
"The rapid growth in wireless infrastructure has increased the need to accurately estimate and forecast electromagnetic field (EMF) levels to ensure ongoing compliance, assess potential health impacts, and support efficient network planning. While existing studies rely on univariate forecasting of wideband aggregate EMF data, frequency-selective multivariate forecasting is needed to capture the inter-operator and inter-frequency variations essential for proactive network planning. To this end, this paper introduces EMFusion, a conditional multivariate diffusion-based probabilistic forecasting framework that integrates diverse contextual factors (e.g., time of day, season, and holidays) while providing explicit uncertainty estimates. The proposed architecture features a residual U-Net backbone enhanced by a cross-attention mechanism that dynamically integrates external conditions to guide the generation process. Furthermore, EMFusion integrates an imputation-based sampling strategy that treats forecasting as a structural inpainting task, ensuring temporal coherence even with irregular measurements. Unlike standard point forecasters, EMFusion generates calibrated probabilistic prediction intervals directly from the learned conditional distribution, providing explicit uncertainty quantification essential for trustworthy decision-making. Numerical experiments conducted on frequency-selective EMF datasets demonstrate that EMFusion with the contextual information of working hours outperforms the baseline models with or without conditions. The EMFusion outperforms the best baseline by 23.85% in continuous ranked probability score (CRPS), 13.93% in normalized root mean square error, and reduces prediction CRPS error by 22.47%.",human
"Out-of-equilibrium quantum many-body systems exhibit rapid correlation buildup that underlies many emerging phenomena. Exact wave-function methods to describe this scale exponentially with particle number; simpler mean-field approaches neglect essential two-particle correlations. The time-dependent two-particle reduced density matrix (TD2RDM) formalism offers a middle ground by propagating the two-particle reduced density matrix (2RDM) and closing the BBGKY hierarchy with a reconstruction of the three-particle cumulant. But the validity and existence of time-local reconstruction functionals ignoring memory effects remain unclear across different dynamical regimes. We show that a neural ODE model trained on exact 2RDM data (no dimensionality reduction) can reproduce its dynamics without any explicit three-particle information -- but only in parameter regions where the Pearson correlation between the two- and three-particle cumulants is large. In the anti-correlated or uncorrelated regime, the neural ODE fails, indicating that no simple time-local functional of the instantaneous two-particle cumulant can capture the evolution. The magnitude of the time-averaged three-particle-correlation buildup appears to be the primary predictor of success: For a moderate correlation buildup, both neural ODE predictions and existing TD2RDM reconstructions are accurate, whereas stronger values lead to systematic breakdowns. These findings pinpoint the need for memory-dependent kernels in the three-particle cumulant reconstruction for the latter regime. Our results place the neural ODE as a model-agnostic diagnostic tool that maps the regime of applicability of cumulant expansion methods and guides the development of non-local closure schemes. More broadly, the ability to learn high-dimensional RDM dynamics from limited data opens a pathway to fast, data-driven simulation of correlated quantum matter.",human
"--- **Automated Detection and Segmentation of Pulmonary Nodules in Computed Tomography Scans via Deep Learning with Attention Mechanisms** The accurate and timely detection and segmentation of pulmonary nodules in Computed Tomography (CT) scans is crucial for early diagnosis and treatment of lung cancer. However, the subtle appearance, variable size, and anatomical location of nodules pose significant challenges for radiologists. This study proposes a novel deep learning framework for automated pulmonary nodule detection and segmentation, leveraging a 3D convolutional neural network (CNN) architecture incorporating spatial and channel attention mechanisms. The proposed method first utilizes a ResNet-based encoder to extract hierarchical features from the CT volumes. Subsequently, attention modules are integrated within the decoder pathways to selectively emphasize relevant spatial regions and feature channels associated with nodule characteristics, suppressing irrelevant background information. We evaluated the performance of our method on the publicly available LIDC-IDRI dataset, achieving a competitive free-response operating characteristic (FROC) score of 0.896 at 8 false positives per scan for nodule detection. Furthermore, the segmentation branch yielded a Dice coefficient of 0.782 for nodule delineation. These results demonstrate the efficacy of our attention-guided deep learning approach for accurate and robust pulmonary nodule detection and segmentation in CT imaging, potentially assisting radiologists in improved diagnostic accuracy and reduced workload.",ai
"Personalization is one of the next milestones in advancing AI capability and alignment. We introduce PersonaMem-v2, the state-of-the-art dataset for LLM personalization that simulates 1,000 realistic user-chatbot interactions on 300+ scenarios, 20,000+ user preferences, and 128k-token context windows, where most user preferences are implicitly revealed to reflect real-world interactions. Using this data, we investigate how reinforcement fine-tuning enables a model to improve its long-context reasoning capabilities for user understanding and personalization. We also develop a framework for training an agentic memory system, which maintains a single, human-readable memory that grows with each user over time. In our experiments, frontier LLMs still struggle with implicit personalization, achieving only 37-48% accuracy. While they support long context windows, reasoning remains the bottleneck for implicit personalization tasks. Using reinforcement fine-tuning, we successfully train Qwen3-4B to outperforms GPT-5, reaching 53% accuracy in implicit personalization. Moreover, our agentic memory framework achieves state-of-the-art 55% accuracy while using 16x fewer input tokens, relying on a 2k-token memory instead of full 32k conversation histories. These results underscore the impact of our dataset and demonstrate agentic memory as a scalable path toward real-world personalized intelligence.",human
"We address the problem of automatically constructing and verifying formal proofs for complex theorems in propositional logic, a task traditionally reliant on human expertise and computationally expensive proof search algorithms. Current automated theorem provers often struggle with theorems requiring intricate reasoning steps or those involving a large number of variables and clauses, leading to significant computational bottlenecks. We introduce a novel reinforcement learning (RL) framework, ProofNet, that leverages graph neural networks (GNNs) to guide proof search. ProofNet represents the proof state as a graph, where nodes correspond to clauses and edges represent logical relationships. The GNN learns to predict the utility of applying different inference rules based on the graph structure, effectively pruning the search space and prioritizing promising proof paths. We train ProofNet on a large dataset of synthetically generated propositional logic theorems and evaluate its performance on a held-out test set of challenging theorems. Our results demonstrate that ProofNet significantly outperforms state-of-the-art automated theorem provers, achieving a higher success rate in proving complex theorems within a fixed time budget. Specifically, ProofNet increased the number of solved theorems by 23% compared to the next best solver, demonstrating the effectiveness of GNN-guided proof search for automated reasoning. Further analysis reveals that ProofNet learns to identify critical clauses and inference steps, mimicking human intuition in logical reasoning.",ai
"Retrieval-Augmented Generation (RAG) integrates non-parametric knowledge into Large Language Models (LLMs), typically from unstructured texts and structured graphs. While recent progress has advanced text-based RAG to multi-turn reasoning through Reinforcement Learning (RL), extending these advances to hybrid retrieval introduces additional challenges. Existing graph-based or hybrid systems typically depend on fixed or handcrafted retrieval pipelines, lacking the ability to integrate supplementary evidence as reasoning unfolds. Besides, while graph evidence provides relational structures crucial for multi-hop reasoning, it is substantially more expensive to retrieve. To address these limitations, we introduce , an RL-based framework that enables LLMs to perform multi-turn and adaptive graph-text hybrid RAG. jointly optimizes the entire generation process via RL, allowing the model to learn when to reason, what to retrieve from either texts or graphs, and when to produce final answers, all within a unified generation policy. To guide this learning process, we design a two-stage training framework that accounts for both task outcome and retrieval efficiency, enabling the model to exploit hybrid evidence while avoiding unnecessary retrieval overhead. Experimental results across five question answering benchmarks demonstrate that significantly outperforms existing RAG baselines, highlighting the benefits of end-to-end RL in supporting adaptive and efficient retrieval for complex reasoning.",human
"We investigate the problem of decentralized learning in cooperative multi-agent systems where agents possess heterogeneous data distributions and are constrained to communicate via a limited-bandwidth network. This setting presents significant challenges due to statistical heterogeneity and communication bottlenecks, leading to suboptimal performance for traditional distributed learning algorithms. We propose a novel federated learning framework, termed ""Adaptive Communication via Proximal Sparsification"" (ACPS), which addresses these challenges by incorporating proximal regularization to induce communication sparsity and adaptive communication strategies based on agent-specific data heterogeneity. Specifically, each agent periodically refines a local model and selectively transmits model updates to a central server based on a proximal operator applied to the difference between the local and global model. The server aggregates these updates and redistributes an updated global model. ACPS incorporates a dynamic communication threshold, allowing agents to adapt their communication frequency based on the divergence of their local data from the global data distribution. Empirical evaluations on benchmark multi-agent reinforcement learning environments, including predator-prey and cooperative navigation tasks, demonstrate that ACPS achieves superior convergence rates and improved overall performance compared to existing federated learning and decentralized optimization algorithms. Furthermore, ACPS significantly reduces communication overhead, enabling efficient learning in bandwidth-constrained settings while maintaining robustness against data heterogeneity.",ai
"In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.",human
"We investigate a novel approach to robust optimization in stochastic environments, specifically addressing the challenge of distributionally robust training of machine learning models. Traditional robust optimization often relies on constructing uncertainty sets based on assumptions about the data distribution that may not hold in practice. This work introduces a data-driven robust optimization framework that leverages kernel mean embeddings to characterize distributional ambiguity. Specifically, we propose a robust optimization problem where the ambiguity set is defined as a Wasserstein ball centered around the empirical distribution, and the radius of the ball is adaptively chosen using a kernel-based discrepancy measure. This allows the model to be robust against distributional shifts without requiring explicit knowledge of the underlying distribution. We derive a tractable reformulation of the robust optimization problem utilizing duality theory and demonstrate its applicability to both regression and classification tasks. Empirical evaluations on benchmark datasets subject to various synthetic and real-world distributional shifts demonstrate that our proposed method achieves significant improvements in out-of-distribution performance compared to standard empirical risk minimization and existing robust optimization techniques. Furthermore, we provide theoretical guarantees on the generalization performance of the learned models, showing that the Wasserstein radius can be chosen to balance robustness and accuracy.",ai
"We present a novel approach to automated detection and segmentation of pulmonary nodules in computed tomography (CT) scans, addressing the critical challenge of early lung cancer diagnosis. Existing methods often struggle with the high variability in nodule appearance, size, and location, leading to suboptimal sensitivity and specificity. Our proposed method, termed Multi-Scale Contextual Feature Aggregation Network (MSCFAN), leverages a deep convolutional neural network architecture incorporating multiple convolutional layers with varying receptive fields to capture both local nodule characteristics and broader contextual information within the lung parenchyma. Specifically, MSCFAN employs a hierarchical feature fusion strategy that aggregates features extracted at different scales, enabling the model to effectively differentiate between malignant nodules and benign structures such as blood vessels and pleural attachments. We evaluated MSCFAN on the publicly available Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) dataset. Experimental results demonstrate that MSCFAN achieves a significant improvement in nodule detection sensitivity at a clinically relevant false positive rate compared to several state-of-the-art methods. Furthermore, our segmentation accuracy, measured by Dice score, surpasses existing techniques, providing more precise delineation of nodule boundaries, which is crucial for accurate downstream analysis and treatment planning.",ai
"The rapid progress of Large Language Models (LLMs) has transformed natural language processing and broadened its impact across research and society. Yet, systematic evaluation of these models, especially for languages beyond English, remains limited. ""Challenging the Abilities of LAnguage Models in ITAlian"" (CALAMITA) is a large-scale collaborative benchmarking initiative for Italian, coordinated under the Italian Association for Computational Linguistics. Unlike existing efforts that focus on leaderboards, CALAMITA foregrounds methodology: it federates more than 80 contributors from academia, industry, and the public sector to design, document, and evaluate a diverse collection of tasks, covering linguistic competence, commonsense reasoning, factual consistency, fairness, summarization, translation, and code generation. Through this process, we not only assembled a benchmark of over 20 tasks and almost 100 subtasks, but also established a centralized evaluation pipeline that supports heterogeneous datasets and metrics. We report results for four open-weight LLMs, highlighting systematic strengths and weaknesses across abilities, as well as challenges in task-specific evaluation. Beyond quantitative results, CALAMITA exposes methodological lessons: the necessity of fine-grained, task-representative metrics, the importance of harmonized pipelines, and the benefits and limitations of broad community engagement. CALAMITA is conceived as a rolling benchmark, enabling continuous integration of new tasks and models. This makes it both a resource -- the most comprehensive and diverse benchmark for Italian to date -- and a framework for sustainable, community-driven evaluation. We argue that this combination offers a blueprint for other languages and communities seeking inclusive and rigorous LLM evaluation practices.",human
"Graph Neural Networks (GNNs) have emerged as powerful tools for learning representations of graph-structured data, yet their vulnerability to adversarial attacks remains a significant obstacle to their reliable deployment. This paper addresses the problem of enhancing the robustness of GNNs against such attacks, specifically focusing on evasion attacks targeting node classification tasks. We introduce a novel spectral regularization technique, termed Spectrally-Regularized Graph Neural Network (SRGNN), that explicitly encourages the learned node embeddings to align with the principal eigenvectors of a robust graph Laplacian matrix. The robust graph Laplacian is constructed using a carefully designed edge rewiring strategy that is resilient to adversarial perturbations. This approach mitigates the influence of adversarial edges by diminishing their contribution to the graph Laplacian's spectral decomposition, thereby stabilizing the node embeddings. Empirical evaluations on benchmark datasets demonstrate that SRGNN exhibits superior performance in resisting adversarial attacks compared to existing state-of-the-art defense mechanisms. Furthermore, our theoretical analysis provides insights into the spectral properties of SRGNN, validating its enhanced robustness against adversarial perturbations. The results showcase SRGNN's potential as a reliable defense mechanism for GNNs in security-critical applications.",ai
"The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity function and the solution function of the velocity ordinary differential equation (ODE), we propose a Flow Matching loss and a solution consistency loss to train our models. The Flow Matching loss allows our models to provide estimated velocity fields for Classifier-Free Guidance (CFG) during training, which improves generation performance. Notably, our consistency loss does not require the calculation of the Jacobian-vector product (JVP), a common requirement in recent works that is not well-optimized in deep learning frameworks like PyTorch. Experimental results indicate that, when trained from scratch using the same Diffusion Transformer (DiT) architecture and an equal number of training epochs, our models achieve better FID-50K scores than MeanFlow models on the ImageNet 256x256 dataset.",human
"Inferring causal relationships from observational text data remains a significant challenge in natural language processing. While correlational language models excel at prediction, they often fail to capture the underlying causal mechanisms, leading to spurious associations and unreliable generalizations. This paper addresses the problem of identifying and mitigating confounding bias in causal effect estimation from textual data. We propose a novel framework that integrates propensity score estimation with large language models (LLMs) to approximate treatment assignment probabilities conditional on observed confounders extracted from the text. Specifically, we leverage the contextualized representations learned by LLMs to identify potential confounders, followed by a fine-tuning procedure that optimizes for accurate propensity score prediction. To estimate the average treatment effect (ATE), we employ inverse probability weighting (IPW) based on the estimated propensity scores. We evaluate our method on a series of synthetic and real-world text datasets, demonstrating its ability to reduce confounding bias and improve the accuracy of causal effect estimation compared to baseline methods relying solely on correlational models. Experimental results show a significant reduction in ATE estimation error, with improvements ranging from 15% to 30% on benchmark datasets. These findings highlight the potential of incorporating causal inference techniques with LLMs to enhance the reliability and interpretability of text-based decision-making systems.",ai
"Automated Theorem Proving (ATP) represents a core research direction in artificial intelligence for achieving formal reasoning and verification, playing a significant role in advancing machine intelligence. However, current large language model (LLM)-based theorem provers suffer from limitations such as restricted domain coverage and weak generalization in mathematical reasoning. To address these issues, we propose MSC-180, a benchmark for evaluation based on the MSC2020 mathematical subject classification. It comprises 180 formal verification problems, 3 advanced problems from each of 60 mathematical branches, spanning from undergraduate to graduate levels. Each problem has undergone multiple rounds of verification and refinement by domain experts to ensure formal accuracy. Evaluations of state-of-the-art LLM-based theorem provers under the pass@32 setting reveal that the best model achieves only an 18.89% overall pass rate, with prominent issues including significant domain bias (maximum domain coverage 41.7%) and a difficulty gap (significantly lower pass rates on graduate-level problems). To further quantify performance variability across mathematical domains, we introduce the coefficient of variation (CV) as an evaluation metric. The observed CV values are 4-6 times higher than the statistical high-variability threshold, indicating that the models still rely on pattern matching from training corpora rather than possessing transferable reasoning mechanisms and systematic generalization capabilities. MSC-180, together with its multi-dimensional evaluation framework, provides a discriminative and systematic benchmark for driving the development of next-generation AI systems with genuine mathematical reasoning abilities.",human
"Recent divide-and-conquer reasoning approaches, particularly those based on Chain-of-Thought (CoT), have substantially improved the Text-to-SQL capabilities of Large Language Models (LLMs). However, when applied to complex enterprise databases, such methods struggle to maintain coherent reasoning due to limited context capacity, unreliable schema linking, and weak grounding in database semantics. To overcome these issues, we introduce DSR-SQL, a ual-tate easoning framework that models Text-to-SQL as an interaction between an adaptive context state and a progressive generation state. The first constructs a compact, semantically faithful environment by refining large schemas and selecting relevant structures, while the second formalizes SQL synthesis as feedback-guided state transitions, enabling the model to self-correct and align with user intent. Without any post-training or in-context examples, DSR-SQL achieves competitive performance, reaching 35.28\% execution accuracy on Spider 2.0-Snow and 68.32\% on BIRD development set. Our implementation will be open-sourced at: https://github.com/DMIRLAB-Group/DSR-SQL.",human
"We investigate the problem of robust text classification under adversarial attacks, specifically focusing on perturbations applied to word embeddings. Existing approaches often rely on adversarial training with specific, pre-defined attack strategies, leading to limited generalization against unseen attack types. This paper proposes a novel robust optimization framework that incorporates a distributionally robust optimization (DRO) perspective. Our approach utilizes a Wasserstein ambiguity set to model uncertainty in the embedding space, allowing the model to optimize for worst-case performance across a range of potential perturbations. We formulate the DRO problem as a min-max optimization, where the inner maximization problem seeks the most damaging perturbation within the ambiguity set and the outer minimization problem optimizes the model parameters to minimize the worst-case loss. We develop an efficient iterative algorithm to solve this complex optimization problem, leveraging Lagrangian duality to reformulate the inner maximization. Empirical evaluation on several benchmark text classification datasets demonstrates that our proposed method significantly improves robustness against various types of adversarial attacks, including synonym replacement, word deletion, and semantic perturbation attacks, compared to standard adversarial training and other baseline methods. Furthermore, our approach exhibits improved generalization to unseen attack strategies, indicating its effectiveness in handling diverse adversarial environments.",ai
"Recent advancements in retrieval-augmented generation (RAG) have significantly enhanced the ability of large language models (LLMs) to perform complex question-answering (QA) tasks. In this paper, we introduce MedBioRAG, a retrieval-augmented model designed to improve biomedical QA performance through a combination of semantic and lexical search, document retrieval, and supervised fine-tuning. MedBioRAG efficiently retrieves and ranks relevant biomedical documents, enabling precise and context-aware response generation. We evaluate MedBioRAG across text retrieval, close-ended QA, and long-form QA tasks using benchmark datasets such as NFCorpus, TREC-COVID, MedQA, PubMedQA, and BioASQ. Experimental results demonstrate that MedBioRAG outperforms previous state-of-the-art (SoTA) models and the GPT-4o base model in all evaluated tasks. Notably, our approach improves NDCG and MRR scores for document retrieval, while achieving higher accuracy in close-ended QA and ROUGE scores in long-form QA. Our findings highlight the effectiveness of semantic search-based retrieval and LLM fine-tuning in biomedical applications.",human
"We address the challenge of effectively representing and reasoning with complex relational knowledge in open-domain question answering. Existing knowledge representation schemes often struggle with scalability, expressiveness, and the ability to handle nuanced semantic relationships present in natural language. We introduce a novel Knowledge Representation Graph (KRG) architecture, leveraging dynamically constructed, context-aware subgraphs centered on entities extracted from both the question and supporting knowledge sources. Our approach employs a multi-stage process: (1) entity recognition and linking; (2) subgraph extraction using a path-ranking algorithm optimized for semantic relevance; and (3) relation encoding through graph neural networks (GNNs) trained to predict answer spans based on the subgraph representation. The GNN architecture integrates node features derived from pre-trained language models and edge features capturing the semantic type of relations. We evaluate our KRG framework on the ComplexWebQuestions benchmark and show a significant improvement in answer precision and recall compared to state-of-the-art methods utilizing static knowledge graphs or textual entailment approaches. Ablation studies demonstrate the crucial role of context-aware subgraph extraction and the effectiveness of the GNN-based relation encoding in capturing complex relational dependencies necessary for accurate question answering.",ai
"Large language models (LLMs) present a dual challenge for forensic linguistics. They serve as powerful analytical tools enabling scalable corpus analysis and embedding-based authorship attribution, while simultaneously destabilising foundational assumptions about idiolect through style mimicry, authorship obfuscation, and the proliferation of synthetic texts. Recent stylometric research indicates that LLMs can approximate surface stylistic features yet exhibit detectable differences from human writers, a tension with significant forensic implications. However, current AI-text detection techniques, whether classifier-based, stylometric, or watermarking approaches, face substantial limitations: high false positive rates for non-native English writers and vulnerability to adversarial strategies such as homoglyph substitution. These uncertainties raise concerns under legal admissibility standards, particularly the Daubert and Kumho Tire frameworks. The article concludes that forensic linguistics requires methodological reconfiguration to remain scientifically credible and legally admissible. Proposed adaptations include hybrid human-AI workflows, explainable detection paradigms beyond binary classification, and validation regimes measuring error and bias across diverse populations. The discipline's core insight, i.e., that language reveals information about its producer, remains valid but must accommodate increasingly complex chains of human and machine authorship.",human
"Early-exit networks are effective solutions for reducing the overall energy consumption and latency of deep learning models by adjusting computation based on the complexity of input data. By incorporating intermediate exit branches into the architecture, they provide less computation for simpler samples, which is particularly beneficial for resource-constrained devices where energy consumption is crucial. However, designing early-exit networks is a challenging and time-consuming process due to the need to balance efficiency and performance. Recent works have utilized Neural Architecture Search (NAS) to design more efficient early-exit networks, aiming to reduce average latency while improving model accuracy by determining the best positions and number of exit branches in the architecture. Another important factor affecting the efficiency and accuracy of early-exit networks is the depth and types of layers in the exit branches. In this paper, we use hardware-aware NAS to strengthen exit branches, considering both accuracy and efficiency during optimization. Our performance evaluation on the CIFAR-10, CIFAR-100, and SVHN datasets demonstrates that our proposed framework, which considers varying depths and layers for exit branches along with adaptive threshold tuning, designs early-exit networks that achieve higher accuracy with the same or lower average number of MACs compared to the state-of-the-art approaches.",human
"We address the problem of robust causal effect estimation in the presence of unobserved confounding and selection bias. Specifically, we propose a novel framework, Conditional Adversarial Balancing (CAB), which leverages adversarial training to learn a balanced representation of the data conditional on observed covariates. Unlike existing adversarial methods, CAB explicitly minimizes the discrepancy in conditional distributions of confounders given observed covariates between treatment groups and a pseudo-population constructed to mitigate selection bias. This pseudo-population is estimated using a kernel density matching approach, enabling the method to adapt to complex selection mechanisms. We theoretically demonstrate that CAB achieves tighter bounds on the bias compared to standard adversarial balancing techniques under mild assumptions. Empirically, we evaluate CAB on a suite of synthetic datasets with varying degrees of confounding and selection bias, demonstrating superior performance in recovering the average treatment effect compared to state-of-the-art methods, including inverse propensity weighting, targeted maximum likelihood estimation, and existing adversarial balancing algorithms. Furthermore, we apply CAB to a real-world observational study of the effect of a new medication on patient outcomes, showing its potential for more reliable causal inference in healthcare settings.",ai
"## Automated Diagnosis of Pulmonary Embolism Severity via Multi-Modal Image Analysis Pulmonary embolism (PE) diagnosis and severity assessment currently rely heavily on manual radiological interpretation, a process susceptible to inter-observer variability and time constraints. This work addresses the challenge of automating PE severity grading by leveraging a multi-modal computer vision approach. We propose a novel architecture that integrates information from computed tomography pulmonary angiography (CTPA) images, specifically right ventricular (RV) to left ventricular (LV) diameter ratio, pulmonary artery clot burden, and presence of right ventricular dysfunction signs, with clinical meta-data such as patient demographics and vital signs. The proposed method employs a convolutional neural network (CNN) to extract salient features from CTPA volumes, complemented by a multi-layer perceptron (MLP) to process clinical data. The outputs are fused through an attention mechanism, allowing the model to prioritize relevant features across both modalities for final severity classification. Experimental results on a dataset of 500 CTPA scans demonstrate that our method achieves an area under the receiver operating characteristic curve (AUC-ROC) of 0.89 for distinguishing between high-risk and non-high-risk PE, representing a significant improvement over baseline models relying solely on imaging or clinical data. This automated approach offers the potential to enhance diagnostic accuracy, expedite PE severity assessment, and improve patient management.",ai
"### Abstract The accurate and efficient analysis of medical images is crucial for timely diagnosis and treatment planning. However, manual interpretation of large volumes of imaging data is both time-consuming and prone to inter-observer variability. This work addresses the problem of automated lesion detection and segmentation in radiological images, specifically focusing on pulmonary nodule identification in computed tomography (CT) scans. We propose a novel multi-scale convolutional neural network (CNN) architecture incorporating attention mechanisms to enhance feature representation and improve localization accuracy. The proposed network, termed Attention-Guided Multi-Scale CNN (AGM-CNN), leverages a series of convolutional layers with varying kernel sizes to capture both fine-grained and global contextual information. Attention modules are integrated at different stages of the network to selectively highlight relevant features and suppress irrelevant background noise. We evaluate the performance of AGM-CNN on the publicly available LUNA16 dataset. Experimental results demonstrate that our proposed approach achieves a state-of-the-art performance in pulmonary nodule detection, achieving a competitive free-response operating characteristic (FROC) score of 0.896 and a significant improvement in segmentation accuracy as measured by the Dice coefficient of 0.782, outperforming existing methods. These findings highlight the potential of AGM-CNN as a valuable tool for radiologists in clinical practice, potentially leading to more accurate and efficient diagnosis of pulmonary diseases.",ai
"Finding rare but useful solutions in very large candidate spaces is a recurring practical challenge across language generation, planning, and reinforcement learning. We present a practical framework, (ICFA), that treats search as a target-conditioned reweighting process. ICFA reuses an available proposal sampler and a task-specific similarity function to form a focused sampling distribution, while adaptively controlling focusing strength to avoid degeneracy. We provide a clear recipe, a stability diagnostic based on effective sample size, a compact theoretical sketch explaining when ICFA can reduce sample needs, and two reproducible experiments: constrained language generation and sparse-reward navigation. We further show how structured prompts instantiate an approximate, language-level form of ICFA and describe a hybrid architecture combining prompted inference with algorithmic reweighting.",human
"We investigate the problem of enhancing automated theorem proving in first-order logic (FOL) by integrating large language models (LLMs) for strategic premise selection. Traditional theorem provers often struggle with large search spaces, leading to computational intractability even for provable theorems. Our method leverages LLMs fine-tuned on a corpus of formalized mathematics to predict relevant premises given a goal statement. Specifically, we employ a transformer-based architecture trained to rank available premises based on their probability of contributing to a successful proof derivation. The predicted premise rankings are then incorporated into the proof search algorithm of a standard resolution-based theorem prover, influencing the selection of clauses for inference. We evaluate our approach on a subset of the TPTP library, demonstrating a significant improvement in the number of theorems proven within a fixed time limit compared to the baseline prover without LLM-assisted premise selection. Our experiments reveal that the LLM-guided prover solves up to 15% more problems, particularly in domains requiring non-trivial mathematical reasoning. These results suggest that LLMs can be effectively integrated into automated reasoning systems to improve their performance and scalability.",ai
"Recent advances in Natural Language Processing (NLP) have been significantly driven by the Transformer architecture, yet challenges persist in effectively capturing long-range dependencies and adapting to resource-constrained environments. This work investigates a novel adaptation of the Transformer model, termed the ""Contextualized Attention Transformer"" (CAT), designed to enhance performance in tasks requiring deep contextual understanding. The CAT model incorporates a hierarchical attention mechanism that operates at both the word and sentence level, allowing for more nuanced representation of semantic relationships within a given text. Furthermore, we introduce a parameter-efficient fine-tuning strategy based on learned low-rank adaptations (LoRA) to facilitate deployment in low-resource settings. Empirical evaluation on a suite of benchmark NLP tasks, including text summarization, question answering, and sentiment analysis, demonstrates that the CAT model outperforms standard Transformer baselines by a significant margin. Specifically, we observe a 4.2% improvement in ROUGE-2 score on the CNN/DailyMail summarization dataset and a 3.8% increase in F1 score on the SQuAD v2.0 question answering dataset. Moreover, our LoRA fine-tuning approach reduces memory footprint by approximately 60% compared to full fine-tuning, while maintaining comparable performance levels. These results highlight the efficacy of the CAT architecture and the associated fine-tuning strategy for improving Transformer performance in complex NLP tasks, particularly in resource-limited scenarios.",ai
"We address the challenge of training machine learning models on sensitive data while preserving individual privacy. Specifically, we focus on natural language processing tasks where models are trained on text corpora containing potentially private information. Our work introduces a novel privacy-preserving federated learning framework that combines differential privacy with secure aggregation techniques, optimized for sequential data. The core innovation lies in a recurrent neural network (RNN) architecture designed to be inherently more resistant to privacy attacks, achieved through parameter sharing and gradient clipping at the sequence level. We further enhance privacy by injecting calibrated noise during the gradient aggregation process. Empirically, we evaluate our approach on sentiment analysis and next-word prediction tasks using publicly available datasets, modified to simulate federated settings with varying levels of data heterogeneity. Our results demonstrate that the proposed framework achieves a significant improvement in utility-privacy trade-off compared to existing federated learning baselines with traditional RNN architectures. We show that we can maintain comparable model accuracy to non-private federated learning while provably bounding the privacy loss, measured in terms of -differential privacy. The proposed architecture and optimization strategy offer a practical solution for training privacy-preserving language models in real-world federated environments.",ai
"We address the problem of emergent communication inefficiency in cooperative multi-agent reinforcement learning (MARL) scenarios involving complex, compositional tasks. While agents can develop successful communication protocols, these often exhibit redundancy and sub-optimality, particularly as task complexity increases. Our approach introduces a novel regularisation term, the Information Bottleneck for Communication (IBC), integrated into the MARL objective function. IBC penalises the mutual information between the agent's observation and the transmitted message, forcing agents to distill relevant information and avoid unnecessary communication. We evaluate the efficacy of IBC on a suite of challenging multi-agent navigation and cooperative puzzle-solving environments. Empirical results demonstrate that IBC significantly reduces the communication bandwidth required for successful task completion, without compromising overall performance. Furthermore, analysis of the learned communication protocols reveals that IBC promotes the emergence of more structured and interpretable communication strategies, improving robustness to noisy environments and enabling faster adaptation to novel task variations. We observe a significant reduction in message length and an increase in the information content per message compared to standard MARL algorithms.",ai
"Graph Neural Networks (GNNs) have demonstrated efficacy in modeling relational data across diverse domains. However, their performance is often limited by the over-smoothing problem, where node representations converge to similar values as the number of layers increases, hindering the network's ability to distinguish between nodes with differing structural roles. This work addresses the over-smoothing issue by proposing a novel spectral-based graph neural network architecture, dubbed Spectral Graph Convolution with Adaptive Frequency Selection (SGC-AFS). Our method employs a Chebyshev polynomial approximation of the graph Laplacian to perform spectral graph convolution, enabling efficient computation in the vertex domain. Crucially, we introduce an adaptive frequency selection mechanism that learns to selectively amplify or attenuate different spectral components based on the specific task and graph structure. This mechanism allows the network to prioritize relevant frequency bands, mitigating over-smoothing by preserving high-frequency information essential for distinguishing local node neighborhoods. Empirical evaluation on a suite of benchmark node classification datasets demonstrates that SGC-AFS consistently outperforms existing GNN models, achieving significant improvements in accuracy, particularly on graphs prone to over-smoothing. Furthermore, ablation studies validate the efficacy of the adaptive frequency selection mechanism in controlling the spectral characteristics of the learned node representations.",ai
"Graph Neural Networks (GNNs) have demonstrated significant efficacy in processing non-Euclidean data, yet their performance on large-scale graphs remains constrained by computational bottlenecks associated with neighborhood aggregation and message passing. This work addresses the scalability challenge of GNNs in scenarios involving graphs with hundreds of millions of nodes and billions of edges. We propose a novel sampling-based GNN architecture, termed Adaptive Subgraph Learning (ASL), which dynamically selects and aggregates information from a representative subset of each node's neighborhood. ASL incorporates a learned sampling strategy that prioritizes nodes with high structural importance, identified through a combination of centrality measures and node embeddings. The sampling process is further refined through an attention mechanism that weights the importance of sampled neighbors based on their relevance to the target node. We evaluate ASL on a range of benchmark datasets, including the Open Graph Benchmark (OGB) products dataset and a large-scale social network graph. Our results demonstrate that ASL achieves comparable or superior performance to state-of-the-art GNNs, while requiring significantly less computational resources and memory. Specifically, ASL achieves a 5% improvement in classification accuracy on the OGB products dataset compared to graph sampling approaches, with a 30% reduction in training time. These findings suggest that ASL offers a promising approach for scaling GNNs to massive graphs without sacrificing predictive accuracy.",ai
"Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, modular framework for automated structured feature extraction from clinical notes leveraging locally deployed large language models (LLMs) on institutionally approved, Health Insurance Portability and Accountability Act (HIPPA)-compliant compute infrastructure. This system integrates retrieval augmented generation (RAG) and structured response methods of LLMs into a widely deployable and scalable container to provide feature extraction for diverse clinical domains. In evaluation, the framework achieved high accuracy across multiple medical characteristics present in large bodies of patient notes when compared against an expert-annotated dataset and identified several annotation errors missed in manual review. This framework demonstrates the potential of LLM systems to reduce the burden of manual chart review through automated extraction and increase consistency in data capture, accelerating clinical research.",human
"Deep learning techniques have demonstrated considerable promise in medical image analysis, yet often suffer from limitations in generalization across diverse patient populations and imaging modalities. This work addresses the problem of robust and adaptable image segmentation in the context of identifying cancerous lesions in histopathological images. Specifically, we propose a novel architecture, the Contextual Multi-Scale Attentive Network (CMSAN), that leverages a combination of convolutional neural networks (CNNs) and transformer-based attention mechanisms to capture both local and global contextual information. The CMSAN incorporates multi-scale feature extraction through parallel convolutional streams with varying receptive fields, allowing the model to effectively capture features relevant to lesion detection at different resolutions. A self-attention module is integrated to model long-range dependencies and improve segmentation accuracy by considering relationships between distant regions of the image. We evaluate the CMSAN on a publicly available dataset of breast cancer histology images and demonstrate significant improvements in segmentation performance compared to state-of-the-art methods, achieving a Dice coefficient of 0.87 and an Intersection over Union (IoU) score of 0.78. Furthermore, we assess the model's robustness to variations in staining techniques through cross-dataset evaluation, showcasing its superior generalization capabilities compared to conventional CNN-based approaches. These results suggest that the CMSAN provides a robust and accurate framework for medical image segmentation, facilitating improved diagnostic accuracy and personalized treatment planning.",ai
"We address the challenge of coordinating decentralized agents in complex, dynamic environments where communication is limited and stochastic. Specifically, we investigate the problem of cooperative navigation in a multi-agent system facing uncertainty in agent localization and intermittent network connectivity. Existing approaches often rely on centralized control or assume reliable communication, which are unrealistic in many real-world scenarios. We propose a novel decentralized reinforcement learning (DRL) algorithm, termed Communication-Aware Recurrent Policy Gradient (CARPG), which integrates an attention mechanism to dynamically prioritize messages from neighboring agents based on their perceived relevance to the individual agent's state and task. CARPG also incorporates a recurrent neural network architecture to maintain a belief state across time steps, mitigating the effects of intermittent communication. Empirical evaluation on a simulated cooperative navigation task demonstrates that CARPG significantly outperforms baseline DRL algorithms and traditional cooperative strategies, exhibiting superior coordination, robustness to communication failures, and improved task completion rates. Furthermore, analysis reveals that the learned attention weights effectively capture the underlying communication dependencies, enabling agents to selectively attend to the most informative messages. These results indicate the potential of CARPG for addressing coordination challenges in resource-constrained multi-agent systems.",ai
"Legal AI systems powered by retrieval-augmented generation (RAG) face a critical accountability challenge: when an AI assistant cites case law, statutes, or contractual clauses, practitioners need verifiable guarantees that generated text faithfully represents source documents. Existing hallucination detectors rely on semantic similarity metrics that tolerate entity substitutions, a dangerous failure mode when confusing parties, dates, or legal provisions can have material consequences. We introduce HalluGraph, a graph-theoretic framework that quantifies hallucinations through structural alignment between knowledge graphs extracted from context, query, and response. Our approach produces bounded, interpretable metrics decomposed into (EG), measuring whether entities in the response appear in source documents, and (RP), verifying that asserted relationships are supported by context. On structured control documents, HalluGraph achieves near-perfect discrimination (400 words, 20 entities), HalluGraph achieves , while maintaining robust performance () on challenging generative legal task, consistently outperforming semantic similarity baselines. The framework provides the transparency and traceability required for high-stakes legal applications, enabling full audit trails from generated assertions back to source passages.",human
"Graph Neural Networks (GNNs) have demonstrated significant potential in modeling relational data across diverse domains. However, the performance of GNNs is often contingent on the quality and availability of node features and graph structure. In scenarios where node features are sparse or missing, relying solely on the observed graph structure can lead to suboptimal representations. This work addresses the problem of learning robust node embeddings in GNNs when faced with incomplete node feature information. We propose a novel variational autoencoder-based GNN framework that explicitly models the uncertainty associated with missing node features. Our approach, termed Variational Feature Imputation Graph Neural Network (VF-IGNN), leverages a variational inference mechanism to impute missing features while simultaneously learning node embeddings. By incorporating the uncertainty in feature imputation, VF-IGNN mitigates the risk of overfitting to potentially inaccurate imputed values and promotes the learning of more generalizable representations. Experimental results on several benchmark graph datasets demonstrate that VF-IGNN consistently outperforms state-of-the-art GNNs and imputation methods, particularly in scenarios with high missing feature rates. Furthermore, we conduct an ablation study to demonstrate the effectiveness of the variational inference component in capturing the uncertainty associated with feature imputation, leading to improved downstream task performance. The proposed approach offers a principled framework for handling missing node features in GNNs, enabling more effective learning from incomplete graph data.",ai
"We address the problem of robust causal effect estimation in the presence of unobserved confounding and selection bias. Traditional methods, relying on strong ignorability assumptions, are often invalidated by such real-world complexities. We introduce a novel instrumental variable (IV) method, termed ""Selection-Adjusted Instrumental Variable Regression"" (SAIVR), that leverages observed selection indicators to partially identify the causal effect. SAIVR incorporates a proxy for the selection process directly into the IV regression framework, allowing for consistent estimation under weaker assumptions than standard IV approaches. Specifically, we require only that the selection indicator be conditionally independent of the potential outcomes given the instrument and observed covariates, a condition more plausible in many practical settings than full ignorability. We rigorously derive the identification conditions for SAIVR and provide a consistent estimator along with finite-sample guarantees. Through extensive simulations, we demonstrate that SAIVR significantly outperforms existing IV methods and other benchmark approaches when selection bias is present. We further validate the effectiveness of our method on a real-world dataset concerning the effect of a medical intervention, showing improved robustness compared to alternative causal inference techniques. Our results highlight the importance of explicitly accounting for selection bias in causal inference and offer a practical tool for researchers dealing with such challenges.",ai
"### Abstract Automated analysis of medical images holds the potential to significantly improve diagnostic accuracy and efficiency. However, the inherent complexity and variability of medical data pose substantial challenges for existing computer vision techniques. This work addresses the problem of robust and accurate segmentation of pulmonary nodules in computed tomography (CT) scans, a task critical for early detection and diagnosis of lung cancer. We propose a novel deep learning architecture, termed Context-Aware Multi-Scale Network (CAMSN), that leverages both local and global contextual information to enhance segmentation performance. CAMSN integrates a multi-scale feature extraction module with an attention mechanism that adaptively weights features based on their relevance to nodule boundaries. The proposed architecture was trained and evaluated on a publicly available dataset of lung CT scans containing annotated nodules. Experimental results demonstrate that CAMSN achieves state-of-the-art segmentation accuracy, surpassing existing methods by a significant margin in terms of Dice similarity coefficient and Jaccard index. Specifically, CAMSN achieved a mean Dice score of 0.82 and a Jaccard index of 0.70, representing improvements of 5% and 7% respectively, compared to the best-performing baseline method. These findings suggest that CAMSN provides a valuable tool for automated pulmonary nodule segmentation and can potentially assist radiologists in the early detection of lung cancer.",ai
"Neural network optimization remains one of the most consequential yet poorly understood challenges in modern AI research, where improvements in training algorithms can lead to enhanced feature learning in foundation models, order-of-magnitude reductions in training time, and improved interpretability into how networks learn. While stochastic gradient descent (SGD) and its variants have become the de facto standard for training deep networks, their success in these over-parameterized regimes often appears more empirical than principled. This thesis investigates this apparent paradox by tracing the evolution of optimization algorithms from classical first-order methods to modern higher-order techniques, revealing how principled algorithmic design can demystify the training process. Starting from first principles with SGD and adaptive gradient methods, the analysis progressively uncovers the limitations of these conventional approaches when confronted with anisotropy that is representative of real-world data. These breakdowns motivate the exploration of sophisticated alternatives rooted in curvature information: second-order approximation techniques, layer-wise preconditioning, adaptive learning rates, and more. Next, the interplay between these optimization algorithms and the broader neural network training toolkit, which includes prior and recent developments such as maximal update parametrization, learning rate schedules, and exponential moving averages, emerges as equally essential to empirical success. To bridge the gap between theoretical understanding and practical deployment, this paper offers practical prescriptions and implementation strategies for integrating these methods into modern deep learning workflows.",human
"Graph Neural Networks (GNNs) have demonstrated remarkable performance in various node-level and graph-level prediction tasks. However, the over-smoothing problem, where node representations converge to indistinguishable values as the number of GNN layers increases, remains a significant challenge, limiting the expressive power of deep GNN architectures. This work addresses the over-smoothing problem by introducing a novel Graph Fourier Transform-based (GFT) layer aggregation method. Specifically, we leverage the properties of the GFT to selectively filter and combine node representations across layers, emphasizing low-frequency components associated with global graph structure while attenuating high-frequency components that contribute to noise and over-smoothing. The proposed method, termed GFT-Agg, learns a frequency-dependent weighting scheme for each layer's output within the GFT domain, effectively controlling the contribution of different frequency bands to the final node embeddings. Empirical evaluations on benchmark datasets, including Cora, CiteSeer, and PubMed, demonstrate that GFT-Agg significantly outperforms existing GNN architectures and aggregation strategies in terms of node classification accuracy, particularly for deeper networks. Furthermore, analysis of the learned frequency weights reveals that the model adaptively prioritizes lower frequency components as depth increases, mitigating over-smoothing and preserving discriminative information. The results highlight the efficacy of GFT-based aggregation in constructing more robust and expressive deep GNNs.",ai
"Prosody -- the melody of speech -- conveys critical information often not captured by the words or text of a message. In this paper, we propose an information-theoretic approach to quantify how much information is expressed by prosody alone and not by text, and crucially, what that information is about. Our approach applies large speech and language models to estimate the mutual information between a particular dimension of an utterance's meaning (e.g., its emotion) and any of its communication channels (e.g., audio or text). We then use this approach to quantify how much information is conveyed by audio and text about sarcasm, emotion, and questionhood, using speech from television and podcasts. We find that for sarcasm and emotion the audio channel -- and by implication the prosodic channel -- transmits over an order of magnitude more information about these features than the text channel alone, at least when long-term context beyond the current sentence is unavailable. For questionhood, prosody provides comparatively less additional information. We conclude by outlining a program applying our approach to more dimensions of meaning, communication channels, and languages.",human
"We investigate the application of transformer-based architectures to the task of long-range dependency modeling in natural language processing (NLP). Despite their demonstrated efficacy, transformers exhibit computational complexity that scales quadratically with sequence length, hindering their application to documents and extended discourse. This work introduces a novel sparse attention mechanism, implemented via a learned, content-aware routing strategy, to mitigate this computational bottleneck. This strategy, termed ""Routed Attention,"" dynamically allocates computational resources based on the semantic relevance of different sequence positions, effectively pruning irrelevant attention connections. We evaluate Routed Attention on a suite of NLP benchmarks, including long document classification, text summarization, and question answering tasks involving lengthy contexts. Our results demonstrate that models employing Routed Attention achieve comparable or superior performance to dense attention baselines, while exhibiting a significant reduction in computational cost and memory footprint. Specifically, we observe a reduction of up to 40% in training time and a 30% decrease in memory usage, without sacrificing accuracy, on the Longformer-Encoder-Decoder (LED) architecture for document summarization. These findings suggest that Routed Attention provides a scalable and efficient alternative to dense attention for processing long sequences in NLP.",ai
"We investigate the problem of robust optimization in uncertain environments with non-convex objective functions, a scenario prevalent in complex decision-making processes. Traditional robust optimization techniques often rely on convex relaxation or tractable uncertainty sets, which can lead to overly conservative solutions or computational intractability in non-convex settings. To address this, we propose a novel data-driven robust optimization framework that leverages a distributionally robust approach combined with a learned ambiguity set. Our method utilizes Wasserstein distance to quantify the discrepancy between the empirical distribution derived from observed data and the true, unknown distribution. We learn the parameters of a flexible ambiguity set, parameterized by neural networks, which encapsulates plausible variations in the uncertain parameters. This learned ambiguity set is then incorporated into a robust optimization formulation, minimizing the worst-case objective function value over the ambiguity set. The resulting optimization problem is solved using a customized alternating direction method of multipliers (ADMM) algorithm. Empirical results on benchmark non-convex optimization problems demonstrate that our approach achieves a significantly better trade-off between robustness and optimality compared to existing methods, yielding solutions with superior out-of-sample performance and reduced conservatism. The learned ambiguity sets adapt to the data distribution, enabling more precise modeling of uncertainty and leading to more effective robust decision-making.",ai
"We address the problem of robust causal effect estimation in the presence of unobserved confounding and selection bias. Traditional causal inference methods often rely on strong assumptions regarding the absence of unobserved confounders or the ignorability of selection mechanisms, which are frequently violated in real-world observational data. We propose a novel framework, Causal Balancing with Latent Confounders (CBLC), which leverages a latent variable model to simultaneously infer unobserved confounders and adjust for selection bias. CBLC combines variational autoencoders with balancing weights derived from a modified propensity score, learned in the latent space. The objective function jointly optimizes for reconstruction error, balancing of observed covariates, and reduction of discrepancy between treated and control groups within latent confounder strata. We evaluate CBLC on both synthetic and real-world datasets exhibiting varying degrees of unobserved confounding and selection bias. Our results demonstrate that CBLC consistently outperforms existing methods, including traditional propensity score matching and inverse probability weighting, in terms of bias reduction and accuracy of causal effect estimation. Furthermore, we show that the learned latent representations provide interpretable insights into the structure of unobserved confounding variables. The proposed method offers a significant advancement in robust causal inference for observational studies.",ai
"Results in interpretability suggest that large vision and language models learn implicit linear encodings when models are biased by in-context prompting. However, the existence of similar linear representations in more general adaptation regimes has not yet been demonstrated. In this work, we develop the concept of a task matrix, a linear transformation from a base to finetuned embedding state. We demonstrate that for vision and text models and ten different datasets, a base model augmented with a task matrix achieves results surpassing linear probes, sometimes approaching finetuned levels. Our results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures. Moreover, we show that a data-based approximation for such encodings is both efficient and generalizable to multiple domains. We make our implementation publicly available.",human
"We address the vulnerability of neural machine translation (NMT) systems to adversarial attacks, specifically focusing on imperceptible word-level perturbations. These perturbations, crafted to maximize the probability of incorrect translations, expose a critical lack of robustness in state-of-the-art models. Existing adversarial training methods often rely on computationally expensive inner loop optimization and may suffer from reduced performance on clean data. We propose a novel robust optimization framework that leverages projected gradient descent (PGD) on the embedding space to efficiently generate adversarial examples. Furthermore, we introduce a regularization term that explicitly penalizes sensitivity to small embedding variations, promoting a smoother loss landscape. Our approach, termed ""Embedding Smoothing for Adversarial Robustness"" (ESAR), is evaluated on standard machine translation benchmarks, including WMT'14 English-German and English-French. Experimental results demonstrate that ESAR significantly improves the robustness of NMT models against both white-box and black-box adversarial attacks compared to baseline adversarial training strategies. Crucially, ESAR achieves this enhanced robustness with minimal degradation in translation quality on clean data, offering a practical and efficient method for deploying secure NMT systems. We also analyze the impact of different regularization strengths and perturbation budgets on the trade-off between robustness and accuracy.",ai
"We present DeepVekua, a hybrid architecture that unifies geometric deep learning with spectral analysis to solve partial differential equations (PDEs) in sparse data regimes. By learning a diffeomorphic coordinate transformation that maps complex geometries to a latent harmonic space, our method outperforms state-of-the-art implicit representations on advection-diffusion systems. Unlike standard coordinate-based networks which struggle with spectral bias, DeepVekua separates the learning of geometry from the learning of physics, solving for optimal spectral weights in closed form. We demonstrate a 100x improvement over spectral baselines. The code is available at https://github.com/VladimerKhasia/vekuanet.",human
"Transformer models have achieved state-of-the-art performance across a diverse range of natural language processing (NLP) tasks. However, the computational complexity of self-attention, a core component of the Transformer architecture, scales quadratically with the input sequence length, posing a significant bottleneck for processing long documents. This work addresses this challenge by investigating a novel sparse attention mechanism, termed ""Localized Global Attention"" (LGA), which aims to reduce computational cost while preserving model expressiveness. LGA partitions the input sequence into local segments and selectively attends to a small set of global tokens distributed across the entire sequence, in addition to attending within each local segment. The global tokens are learned embeddings designed to capture salient information from the entire input. We evaluate LGA on several benchmark NLP tasks requiring long-range dependency modeling, including document classification and summarization. Empirical results demonstrate that LGA achieves comparable or superior performance to full self-attention models with significantly reduced computational requirements, particularly for long input sequences. Specifically, we observe a speedup of up to 3x on document classification tasks while maintaining accuracy within 1% of the full attention baseline. These findings suggest that LGA provides a promising avenue for scaling Transformer models to handle longer sequences and more complex NLP tasks.",ai
"**Abstract** The accurate and efficient segmentation of brain tumors from multi-modal Magnetic Resonance Imaging (MRI) is crucial for diagnosis, treatment planning, and monitoring disease progression. However, manual segmentation is time-consuming and subject to inter-observer variability. Existing automated segmentation methods often struggle with the significant heterogeneity in tumor size, shape, and location, as well as the varying image quality inherent in clinical MRI datasets. We propose a novel deep learning architecture, a cascaded U-Net with attention mechanisms and multi-scale feature fusion, to address these challenges. The cascaded structure allows for hierarchical segmentation, first delineating the general tumor region and subsequently refining the boundaries of tumor sub-regions (enhancing tumor, tumor core, and whole tumor). Attention gates are incorporated to focus the network's attention on relevant image features, improving segmentation accuracy in regions with ambiguous boundaries. Multi-scale feature fusion integrates information from different resolutions, capturing both global context and fine-grained details. The proposed method was evaluated on the BraTS 2021 dataset, achieving Dice scores of 0.89, 0.83, and 0.86 for whole tumor, tumor core, and enhancing tumor, respectively. These results demonstrate a significant improvement over baseline U-Net models and comparable performance to state-of-the-art techniques, indicating the potential of this approach for clinical translation.",ai
"This paper addresses the challenge of training machine learning models that exhibit robustness against adversarial perturbations in the input data, a critical concern for deploying models in safety-sensitive applications. While empirical risk minimization (ERM) often yields high performance on clean data, it is known to be vulnerable to even small, carefully crafted adversarial attacks. We propose a novel robust optimization framework leveraging a dual formulation and a projected accelerated gradient descent scheme to efficiently train models that are provably robust. Specifically, we formulate the robust optimization problem as a min-max problem, where the minimization seeks to minimize the risk over all possible data points, and the maximization searches for the worst-case perturbation within a specified threat model. By utilizing the strong duality property, we transform the problem into a tractable form amenable to efficient optimization. Furthermore, our algorithm incorporates a projection step to ensure that the adversarial perturbations remain within the predefined threat model, and an accelerated gradient descent scheme to improve convergence speed. Experimental results on standard image classification datasets (CIFAR-10 and MNIST) demonstrate that our approach achieves significantly higher robust accuracy compared to state-of-the-art defense methods, while maintaining competitive performance on clean data. The proposed algorithm also exhibits improved scalability, enabling training of robust models with larger architectures and more complex datasets.",ai
"Recent advancements in Natural Language Processing (NLP) have been largely driven by the Transformer architecture. However, limitations persist in efficiently capturing long-range dependencies and adapting to diverse task requirements within a single model. This work investigates a novel approach leveraging a sparsely-activated Transformer variant coupled with a dynamic routing mechanism for improved contextual representation. Our method, termed Dynamic Sparse Transformer (DST), selectively activates relevant Transformer layers based on the input sequence and task specification. This dynamic routing is achieved through a differentiable, task-conditioned gating network that learns to distribute computational resources across layers. We evaluate DST on a suite of benchmark NLP tasks, including text classification, question answering, and machine translation. Results demonstrate that DST achieves comparable or superior performance to standard Transformer models while significantly reducing computational cost, particularly on longer sequences. Ablation studies highlight the effectiveness of the dynamic routing mechanism in adapting to varying sequence lengths and task complexities. Furthermore, analysis of the layer activation patterns reveals that DST learns to allocate computational resources strategically, focusing on task-relevant information and mitigating the burden of processing redundant features. These findings suggest that DST offers a promising avenue for developing more efficient and adaptable Transformer-based NLP models.",ai
"Weight-only quantization is widely used to mitigate the memory-bound nature of LLM inference. Codebook-based methods extend this trend by achieving strong accuracy in the extremely low-bit regime (e.g., 2-bit). However, current kernels rely on dequantization, which repeatedly fetches centroids and reconstructs weights, incurring substantial latency and cache pressure. We present CodeGEMM, a codebook-centric GEMM kernel that replaces dequantization with precomputed inner products between centroids and activations stored in a lightweight Psumbook. At inference, code indices directly gather these partial sums, eliminating per-element lookups and reducing the on-chip footprint. The kernel supports the systematic exploration of latency-memory-accuracy trade-offs under a unified implementation. On Llama-3 models, CodeGEMM delivers 1.83x (8B) and 8.93x (70B) speedups in the 2-bit configuration compared to state-of-the-art codebook-based quantization at comparable accuracy and further improves computing efficiency and memory subsystem utilization.",human
"Diffusion models have shown remarkable capacity in image synthesis based on their U-shaped architecture and convolutional neural networks (CNN) as basic blocks. The locality of the convolution operation in CNN may limit the model's ability to understand long-range semantic information. To address this issue, we propose Yuan-TecSwin, a text-conditioned diffusion model with Swin-transformer in this work. The Swin-transformer blocks take the place of CNN blocks in the encoder and decoder, to improve the non-local modeling ability in feature extraction and image restoration. The text-image alignment is improved with a well-chosen text encoder, effective utilization of text embedding, and careful design in the incorporation of text condition. Using an adapted time step to search in different diffusion stages, inference performance is further improved by 10%. Yuan-TecSwin achieves the state-of-the-art FID score of 1.37 on ImageNet generation benchmark, without any additional models at different denoising stages. In a side-by-side comparison, we find it difficult for human interviewees to tell the model-generated images from the human-painted ones.",human
"Retrieving code units (e.g., files, classes, functions) that are semantically relevant to a given user query, bug report, or feature request from large codebases is a fundamental challenge for LLM-based coding agents. Agentic approaches typically employ sparse retrieval methods like BM25 or dense embedding strategies to identify relevant units. While embedding-based approaches can outperform BM25 by large margins, they often lack exploration of the codebase and underutilize its underlying graph structure. To address this, we propose SpIDER (Spatially Informed Dense Embedding Retrieval), an enhanced dense retrieval approach that incorporates LLM-based reasoning over auxiliary context obtained through graph-based exploration of the codebase. Empirical results show that SpIDER consistently improves dense retrieval performance across several programming languages.",human
"Neural operators offer powerful approaches for solving parametric partial differential equations, but extending them to spherical domains remains challenging due to the need to preserve intrinsic geometry while avoiding distortions that break rotational consistency. Existing spherical operators rely on rotational equivariance but often lack the flexibility for real-world complexity. We propose a general operator-design framework based on the designable spherical Green's function and its harmonic expansion, establishing a solid operator-theoretic foundation for spherical learning. Based on this, we propose an absolute and relative position-dependent Green's function that enables flexible balance of equivariance and invariance for real-world modeling. The resulting operator, Green's-function Spherical Neural Operator (GSNO) with a novel spectral learning method, can adapt to anisotropic, constraint-rich systems while retaining spectral efficiency. To exploit GSNO, we develop GSHNet, a hierarchical architecture that combines multi-scale spectral modeling with spherical up-down sampling, enhancing global feature representation. Evaluations on diffusion MRI, shallow water dynamics, and global weather forecasting, GSNO and GSHNet consistently outperform state-of-the-art methods. Our results position GSNO as a principled and general framework for spherical operator learning, bridging rigorous theory with real-world complexity.",human
"We address the challenge of efficiently representing and reasoning with complex, structured knowledge in machine learning models. Existing knowledge representation techniques often struggle with scalability, expressiveness, and the ability to handle noisy or incomplete information. We propose a novel approach, the Hierarchical Attributed Knowledge Graph Embedding (HAKGE), which integrates hierarchical type information directly into the learning of entity and relation embeddings within a knowledge graph. HAKGE utilizes a type-aware attention mechanism to dynamically modulate the influence of neighboring entities based on their hierarchical relationship to the target entity. This allows the model to prioritize relevant knowledge during reasoning tasks while mitigating the impact of spurious connections. We evaluate HAKGE on benchmark knowledge graph completion datasets, specifically WN18RR and FB15k-237, and demonstrate significant improvements in Mean Reciprocal Rank (MRR) and Hits@K metrics compared to state-of-the-art embedding models. Furthermore, we show that HAKGE exhibits enhanced robustness to noisy knowledge by demonstrating a smaller performance degradation when evaluated on corrupted knowledge graphs. The results suggest that incorporating hierarchical type information into knowledge graph embeddings offers a promising avenue for improving the accuracy, efficiency, and robustness of knowledge representation and reasoning in machine learning systems.",ai
"We address the challenge of sample-efficient reinforcement learning in continuous control environments with sparse rewards. Traditional reinforcement learning algorithms often struggle in such scenarios due to the difficulty of exploration and the instability of value function approximation. We propose a novel approach, Variational Intrinsic Option Discovery (VIOD), that combines variational inference with option discovery to learn reusable skills and guide exploration. VIOD leverages a variational autoencoder to learn a latent space of options, allowing the agent to generate diverse and goal-directed behaviors. An intrinsic reward signal, based on the novelty of the generated options, encourages exploration of unexplored regions of the state space. We demonstrate the efficacy of VIOD in several benchmark continuous control tasks with sparse rewards, including MuJoCo environments. Empirical results indicate that VIOD significantly outperforms state-of-the-art reinforcement learning algorithms, achieving higher asymptotic performance and faster learning rates. Furthermore, we analyze the learned option space and demonstrate that VIOD discovers meaningful and diverse behaviors that facilitate efficient exploration and learning. These findings highlight the potential of variational option discovery as a powerful tool for sample-efficient reinforcement learning in challenging environments.",ai
"We present ShoppingComp, a challenging real-world benchmark for rigorously evaluating LLM-powered shopping agents on three core capabilities: precise product retrieval, expert-level report generation, and safety critical decision making. Unlike prior e-commerce benchmarks, ShoppingComp introduces highly complex tasks under the principle of guaranteeing real products and ensuring easy verifiability, adding a novel evaluation dimension for identifying product safety hazards alongside recommendation accuracy and report quality. The benchmark comprises 120 tasks and 1,026 scenarios, curated by 35 experts to reflect authentic shopping needs. Results reveal stark limitations of current LLMs: even state-of-the-art models achieve low performance (e.g., 11.22% for GPT-5, 3.92% for Gemini-2.5-Flash). These findings highlight a substantial gap between research benchmarks and real-world deployment, where LLMs make critical errors such as failure to identify unsafe product usage or falling for promotional misinformation, leading to harmful recommendations. ShoppingComp fills the gap and thus establishes a new standard for advancing reliable and practical agents in e-commerce.",human
"The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from speech. Our contributions are threefold. First, we introduce SpidR, a self-supervised speech representation model that efficiently learns representations with highly accessible phonetic information, which makes it particularly suited for textless spoken language modeling. It is trained on raw waveforms using a masked prediction objective combined with self-distillation and online clustering. The intermediate layers of the student model learn to predict assignments derived from the teacher's intermediate layers. This learning objective stabilizes the online clustering procedure compared to previous approaches, resulting in higher quality codebooks. SpidR outperforms wav2vec 2.0, HuBERT, WavLM, and DinoSR on downstream language modeling benchmarks (sWUGGY, sBLIMP, tSC). Second, we systematically evaluate across models and layers the correlation between speech unit quality (ABX, PNMI) and language modeling performance, validating these metrics as reliable proxies. Finally, SpidR significantly reduces pretraining time compared to HuBERT, requiring only one day of pretraining on 16 GPUs, instead of a week. This speedup is enabled by the pretraining method and an efficient codebase, which allows faster iteration and easier experimentation. We open-source the training code and model checkpoints at https://github.com/facebookresearch/spidr.",human
"### Abstract Accurate and efficient segmentation of anatomical structures in medical images is crucial for diagnosis, treatment planning, and surgical navigation. Manual segmentation is time-consuming and subject to inter-observer variability. This work addresses the problem of automated segmentation of lung nodules in computed tomography (CT) scans, a critical task for early lung cancer detection. We propose a novel deep learning framework based on a 3D Convolutional Neural Network (CNN) incorporating attention mechanisms and multi-scale feature fusion. Specifically, we employ a U-Net architecture with residual connections to capture both local and global contextual information. Attention modules are integrated at various stages to emphasize salient nodule features and suppress irrelevant background noise. Furthermore, features from different convolutional layers are fused using a dense concatenation approach to leverage multi-scale information. The proposed method was evaluated on the publicly available LIDC-IDRI dataset. Experimental results demonstrate that our approach achieves state-of-the-art performance in lung nodule segmentation, surpassing existing methods in terms of Dice coefficient (0.82), Jaccard index (0.70), and sensitivity (0.85). The reduced inference time compared to other deep learning models validates the efficiency of the architecture. These results highlight the potential of the proposed framework for assisting radiologists in accurate and timely detection of lung cancer.",ai
"Multimodal classifiers function as opaque black box models. While several techniques exist to interpret their predictions, very few of them are as intuitive and accessible as natural language explanations (NLEs). To build trust, such explanations must faithfully capture the classifier's internal decision making behavior, a property known as faithfulness. In this paper, we propose CAuSE (Causal Abstraction under Simulated Explanations), a novel framework to generate faithful NLEs for any pretrained multimodal classifier. We demonstrate that CAuSE generalizes across datasets and models through extensive empirical evaluations. Theoretically, we show that CAuSE, trained via interchange intervention, forms a causal abstraction of the underlying classifier. We further validate this through a redesigned metric for measuring causal faithfulness in multimodal settings. CAuSE surpasses other methods on this metric, with qualitative analysis reinforcing its advantages. We perform detailed error analysis to pinpoint the failure cases of CAuSE. For replicability, we make the codes available at https://github.com/newcodevelop/CAuSE",human
"We address the challenge of effectively representing relational knowledge for improved reasoning and generalization in complex, multi-entity environments. Current approaches, such as graph neural networks, often struggle with long-range dependencies and the explicit encoding of logical constraints, leading to suboptimal performance in tasks requiring intricate inference. To overcome these limitations, we propose a novel knowledge representation framework that combines differentiable inductive logic programming with graph embedding techniques. Our method, termed Neuro-Symbolic Relation Embeddings (NSRE), learns embeddings of entities and relations while simultaneously grounding logical rules that capture domain-specific knowledge. The logical rules are incorporated as constraints during the embedding learning process, guiding the model towards representations that are consistent with the underlying relational structure. We evaluate NSRE on several benchmark datasets involving knowledge graph completion and reasoning tasks. Our experimental results demonstrate that NSRE significantly outperforms state-of-the-art methods, achieving substantial improvements in accuracy and generalization ability, particularly in scenarios with limited training data and the need for reasoning across multiple relational hops. The learned representations are also more interpretable, enabling a deeper understanding of the model's decision-making process.",ai
"### Abstract The accurate and efficient analysis of medical images is critical for timely diagnosis and treatment planning. However, manual interpretation by radiologists is often time-consuming, subjective, and prone to inter-observer variability. This work addresses the challenge of automatically detecting and segmenting pathological structures in medical images, specifically focusing on pulmonary nodules in computed tomography (CT) scans. We propose a novel multi-stage convolutional neural network (CNN) architecture that leverages both global contextual information and fine-grained local features. The architecture consists of an initial detection network trained to identify regions of interest (ROIs) likely to contain nodules, followed by a segmentation network that refines the bounding box predictions and delineates the precise nodule boundaries. A key innovation is the incorporation of attention mechanisms within the segmentation network to selectively weight informative features, thereby improving robustness to variations in nodule size, shape, and density. Experimental results on the LIDC-IDRI dataset demonstrate that our approach achieves state-of-the-art performance in nodule detection, with a competitive free-response operating characteristic (FROC) score of 0.88 at 8 false positives per scan. Furthermore, the segmentation network achieves a Dice score of 0.79, indicating high accuracy in delineating nodule boundaries. These results suggest that the proposed method offers a promising solution for automated pulmonary nodule analysis and has the potential to assist radiologists in clinical practice.",ai
"We present a novel methodology for automated detection and segmentation of pulmonary nodules in computed tomography (CT) scans, addressing the critical challenge of early lung cancer diagnosis. Existing approaches often suffer from high false positive rates and limited accuracy in handling nodules with varying sizes, shapes, and densities. Our method leverages a three-dimensional convolutional neural network (3D-CNN) architecture, specifically designed to capture contextual information within the volumetric CT data. This network incorporates a multi-scale feature fusion module, enabling the effective integration of features extracted at different resolutions to improve the robustness of nodule detection and segmentation. Furthermore, we introduce a novel loss function that combines Dice loss with a shape-aware penalty term, encouraging the generation of more accurate and anatomically plausible segmentations. Evaluation on the LIDC-IDRI dataset demonstrates that our approach achieves state-of-the-art performance, with a competitive free-response receiver operating characteristic (FROC) score of 0.88 at 8 false positives per scan, and a mean Dice coefficient of 0.79 for nodule segmentation. These results indicate the potential of our method to significantly enhance the accuracy and efficiency of computer-aided diagnosis in pulmonary medicine.",ai
"Speech Emotion Recognition (SER) systems often degrade in performance when exposed to the unpredictable acoustic interference found in real-world environments. Additionally, the opacity of deep learning models hinders their adoption in trust-sensitive applications. To bridge this gap, we propose a Hybrid Transformer-CNN framework that unifies the contextual modeling of Wav2Vec 2.0 with the spectral stability of 1D-Convolutional Neural Networks. Our dual-stream architecture processes raw waveforms to capture long-range temporal dependencies while simultaneously extracting noise-resistant spectral features (MFCC, ZCR, RMSE) via a custom Attentive Temporal Pooling mechanism. We conducted extensive validation across four diverse benchmark datasets: RAVDESS, TESS, SAVEE, and CREMA-D. To rigorously test robustness, we subjected the model to non-stationary acoustic interference using real-world noise profiles from the SAS-KIIT dataset. The proposed framework demonstrates superior generalization and state-of-the-art accuracy across all datasets, significantly outperforming single-branch baselines under realistic environmental interference. Furthermore, we address the ``black-box"" problem by integrating SHAP and Score-CAM into the evaluation pipeline. These tools provide granular visual explanations, revealing how the model strategically shifts attention between temporal and spectral cues to maintain reliability in the presence of complex environmental noise.",human
"We address the challenge of constructing robust and interpretable knowledge representations from high-dimensional, noisy observational data. Existing methods often struggle with capturing complex inter-variable dependencies and mitigating the impact of spurious correlations, leading to representations that are either overly simplistic or prone to overfitting. We propose a novel approach based on probabilistic graphical models integrated with a sparse regularized optimization framework. Our method, termed Sparse Latent Dependency Network (SLDN), simultaneously infers the structure of a latent variable model and estimates the parameters governing the dependencies between observed and latent variables. SLDN utilizes a variational inference scheme for efficient posterior approximation and incorporates an L1-penalty on the dependency parameters to promote sparsity and enhance interpretability. We evaluate SLDN on synthetic datasets with controlled ground truth and real-world datasets in the domains of genomics and finance. Empirical results demonstrate that SLDN effectively identifies relevant dependencies, outperforms competing methods in terms of structure recovery and prediction accuracy, and provides a more parsimonious representation of the underlying knowledge domain, leading to improved understanding of the relationships between variables.",ai
"Diffusion language models (DLMs) have recently emerged as a compelling alternative to autoregressive generation, offering parallel generation and improved global coherence. During inference, DLMs generate text by iteratively denoising masked sequences in parallel; however, determining which positions to unmask and which tokens to commit forms a large combinatorial search problem. Existing inference methods approximate this search using heuristics, which often yield suboptimal decoding paths; other approaches instead rely on additional training to guide token selection. To introduce a principled search mechanism for DLMs inference, we introduce MEDAL, a framework that integrates Monte Carlo Tree SEarch initialization for Diffusion LAnguage Model inference. We employ Monte Carlo Tree Search at the initialization stage to explore promising unmasking trajectories, providing a robust starting point for subsequent refinement. This integration is enabled by restricting the search space to high-confidence actions and prioritizing token choices that improve model confidence over remaining masked positions. Across multiple benchmarks, MEDAL achieves up to 22.0% improvement over existing inference strategies, establishing a new paradigm for search-based inference in diffusion language models.",human
"Leveraging a dataset of paired narratives, we investigate the extent to which large language models (LLMs) can reliably separate incoherent and coherent stories. A probing study finds that LLMs' internal representations can reliably identify incoherent narratives. However, LLMs generate responses to rating questions that fail to satisfactorily separate the coherent and incoherent narratives across several prompt variations, hinting at a gap in LLM's understanding of storytelling. The reasoning LLMs tested do not eliminate these deficits, indicating that thought strings may not be able to fully address the discrepancy between model internal state and behavior. Additionally, we find that LLMs appear to be more sensitive to incoherence resulting from an event that violates the setting (e.g., a rainy day in the desert) than to incoherence arising from a character violating an established trait (e.g., Mary, a vegetarian, later orders a cheeseburger), suggesting that LLMs may rely more on prototypical world knowledge than building meaning-based narrative coherence. The consistent asymmetry found in our results suggests that LLMs do not have a complete grasp on narrative coherence.",human
"Graph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.",human
"We address the problem of sample inefficiency in model-free reinforcement learning, particularly in continuous control tasks with sparse rewards. Traditional methods often require extensive environment interactions to achieve satisfactory performance, limiting their applicability in real-world scenarios. We propose a novel approach, dubbed ""Adaptive Reward Shaping via Intrinsic Curiosity Modulation"" (ARS-ICM), which dynamically adjusts the reward landscape based on an agent's intrinsic curiosity and exploration progress. ARS-ICM integrates an intrinsic reward signal derived from prediction error within a forward dynamics model, scaled by a learned modulation function. This modulation function adaptively weights the intrinsic reward to prioritize exploration in initially unknown regions while gradually reducing its influence as the agent gains experience, thereby preventing premature convergence to suboptimal solutions. Empirical evaluation on a suite of challenging MuJoCo locomotion tasks demonstrates that ARS-ICM significantly outperforms state-of-the-art algorithms, including PPO and SAC, in terms of sample efficiency and asymptotic performance. Specifically, we observe a reduction in the number of environment interactions required to achieve a target performance level by a factor of 2 to 5 across various benchmark environments. Furthermore, ablation studies validate the effectiveness of both the intrinsic curiosity signal and the adaptive modulation function in contributing to the overall performance gains.",ai
"This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation behavior of ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN). While all models perform well on spatially split, conventional test sets, their performance degrades substantially on temporally independent validation years, revealing persistent limitations in generalization. Notably, models with strong test-set accuracy, but weak temporal validation performance can still produce seemingly credible SHAP feature importance values. This exposes a critical vulnerability in post hoc explainability methods: interpretability may appear reliable even when the underlying model fails to generalize. These findings underscore the need for validation-aware interpretation of ML predictions in agricultural and environmental systems. Feature importance should not be accepted at face value unless models are explicitly shown to generalize to unseen temporal and spatial conditions. The study advocates for domain-aware validation, hybrid modeling strategies, and more rigorous scrutiny of explainability methods in data-driven agriculture. Ultimately, this work addresses a growing challenge in environmental data science: how can we evaluate generalization robustly enough to trust model explanations?",human
"Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradient-based membership inference attack for federated learning scenarios that exploits the temporal evolution of last-layer gradients across multiple federated rounds. Our method uses the shadow technique to learn round-wise gradient patterns of the training records, requiring no access to the private dataset, and is designed to consider both semi-honest and malicious adversaries (aggregators or data owners). Beyond membership inference, we also provide a natural extension of the proposed attack to discrete attribute inference by contrasting gradient responses under alternative attribute hypotheses. The proposed attacks are model-agnostic, and therefore applicable to any gradient-based model and can be applied to both classification and regression settings. We evaluate the attack on CIFAR-100 and Purchase100 datasets for membership inference and on Breast Cancer Wisconsin for attribute inference. Our findings reveal strong attack performance and comparable computational and memory overhead in membership inference when compared to another attack from the literature. The obtained results emphasize that multi-round federated learning can increase the vulnerability to inference attacks, that aggregators pose a more substantial threat than data owners, and that attack performance is strongly influenced by the nature of the training dataset, with richer, high-dimensional data leading to stronger leakage than simpler tabular data.",human
"We address the problem of efficiently representing and reasoning with commonsense knowledge in large-scale natural language processing systems. Current knowledge representation techniques often struggle to capture the nuances and contextual dependencies inherent in human understanding, leading to brittle and limited performance in tasks requiring sophisticated reasoning. We propose a novel approach, Contextualized Knowledge Graph Embeddings (CKGE), which integrates knowledge graph completion with contextualized language models. CKGE leverages pre-trained language models to generate dynamic entity and relation embeddings conditioned on the surrounding textual context. These embeddings are then incorporated into a graph neural network architecture to refine knowledge graph representations, enabling more accurate prediction of missing relationships and improved reasoning capabilities. Experiments conducted on benchmark knowledge graph completion datasets, including WN18RR and FB15k-237, demonstrate that CKGE outperforms existing state-of-the-art methods, achieving significant improvements in Mean Reciprocal Rank (MRR) and Hits@K metrics. Further evaluation on a commonsense reasoning task, specifically the CommonsenseQA dataset, shows that CKGE-enhanced knowledge-aware models exhibit a substantial increase in accuracy compared to baseline models relying solely on pre-trained language model representations. The results highlight the effectiveness of contextualized knowledge graph embeddings in bridging the gap between symbolic and sub-symbolic knowledge representation for enhanced commonsense reasoning.",ai
"We investigate the challenge of automating complex logical reasoning within structured knowledge graphs, focusing on multi-hop relation prediction. While current neural methods excel at pattern recognition in local neighborhoods, they often struggle with long-range dependencies and compositional reasoning required for paths exceeding a few hops. To address this limitation, we propose a novel framework, Neural Logic Programming with Self-Supervised Path Augmentation (NLPSA). NLPSA leverages neural logic programming to explicitly represent and manipulate logical rules derived from the knowledge graph structure. Critically, we introduce a self-supervised path augmentation strategy that generates synthetic, yet structurally consistent, paths to expand the training data. These augmented paths encourage the model to learn transferable reasoning patterns applicable beyond the observed data. Empirical evaluation on benchmark datasets, including FB15k-237 and WN18RR, demonstrates that NLPSA significantly outperforms state-of-the-art graph neural networks and existing neural logic programming approaches. Specifically, NLPSA achieves relative improvements of up to 15% in mean reciprocal rank (MRR) and Hits@1, indicating enhanced accuracy and efficiency in inferring logical relationships within complex knowledge graphs. The results suggest that combining explicit logical reasoning with self-supervised augmentation provides a powerful approach for automating complex inference tasks.",ai
"We address the problem of learning robust and transferable knowledge representations from limited and noisy observational data. Existing methods often struggle to generalize across diverse environments due to overfitting to spurious correlations and lack of explicit causal reasoning. We propose a novel framework, termed ""Environmentally Disentangled and Causal Knowledge Graph Embedding"" (EDCKGE), that leverages graph neural networks and environment-specific interventions to learn disentangled and causal representations. EDCKGE constructs a knowledge graph from observed data, encoding entities and relations. Crucially, it incorporates environment-specific intervention nodes that modulate the influence of different relations. During training, we apply simulated interventions to these environment nodes, forcing the model to learn representations that are invariant to irrelevant environmental variations and sensitive to causal mechanisms. This disentanglement is achieved through a regularized information bottleneck applied to the learned node embeddings. Empirical evaluations on synthetic and real-world knowledge graph completion and relation prediction tasks demonstrate that EDCKGE significantly outperforms existing methods, especially in low-data regimes and under distribution shift. Further analysis reveals that EDCKGE learns more interpretable and robust representations, facilitating improved generalization and counterfactual reasoning.",ai
"We introduce Image-LoRA, a lightweight parameter efficient fine-tuning (PEFT) recipe for transformer-based vision-language models (VLMs). Image-LoRA applies low-rank adaptation only to the value path of attention layers within the visual-token span, reducing adapter-only training FLOPs roughly in proportion to the visual-token fraction. We further adapt only a subset of attention heads, selected using head influence scores estimated with a rank-1 Image-LoRA, and stabilize per-layer updates via selection-size normalization. Across screen-centric grounding and referring benchmarks spanning text-heavy to image-heavy regimes, Image-LoRA matches or closely approaches standard LoRA accuracy while using fewer trainable parameters and lower adapter-only training FLOPs. The method also preserves the pure-text reasoning performance of VLMs before and after fine-tuning, as further shown on GSM8K.",human
"## Estimating Causal Effects in the Presence of Latent Confounding and Measurement Error Estimating causal effects from observational data remains a significant challenge, particularly when both latent confounding and measurement error are present. These issues, individually, can bias causal estimates, and their combined impact is often exacerbated. We address this problem by proposing a novel instrumental variable (IV) method, leveraging a moment-based approach to identify and estimate causal effects in linear non-Gaussian models. Our method, termed Latent and Error-robust IV Estimator (LERIE), utilizes higher-order moments to disentangle the effects of latent confounders and measurement error on both the instrument and the treatment variable. Specifically, LERIE exploits the non-Gaussianity of observed variables to construct valid IVs that are uncorrelated with the latent confounders and measurement error after appropriate correction. We provide theoretical guarantees for the identifiability of the causal effect under mild conditions on the distribution of the latent variables. Through extensive simulations, we demonstrate that LERIE outperforms existing IV methods that ignore either latent confounding or measurement error, exhibiting substantially reduced bias and improved accuracy in estimating the true causal effect. Furthermore, we showcase the applicability of LERIE on a real-world dataset concerning the causal effect of education on income, demonstrating its robustness in scenarios with complex data generating processes.",ai
"We discuss conditionalisation for Accept-Desirability models in an abstract decision-making framework, where uncertain rewards live in a general linear space, and events are special projection operators on that linear space. This abstract setting allows us to unify classical and quantum probabilities, and extend them to an imprecise probabilities context. We introduce a new conditioning rule for our Accept-Desirability models, based on the idea that observing an event introduces new indifferences between options. We associate a belief revision operator with our conditioning rule, and investigate which of the AGM axioms for belief revision still hold in our more general framework. We investigate two interesting special cases where all of these axioms are shown to still hold: classical propositional logic and full conditional probabilities.",human
"Inverse problems are extensively studied in applied mathematics, with applications ranging from acoustic tomography for medical diagnosis to geophysical exploration. Physics informed neural networks (PINNs) have emerged as a powerful tool for solving such problems, while Physics informed Kolmogorov Arnold networks (PIKANs) represent a recent benchmark that, in certain problems, promises greater interpretability and accuracy compared to PINNs, due to their nature, being constructed as a composition of polynomials. In this work, we develop a methodology for addressing inverse problems in infinite and semi infinite domains. We introduce a novel sampling strategy for the network's training points, using the negative exponential and normal distributions, alongside a dual network architecture that is trained to learn the solution and parameters of an equation with the same loss function. This design enables the solution of inverse problems without explicitly imposing boundary conditions, as long as the solutions tend to stabilize when leaving the domain of interest. The proposed architecture is implemented using both PINNs and PIKANs, and their performance is compared in terms of accuracy with respect to a known solution as well as computational time and response to a noisy environment. Our results demonstrate that, in this setting, PINNs provide a more accurate and computationally efficient solution, solving the inverse problem 1,000 times faster and in the same order of magnitude, yet with a lower relative error than PIKANs.",human
"We address the problem of sample inefficiency in reinforcement learning (RL) when applied to sparse-reward, high-dimensional environments. Traditional RL algorithms often struggle to learn effectively in such settings due to the infrequent occurrence of informative feedback signals. This work introduces a novel approach, *Hierarchical Reinforcement Learning with Intrinsic Curiosity Module (HRL-ICM)*, designed to mitigate these challenges. Our method decomposes the learning problem into a hierarchy of temporal abstractions. A high-level manager learns to set abstract goals for a low-level worker, which then strives to achieve these goals. The worker's learning is guided by an Intrinsic Curiosity Module (ICM) that incentivizes exploration of novel states, effectively shaping the reward landscape and accelerating learning. Crucially, the manager is trained using both extrinsic rewards (from the environment) and intrinsic rewards derived from the worker's exploration. We evaluate HRL-ICM on a suite of challenging benchmark tasks characterized by sparse rewards and high-dimensional state spaces. Empirical results demonstrate that HRL-ICM significantly outperforms several state-of-the-art RL algorithms, including A2C, PPO, and SAC, in terms of sample efficiency, convergence speed, and final performance. Furthermore, ablation studies highlight the contribution of each component of our proposed architecture, validating the efficacy of the hierarchical decomposition and the ICM-based exploration strategy. The findings suggest that HRL-ICM provides a promising avenue for addressing the sample inefficiency bottleneck in RL, particularly in complex and scarcely rewarded environments.",ai
"Natural Language Processing (NLP) is one of the most revolutionary technologies today. It uses artificial intelligence to understand human text and spoken words. It is used for text summarization, grammar checking, sentiment analysis, and advanced chatbots and has many more potential use cases. Furthermore, it has also made its mark on the education sector. Much research and advancements have already been conducted on objective question generation; however, automated subjective question generation and answer evaluation are still in progress. An automated system to generate subjective questions and evaluate the answers can help teachers assess student work and enhance the student's learning experience by allowing them to self-assess their understanding after reading an article or a chapter of a book. This research aims to improve current NLP models or make a novel one for automated subjective question generation and answer evaluation from text input.",human
"The current era of AI development places a heavy emphasis on training large models on increasingly scaled-up datasets. This paradigm has catalyzed entirely new product categories, such as LLM chatbots, while also raising concerns about data privacy and consumer choice. In this paper, we consider questions of data portability and user autonomy in the context of LLMs that ""reason"" using chain-of-thought (CoT) traces, computing intermediate text artifacts from user input before producing a final output. We first interpret recent data privacy and portability law to argue that these intermediate computations qualify as users' personal data. Then, building on the existing framework of Conscious Data Contribution, we show how communities who receive low utility from an available model can aggregate and distill their shared knowledge into an alternate model better aligned with their goals. We verify this approach empirically and investigate the effects of community diversity, reasoning granularity, and community size on distillation performance.",human
"Model merging combines multiple fine-tuned checkpoints into a single model without additional training, offering an attractive approach to reusing models and efficiently improving performance. However, it remains unclear whether the advantages reported for smaller models and classifiers generalize to LLMs. We present a large-scale, systematic evaluation of six state-of-the-art merging methods, including recent subspace methods, across four open-weight LLMs, twelve fine-tuned checkpoints per base model, and sixteen standard LLM benchmarks. Evaluating through standardized benchmarks, we measure both the probability that a merged model outperforms the base model and relative gains over the best individual checkpoint. Our results show that the oldest and simplest method, Task Arithmetic, is the only approach that reliably yields performance gains on LLMs. Other interference-aware and subspace merging methods typically result in significant performance drops. Our findings indicate that current merging techniques do not directly transfer to modern LLMs. This motivates the design of LLM-specific merging algorithms and merging-aware fine-tuning methods. Code will be released upon acceptance of this paper.",human
"We investigate the problem of decentralized task allocation in multi-agent systems operating under communication constraints and stochastic environments. Specifically, we address the challenge of efficiently assigning agents to tasks when agents have limited knowledge of the global state and face uncertainties in task execution. We propose a novel distributed reinforcement learning algorithm, termed Communication-Efficient Decentralized Task Allocation (CEDTA), which integrates a graph neural network (GNN) architecture for local information aggregation and a policy gradient method for decentralized decision-making. The GNN enables agents to learn to selectively communicate relevant information with their neighbors, mitigating the impact of communication bottlenecks. Furthermore, CEDTA incorporates a robust reward shaping mechanism that incentivizes efficient task completion and collaboration despite environmental stochasticity. We evaluate CEDTA in simulated environments with varying numbers of agents, tasks, and communication ranges. Empirical results demonstrate that CEDTA significantly outperforms existing decentralized task allocation algorithms, including those based on auction mechanisms and traditional reinforcement learning, in terms of task completion rate, total reward, and communication overhead. The proposed method exhibits superior scalability and adaptability to dynamic environments, suggesting its potential applicability in real-world multi-agent coordination scenarios.",ai
"We investigate a novel approach to robust optimization for machine learning models trained on datasets susceptible to adversarial perturbations. Traditional robust optimization techniques often suffer from scalability issues and can lead to overly conservative solutions, sacrificing performance on clean data. Our work addresses these limitations by introducing a stochastic approximation method based on a modified Frank-Wolfe algorithm. This method iteratively refines the model parameters by approximating the worst-case perturbation within a budget constraint using a stochastic gradient estimator. We leverage a momentum-based gradient estimator to reduce variance and accelerate convergence. Furthermore, we propose a dynamic budget adjustment strategy that adaptively controls the robustness trade-off during training, allowing the model to balance performance on both clean and adversarially perturbed data. We empirically evaluate our approach on image classification tasks using the CIFAR-10 and MNIST datasets, demonstrating significant improvements in robust accuracy compared to state-of-the-art robust optimization algorithms, while maintaining competitive clean accuracy. Specifically, our method achieves a 5-10% increase in robust accuracy against strong adversarial attacks (e.g., PGD attack) compared to standard adversarial training, with minimal impact on clean accuracy. The proposed algorithm demonstrates improved scalability and efficiency, making it a viable option for training robust machine learning models on large-scale datasets.",ai
"We investigate the problem of efficient exploration in sparse-reward reinforcement learning environments with high-dimensional continuous state spaces. Traditional methods often struggle due to the difficulty of discovering rewarding states through random exploration. To address this challenge, we propose a novel intrinsic motivation framework incorporating a variational autoencoder (VAE) to learn a compressed latent representation of the state space, coupled with a curiosity-driven reward signal based on prediction error within this latent space. Specifically, the VAE provides a low-dimensional embedding that focuses on salient features of the environment, filtering out irrelevant noise and facilitating more effective generalization. The prediction error, quantified as the difference between the predicted next latent state and the actual next latent state, serves as an intrinsic reward, encouraging the agent to explore regions of the state space where its model is uncertain. We evaluate our method on a suite of challenging continuous control tasks characterized by sparse rewards. Experimental results demonstrate that our approach significantly outperforms several state-of-the-art exploration methods, including random exploration, count-based exploration, and other intrinsic motivation techniques. We observe a substantial improvement in sample efficiency and overall performance, indicating that the learned latent space effectively guides exploration towards promising regions and accelerates the learning process. Our findings suggest that integrating representation learning with curiosity-driven exploration is a promising direction for tackling sparse-reward reinforcement learning in complex environments.",ai
"Transformer models have achieved state-of-the-art performance across a diverse range of natural language processing (NLP) tasks. However, the computational expense associated with training and deploying these models, particularly on long sequences, remains a significant impediment to their broader adoption. This work investigates methods for improving the efficiency of transformer models without sacrificing accuracy. We introduce a novel attention mechanism, termed â€œSparse Sinkhorn Attentionâ€ (SSA), which combines the strengths of sparse attention with the global optimality properties of Sinkhorn normalization. SSA restricts attention to a learned, sparse subset of the input sequence while leveraging Sinkhorn iterations to encourage more uniform attention distributions across this subset, mitigating the representational bottleneck introduced by sparsity. We empirically evaluate SSA on a suite of benchmark NLP tasks, including machine translation and text summarization. Results demonstrate that SSA achieves comparable or superior performance to full attention transformers and other sparse attention variants, while exhibiting a significant reduction in computational complexity, particularly on long sequences. Specifically, we observe a 2-4x speedup in training time and a reduction in memory footprint of up to 30% compared to the standard attention mechanism, with minimal impact on model accuracy. These findings suggest that SSA offers a promising approach for scaling transformer models to longer sequences and resource-constrained environments.",ai
"We address the problem of sample inefficiency in reinforcement learning, particularly in environments with sparse rewards and long horizons. Traditional reinforcement learning algorithms often struggle to effectively explore such environments, leading to slow learning or convergence to suboptimal policies. We introduce a novel method, Hierarchical Imitation with Reward Shaping (HIRS), which leverages demonstrations from a sub-optimal teacher policy to guide exploration and accelerate learning. HIRS employs a hierarchical structure, decomposing the task into high-level goals and low-level actions. The high-level policy learns to imitate the teacher's goal selection, while the low-level policy learns to achieve the selected goals using reinforcement learning. To further improve sample efficiency, we introduce a reward shaping mechanism based on the teacher's policy, providing intrinsic rewards that encourage the agent to explore regions of the state space visited by the teacher. We evaluate HIRS in several challenging benchmark environments characterized by sparse rewards and long horizons, including a navigation task and a manipulation task. Our results demonstrate that HIRS significantly outperforms state-of-the-art reinforcement learning algorithms, achieving higher rewards with fewer samples. Ablation studies confirm the effectiveness of both the hierarchical imitation and reward shaping components of HIRS. These findings suggest that leveraging sub-optimal demonstrations can be a powerful tool for improving sample efficiency in reinforcement learning.",ai
"We generalize the AIXI reinforcement learning agent to admit a wider class of utility functions. Assigning a utility to each possible interaction history forces us to confront the ambiguity that some hypotheses in the agent's belief distribution only predict a finite prefix of the history, which is sometimes interpreted as implying a chance of death equal to a quantity called the semimeasure loss. This death interpretation suggests one way to assign utilities to such history prefixes. We argue that it is as natural to view the belief distributions as imprecise probability distributions, with the semimeasure loss as total ignorance. This motivates us to consider the consequences of computing expected utilities with Choquet integrals from imprecise probability theory, including an investigation of their computability level. We recover the standard recursive value function as a special case. However, our most general expected utilities under the death interpretation cannot be characterized as such Choquet integrals.",human
"Open challenges have become the de facto standard for comparative ranking of medical AI methods. Despite their importance, medical AI leaderboards exhibit three persistent limitations: (1) score gaps are rarely tested for statistical significance, so rank stability is unknown; (2) single averaged metrics are applied to every organ, hiding clinically important boundary errors; (3) performance across intersecting demographics is seldom reported, masking fairness and equity gaps. We introduce RankInsight, an open-source toolkit that seeks to address these limitations. RankInsight (1) computes pair-wise significance maps that show the nnU-Net family outperforms Vision-Language and MONAI submissions with high statistical certainty; (2) recomputes leaderboards with organ-appropriate metrics, reversing the order of the top four models when Dice is replaced by NSD for tubular structures; and (3) audits intersectional fairness, revealing that more than half of the MONAI-based entries have the largest gender-race discrepancy on our proprietary Johns Hopkins Hospital dataset. The RankInsight toolkit is publicly released and can be directly applied to past, ongoing, and future challenges. It enables organizers and participants to publish rankings that are statistically sound, clinically meaningful, and demographically fair.",human
"We investigate a novel approach to robust optimization problems under distributional uncertainty, specifically focusing on scenarios where the support of the uncertain parameters is unknown or partially known. Traditional robust optimization techniques often rely on a predefined uncertainty set, which can lead to overly conservative solutions if the true uncertainty is smaller or miss critical vulnerabilities if the uncertainty is underestimated. We propose a data-driven robust optimization framework that leverages kernel density estimation (KDE) to estimate the unknown distribution of the uncertain parameters from observed data. This KDE-based approach allows for the construction of a confidence region around the empirical support of the data, which is then used to formulate a distributionally robust optimization problem. We demonstrate that the resulting optimization problem can be reformulated as a tractable convex program under certain regularity conditions. Empirical results on benchmark portfolio optimization and engineering design problems show that our method significantly outperforms traditional box and ellipsoidal uncertainty sets, providing solutions with improved out-of-sample performance and robustness against distributional shifts, particularly when the underlying uncertainty distribution is non-symmetric or multi-modal. Moreover, we analyze the theoretical properties of the proposed estimator and provide finite-sample guarantees on the concentration of the estimated support, highlighting the robustness and reliability of our approach.",ai
"We address the problem of learning structured knowledge representations from unstructured data, specifically focusing on the task of relational concept emergence. Traditional methods often rely on predefined ontologies or symbolic representations, limiting their adaptability to novel domains and hindering their ability to capture nuanced relationships. We propose a novel framework, Neural Relational Concept Learner (NRCL), which leverages a neural network architecture to induce latent relational concepts directly from data. NRCL employs a variational autoencoder to encode input data into a latent space, coupled with a relational reasoning module that explicitly models interactions between latent representations. This module learns to predict relationships between entities, effectively grounding the latent space with relational semantics. We evaluate NRCL on synthetic and real-world datasets, demonstrating its ability to discover meaningful relational concepts and achieve superior performance compared to baseline methods in downstream tasks such as knowledge graph completion and relation prediction. Our results indicate that NRCL can effectively learn structured knowledge representations from unstructured data without relying on explicit symbolic supervision, opening avenues for automated knowledge discovery and reasoning.",ai
"We address the problem of efficiently solving quantified constraint satisfaction problems (QCSPs) with complex quantifier alternations, a task that remains computationally challenging despite significant advances in SAT and CSP solving. Existing QCSP solvers often struggle with instances exhibiting intricate dependencies between variables introduced by alternating quantifiers. Our approach introduces a novel hybrid reasoning framework that integrates strategic quantifier instantiation with conflict-driven clause learning (CDCL). Specifically, we employ a decision procedure that dynamically selects variables for instantiation based on the predicted impact on the search space, guided by a learned heuristic function derived from structural properties of the constraint network. Simultaneously, we adapt the CDCL framework to learn clauses not only from conflicts arising from quantifier-free constraint violations, but also from unsuccessful instantiation attempts, thereby encoding dependencies between quantified variables. We evaluate our solver on a benchmark suite of challenging QCSP instances derived from formal verification and planning domains. The results demonstrate a significant improvement in solution time and the ability to solve previously intractable instances compared to state-of-the-art QCSP solvers employing purely instantiation-based or purely CDCL-based strategies. Our hybrid framework achieves a substantial reduction in both the search space exploration and the number of required quantifier alternations, leading to a more efficient and scalable approach to QCSP solving.",ai
"We investigate the challenge of improving the sample efficiency of reinforcement learning (RL) agents operating in sparse-reward environments with deceptive local optima. Standard on-policy RL algorithms often struggle to escape such suboptimal regions, requiring extensive exploration and rendering them impractical for complex tasks. To address this, we propose a novel approach, *Exploration-Augmented Trajectory Optimization (EATO)*, which combines trajectory optimization techniques with an explicit exploration bonus derived from a learned intrinsic reward function. Specifically, EATO employs a model-based trajectory optimizer to plan sequences of actions, biased towards regions of high estimated uncertainty. The intrinsic reward is learned using a variational autoencoder (VAE) trained to reconstruct the state space, rewarding novelty based on reconstruction error. Furthermore, we incorporate a dynamic temperature scaling of the exploration bonus to facilitate a smooth transition from exploration to exploitation. We evaluate EATO on a suite of benchmark robotic navigation tasks featuring sparse rewards and challenging deceptive optima. Experimental results demonstrate that EATO significantly outperforms both standard on-policy RL algorithms (PPO) and alternative exploration strategies, achieving a 30-50% improvement in sample efficiency and exhibiting greater robustness to varying environment parameters. These findings suggest that EATO provides a promising avenue for developing more efficient and reliable RL agents for complex real-world applications.",ai
"Background: Large Language Models show promise in psychiatry but are English-centric. Their ability to understand mood states in other languages is unclear, as different languages have their own idioms of distress. Aim: To quantify the ability of language models to faithfully represent phrases (idioms of distress) of four distinct mood states (depression, euthymia, euphoric mania, dysphoric mania) expressed in Indian languages. Methods: We collected 247 unique phrases for the four mood states across 11 Indic languages. We tested seven experimental conditions, comparing k-means clustering performance on: (a) direct embeddings of native and Romanised scripts (using multilingual and Indic-specific models) and (b) embeddings of phrases translated to English and Chinese. Performance was measured using a composite score based on Adjusted Rand Index, Normalised Mutual Information, Homogeneity and Completeness. Results: Direct embedding of Indic languages failed to cluster mood states (Composite Score = 0.002). All translation-based approaches showed significant improvement. High performance was achieved using Gemini-translated English (Composite=0.60) and human-translated English (Composite=0.61) embedded with gemini-001. Surprisingly, human-translated English, further translated into Chinese and embedded with a Chinese model, performed best (Composite = 0.67). Specialised Indic models (IndicBERT and Sarvam-M) performed poorly. Conclusion: Current models cannot meaningfully represent mood states directly from Indic languages, posing a fundamental barrier to their psychiatric application for diagnostic or therapeutic purposes in India. While high-quality translation bridges this gap, reliance on proprietary models or complex translation pipelines is unsustainable. Models must first be built to understand diverse local languages to be effective in global mental health.",human
"Out of distribution (OOD) detection remains a critical challenge in malware classification due to the substantial intra family variability introduced by polymorphic and metamorphic malware variants. Most existing deep learning based malware detectors rely on closed world assumptions and fail to adequately model this intra class variation, resulting in degraded performance when confronted with previously unseen malware families. This paper presents MADOOD, a novel two stage, cluster driven deep learning framework for robust OOD malware detection and classification. In the first stage, malware family embeddings are modeled using class conditional spherical decision boundaries derived from Gaussian Discriminant Analysis (GDA), enabling statistically grounded separation of indistribution and OOD samples without requiring OOD data during training. Z score based distance analysis across multiple class centroids is employed to reliably identify anomalous samples in the latent space. In the second stage, a deep neural network integrates cluster based predictions, refined embeddings, and supervised classifier outputs to enhance final classification accuracy. Extensive evaluations on benchmark malware datasets comprising 25 known families and multiple novel OOD variants demonstrate that MADOOD significantly outperforms state of the art OOD detection methods, achieving an AUC of up to 0.911 on unseen malware families. The proposed framework provides a scalable, interpretable, and statistically principled solution for real world malware detection and anomaly identification in evolving cybersecurity environments.",human
"Generalist multimodal agents are expected to unify perception, language, and control - operating robustly across diverse real world domains. However, current evaluation practices remain fragmented across isolated benchmarks, making it difficult to assess whether today's foundation models truly generalize beyond their training distributions. We introduce MultiNet v1.0, a unified benchmark for measuring the cross domain generality of vision language models (VLMs) and vision language action models (VLAs) across six foundational capability regimes. Visual grounding, spatial reasoning, tool use, physical commonsense, multi agent coordination, and continuous robot control. Evaluating GPT 5, Pi0, and Magma, we find that no model demonstrates consistent generality. All exhibit substantial degradation on unseen domains, unfamiliar modalities, or cross domain task shifts despite strong performance within their training distributions.These failures manifest as modality misalignment, output format instability, and catastrophic knowledge degradation under domain transfer.Our findings reveal a persistent gap between the aspiration of generalist intelligence and the actual capabilities of current foundation models.MultiNet v1.0 provides a standardized evaluation substrate for diagnosing these gaps and guiding the development of future generalist agents.Code, data, and leaderboards are publicly available.",human
"We investigate the problem of coordinating decentralized agents with limited communication bandwidth in complex, partially observable environments. Traditional multi-agent reinforcement learning (MARL) approaches often struggle with scalability and communication bottlenecks when applied to scenarios with a large number of agents. To address these limitations, we propose a novel communication compression technique based on variational autoencoders (VAEs) coupled with a hierarchical reinforcement learning framework. The VAE learns a compact, latent representation of each agent's local observations and intentions, which is then communicated to a central coordinator. The coordinator leverages this compressed information to derive global action policies that incentivize emergent cooperation. Furthermore, the hierarchical structure allows for abstraction of individual agent actions, reducing the complexity of the joint action space. We empirically evaluate our approach in a cooperative navigation task and a resource allocation scenario. Results demonstrate that our method significantly outperforms existing MARL algorithms in terms of both task completion rate and communication efficiency. Specifically, our agent teams achieve comparable performance with 50% less communication overhead, highlighting the potential for deploying such systems in resource-constrained settings. We provide ablation studies to analyze the impact of each component of our proposed architecture.",ai
"We study distributed control of networked systems through reinforcement learning, where neural policies must be simultaneously scalable, expressive and stabilizing. We introduce a policy parameterization that embeds Graph Neural Networks (GNNs) into a Youla-like magnitude-direction parameterization, yielding distributed stochastic controllers that guarantee network-level closed-loop stability by design. The magnitude is implemented as a stable operator consisting of a GNN acting on disturbance feedback, while the direction is a GNN acting on local observations. We prove robustness of the closed loop to perturbations in both the graph topology and model parameters, and show how to integrate our parameterization with Proximal Policy Optimization. Experiments on a multi-agent navigation task show that policies trained on small networks transfer directly to larger ones and unseen network topologies, achieve higher returns and lower variance than a state-of-the-art MARL baseline while preserving stability.",human
"Accurate and physically consistent modeling of Earth system dynamics requires machine-learning architectures that operate directly on continuous geophysical fields and preserve their underlying geometric structure. Here we introduce Field-Space attention, a mechanism for Earth system Transformers that computes attention in the physical domain rather than in a learned latent space. By maintaining all intermediate representations as continuous fields on the sphere, the architecture enables interpretable internal states and facilitates the enforcement of scientific constraints. The model employs a fixed, non-learned multiscale decomposition and learns structure-preserving deformations of the input field, allowing coherent integration of coarse and fine-scale information while avoiding the optimization instabilities characteristic of standard single-scale Vision Transformers. Applied to global temperature super-resolution on a HEALPix grid, Field-Space Transformers converge more rapidly and stably than conventional Vision Transformers and U-Net baselines, while requiring substantially fewer parameters. The explicit preservation of field structure throughout the network allows physical and statistical priors to be embedded directly into the architecture, yielding improved fidelity and reliability in data-driven Earth system modeling. These results position Field-Space Attention as a compact, interpretable, and physically grounded building block for next-generation Earth system prediction and generative modeling frameworks.",human
"We address the problem of effectively representing relational knowledge to facilitate accurate and efficient reasoning. Traditional knowledge representation formalisms often struggle with scalability and the ability to capture complex, nuanced relationships between entities. Our approach introduces a novel graph-based embedding method, termed Relational Attentive Walk Embeddings (RAWE), which leverages attention mechanisms to learn context-aware representations of entities and relations within a knowledge graph. RAWE constructs embeddings by aggregating information from random walks initiated from each entity, weighting the contribution of neighboring entities and relations based on their relevance to the source entity, as determined by an attention network. This allows the model to focus on the most salient aspects of the graph structure for each entity. We evaluate RAWE on a suite of knowledge graph completion benchmarks, including WN18RR, FB15k-237, and YAGO3-10, demonstrating substantial improvements in link prediction accuracy compared to state-of-the-art embedding models, particularly on datasets exhibiting complex relational patterns. Furthermore, ablation studies confirm the importance of the attention mechanism in capturing nuanced relational dependencies. The results suggest that RAWE provides a more robust and informative knowledge representation, leading to enhanced performance in downstream reasoning tasks.",ai
"This report summarizes the 6th International Verification of Neural Networks Competition (VNN-COMP 2025), held as a part of the 8th International Symposium on AI Verification (SAIV), that was collocated with the 37th International Conference on Computer-Aided Verification (CAV). VNN-COMP is held annually to facilitate the fair and objective comparison of state-of-the-art neural network verification tools, encourage the standardization of tool interfaces, and bring together the neural network verification community. To this end, standardized formats for networks (ONNX) and specification (VNN-LIB) were defined, tools were evaluated on equal-cost hardware (using an automatic evaluation pipeline based on AWS instances), and tool parameters were chosen by the participants before the final test sets were made public. In the 2025 iteration, 8 teams participated on a diverse set of 16 regular and 9 extended benchmarks. This report summarizes the rules, benchmarks, participating tools, results, and lessons learned from this iteration of this competition.",human
"How do language models use contextual information to answer health questions? How are their responses impacted by conflicting contexts? We assess the ability of language models to reason over long, conflicting biomedical contexts using HealthContradict, an expert-verified dataset comprising 920 unique instances, each consisting of a health-related question, a factual answer supported by scientific evidence, and two documents presenting contradictory stances. We consider several prompt settings, including correct, incorrect or contradictory context, and measure their impact on model outputs. Compared to existing medical question-answering evaluation benchmarks, HealthContradict provides greater distinctions of language models' contextual reasoning capabilities. Our experiments show that the strength of fine-tuned biomedical language models lies not only in their parametric knowledge from pretraining, but also in their ability to exploit correct context while resisting incorrect context.",human
"**Transformer Architectures with Attention Masking for Enhanced Long-Range Dependency Modeling in NLP** The prevalent sequence-to-sequence paradigm in natural language processing (NLP) increasingly relies on Transformer architectures. However, modeling long-range dependencies remains a persistent challenge, particularly in tasks involving lengthy texts or complex syntactic structures. This work investigates the impact of novel attention masking strategies within Transformer models to improve the representation and processing of distant relationships between tokens. We propose a series of structured sparsity masks applied during the self-attention mechanism. These masks selectively restrict attention to specific subsets of the input sequence, either based on learned structural information or predetermined patterns. We evaluate our proposed masking strategies on a suite of NLP benchmarks, including machine translation, text summarization, and question answering, focusing on datasets with pronounced long-range dependencies. Empirical results demonstrate that our masked Transformer variants achieve significant performance gains compared to standard Transformer baselines, particularly in tasks requiring precise comprehension of contextual relationships across extensive text spans. Ablation studies further reveal the efficacy of specific masking patterns in capturing distinct types of long-range dependencies, highlighting the potential for tailored attention mechanisms to address the inherent limitations of fully connected attention in Transformer models. These findings suggest a promising avenue for developing more efficient and accurate Transformer architectures for a wide range of NLP applications.",ai
"Frontier language model quality increasingly hinges on our ability to organize web-scale text corpora for training. Today's dominant tools trade off speed and flexibility: lexical classifiers (e.g., FastText) are fast but limited to producing classification output scores, while the vector-valued outputs of transformer text embedding models flexibly support numerous workflows (e.g., clustering, classification, and retrieval) but are computationally expensive to produce. We introduce Luxical, a library for high-speed ""lexical-dense"" text embeddings that aims to recover the best properties of both approaches for web-scale text organization. Luxical combines sparse TF--IDF features, a small ReLU network, and a knowledge distillation training regimen to approximate large transformer embedding models at a fraction of their operational cost. In this technical report, we describe the Luxical architecture and training objective and evaluate a concrete Luxical model in two disparate applications: a targeted webcrawl document retrieval test and an end-to-end language model data curation task grounded in text classification. In these tasks we demonstrate speedups ranging from 3x to 100x over varying-sized neural baselines, and comparable to FastText model inference during the data curation task. On these evaluations, the tested Luxical model illustrates favorable compute/quality trade-offs for large-scale text organization, matching the quality of neural baselines. Luxical is available as open-source software at https://github.com/datologyai/luxical.",human
"Graph Neural Networks (GNNs) have demonstrated significant potential in learning representations of nodes and graphs across diverse application domains. However, the performance of GNNs is often hindered by the oversmoothing problem, where node representations converge to similar values after multiple layers, leading to diminished discriminative power. This work addresses the oversmoothing challenge by proposing a novel graph learning framework that dynamically adjusts the receptive field of each node during message passing. The proposed method, termed Adaptive Receptive Field GNN (ARF-GNN), employs a differentiable attention mechanism to learn optimal neighborhood aggregation schemes specific to each node. The attention weights are modulated by both node features and graph structural information, allowing the network to adaptively control the extent of information propagation. Extensive experiments on benchmark graph datasets, including Cora, Citeseer, and PubMed, demonstrate that ARF-GNN consistently outperforms existing state-of-the-art GNN architectures in node classification tasks. Specifically, ARF-GNN achieves significant improvements in classification accuracy, particularly for deeper network architectures. Furthermore, ablation studies validate the effectiveness of the adaptive receptive field mechanism in mitigating oversmoothing and improving the robustness of node representations.",ai
"Children's speech recognition remains challenging due to substantial acoustic and linguistic variability, limited labeled data, and significant differences from adult speech. Speech foundation models can address these challenges through Speech In-Context Learning (SICL), allowing adaptation to new domains without fine-tuning. However, the effectiveness of SICL depends on how in-context examples are selected. We extend an existing retrieval-based method, Text-Embedding KNN for SICL (TICL), introducing an acoustic reranking step to create TICL+. This extension prioritizes examples that are both semantically and acoustically aligned with the test input. Experiments on four children's speech corpora show that TICL+ achieves up to a 53.3% relative word error rate reduction over zero-shot performance and 37.6% over baseline TICL, highlighting the value of combining semantic and acoustic information for robust, scalable ASR in children's speech.",human
"We address the challenge of sparse reward environments in reinforcement learning (RL) for complex language-based tasks, specifically focusing on instruction-following in simulated environments. Traditional RL methods often struggle in such scenarios due to the lack of informative feedback signals, leading to inefficient exploration and slow convergence. We propose a novel hierarchical RL framework incorporating intrinsic motivation via a learned goal-reaching policy and a high-level planner driven by natural language instructions. The goal-reaching policy, trained via self-play and hindsight experience replay, learns to navigate to specified subgoal locations within the environment. The high-level planner decomposes the instruction into a sequence of subgoals, leveraging a pre-trained language model fine-tuned for subgoal prediction. This decomposition allows the agent to receive more frequent, intrinsically-motivated rewards for achieving subgoals, thereby mitigating the sparsity problem. We evaluate our approach on a simulated block-world environment where agents must stack blocks according to natural language instructions. Experimental results demonstrate that our method significantly outperforms standard RL algorithms and imitation learning baselines, achieving a 30% improvement in task completion rate. Furthermore, analysis reveals that the learned subgoal decomposition aligns with human intuition, suggesting the framework learns interpretable strategies for instruction execution.",ai
"We address the challenge of automating complex logical reasoning within probabilistic graphical models. Inference in these models often necessitates intricate variable eliminations and marginalizations, demanding significant computational resources and expert knowledge to optimize. This work introduces a novel approach, dubbed Gradient-Guided Belief Propagation (GGBP), that leverages gradient information within the message passing framework to dynamically refine the inference trajectory. GGBP utilizes automatic differentiation to estimate the sensitivity of the target marginal probability with respect to individual message updates. This sensitivity information is then incorporated as a guiding signal to adaptively adjust message damping factors and prioritization schemes, thereby accelerating convergence and mitigating oscillations. We demonstrate the efficacy of GGBP across a range of benchmark problems, including Bayesian networks for medical diagnosis and Markov random fields for image segmentation. Empirical evaluations show that GGBP achieves significant speedups in convergence time compared to standard belief propagation and its variants, while maintaining comparable accuracy in marginal probability estimation. Furthermore, GGBP reduces the need for manual parameter tuning, rendering it a more practical solution for automated reasoning in complex probabilistic models.",ai
"We address the challenge of optimizing long-range dependencies in natural language generation (NLG) tasks, specifically in the context of abstractive text summarization. Traditional sequence-to-sequence models, even with attention mechanisms, often struggle to maintain coherence and factual consistency over extended output sequences. This work proposes a novel reinforcement learning (RL) framework that integrates a pre-trained language model with a hierarchical action space. The hierarchical action space decomposes the summarization task into a sequence of high-level planning actions, followed by low-level word generation actions conditioned on the plan. A policy gradient method is employed, leveraging a composite reward function that incorporates both intrinsic metrics (e.g., ROUGE scores against ground truth summaries) and extrinsic metrics obtained from a trained factuality verification model. Experimental results on the CNN/DailyMail and XSum datasets demonstrate significant improvements in summarization quality, as measured by ROUGE scores and human evaluation, compared to state-of-the-art sequence-to-sequence baselines. Furthermore, our approach exhibits improved factuality and coherence, indicating that the hierarchical planning mechanism effectively mitigates the issues of error accumulation and short-sighted decision making prevalent in traditional NLG models. We also perform ablation studies to evaluate the contribution of each component of the reward function.",ai
"We address the problem of identifying causal effects from observational data in the presence of unmeasured confounding and selection bias. Existing approaches often rely on strong assumptions about the functional form of causal relationships or the absence of specific confounding pathways. We propose a novel method, Instrumental Kernel Embeddings (IKE), which leverages kernel embeddings of conditional distributions to estimate average treatment effects (ATEs) by exploiting instrumental variables (IVs). IKE avoids explicit functional form assumptions and mitigates selection bias by conditioning on a set of carefully selected covariates identified through a kernel-based independence criterion. These covariates serve as proxies for the selection mechanism, rendering the IV conditionally valid. We derive theoretical guarantees for the identifiability of the ATE under mild conditions related to the IV strength and the conditional independence assumptions. Through extensive simulations and experiments on benchmark datasets, we demonstrate that IKE significantly outperforms existing methods in estimating ATEs when both unmeasured confounding and selection bias are present. Furthermore, IKE exhibits robustness to violations of the IV assumptions, offering a practical solution for causal inference in complex observational settings.",ai
"We investigate the problem of efficiently representing and reasoning with complex, structured knowledge in machine learning systems. Traditional knowledge representation formalisms, such as ontologies and knowledge graphs, often struggle to scale to the volume and complexity of data encountered in real-world applications, leading to bottlenecks in both storage and inference. We propose a novel approach, , which combines symbolic knowledge representation with neural network-based learning. DIKE represents entities and relations as continuous embeddings within a vector space, while simultaneously enforcing logical constraints through a differentiable loss function. This loss function penalizes embeddings that violate predefined logical rules, thereby guiding the learning process and ensuring semantic consistency. We evaluate DIKE on several benchmark knowledge graph completion and reasoning tasks. Results demonstrate that DIKE achieves state-of-the-art performance compared to existing methods, particularly in scenarios involving sparse and noisy knowledge. Furthermore, we show that DIKE's differentiable inductive bias allows for improved generalization and robustness to unseen data, while maintaining computational efficiency suitable for large-scale knowledge bases. Our findings highlight the potential of integrating symbolic and connectionist approaches to enhance knowledge representation and reasoning capabilities in machine learning.",ai
"Multimodal language models (MLLMs) require large parameter capacity to align high-dimensional visual features with linguistic representations, making them computationally heavy and difficult to deploy efficiently. We introduce a progressive reparameterization strategy that compresses these models by gradually replacing dense feed-forward network blocks with compact Parameterized Hypercomplex Multiplication (PHM) layers. A residual interpolation schedule, together with lightweight reconstruction and knowledge distillation losses, ensures that the PHM modules inherit the functional behavior of their dense counterparts during training. This transition yields substantial parameter and FLOP reductions while preserving strong multimodal alignment, enabling faster inference without degrading output quality. We evaluate the approach on multiple vision-language models (VLMs). Our method maintains performance comparable to the base models while delivering significant reductions in model size and inference latency. Progressive PHM substitution thus offers an architecture-compatible path toward more efficient multimodal reasoning and complements existing low-bit quantization techniques.",human
"**Automated Detection and Segmentation of Pulmonary Nodules in CT Scans using a Multi-Scale Convolutional Neural Network with Attention Mechanisms** Early detection of pulmonary nodules is crucial for improving lung cancer survival rates. However, the manual analysis of Computed Tomography (CT) scans for nodule identification is a time-consuming and often subjective process, leading to potential diagnostic delays. This study addresses the problem of automated pulmonary nodule detection and segmentation by proposing a novel multi-scale convolutional neural network (CNN) architecture incorporating spatial and channel attention mechanisms. Our method leverages a 3D U-Net backbone to capture volumetric contextual information from CT scans. To enhance the network's ability to identify subtle nodule features, we introduce a multi-scale feature fusion module that aggregates information from different convolutional layers. Furthermore, spatial and channel attention modules are integrated into the network to selectively emphasize relevant regions and feature channels, suppressing irrelevant background noise. The proposed model was trained and evaluated on the publicly available Lung Image Database Consortium image collection and image database (LIDC-IDRI). Experimental results demonstrate that our approach achieves state-of-the-art performance in nodule detection, with a competitive free-response receiver operating characteristic (FROC) score. Furthermore, the model exhibits superior segmentation accuracy, as measured by Dice Similarity Coefficient (DSC), outperforming existing methods. These results indicate the potential of our approach to improve the efficiency and accuracy of pulmonary nodule screening in clinical practice.",ai
"We investigate the challenge of achieving efficient and stable coordination among decentralized agents in complex, partially observable environments. Specifically, we address the problem of learning robust communication protocols in cooperative multi-agent reinforcement learning (MARL) settings where agents have limited information about the environment and the intentions of their peers. Our approach, termed Differentiable Inter-Agent Reasoning (DIAR), introduces a novel architecture that explicitly models the reasoning process of each agent about the potential actions and future states of other agents. DIAR leverages differentiable message passing within a graph neural network to enable agents to iteratively refine their beliefs about the environment and the intentions of others. This process incorporates a learned attention mechanism to selectively focus on relevant information from incoming messages and historical interactions. We evaluated DIAR on a suite of challenging benchmark environments, including StarCraft II micromanagement and cooperative navigation tasks. Empirical results demonstrate that DIAR significantly outperforms existing MARL algorithms, achieving higher team rewards and improved coordination strategies. Furthermore, we analyze the emergent communication protocols learned by DIAR and show that the agents develop meaningful and interpretable communication patterns that facilitate effective collaboration even under conditions of limited observability and high stochasticity.",ai
"Heart transplantation is a viable path for patients suffering from advanced heart failure, but this lifesaving option is severely limited due to donor shortage. Although the current allocation policy was recently revised in 2018, a major concern is that it does not adequately take into account pretransplant and post-transplant mortality. In this paper, we take an important step toward addressing these deficiencies. To begin with, we use historical data from UNOS to develop a new simulator that enables us to evaluate and compare the performance of different policies. We then leverage our simulator to demonstrate that the status quo policy is considerably inferior to the myopic policy that matches incoming donors to the patient who maximizes the number of years gained by the transplant. Moreover, we develop improved policies that account for the dynamic nature of the allocation process through the use of potentials -- a measure of a patient's utility in future allocations that we introduce. We also show that batching together even a handful of donors -- which is a viable option for a certain type of donors -- further enhances performance. Our simulator also allows us to evaluate the effect of critical, and often unexplored, factors in the allocation, such as geographic proximity and the tendency to reject offers by the transplant centers.",human
"We investigate the application of deep convolutional neural networks (CNNs) to the automated segmentation of lung tumors in computed tomography (CT) scans. Accurate and efficient segmentation is crucial for diagnosis, treatment planning, and monitoring disease progression. However, manual segmentation is time-consuming and subject to inter-observer variability. This work addresses the challenge of robust lung tumor segmentation in the presence of variations in tumor size, shape, and location, as well as image artifacts and low contrast. We propose a novel multi-scale, attention-guided 3D U-Net architecture enhanced with residual connections and deep supervision. The multi-scale design enables the network to capture features at different resolutions, improving sensitivity to both small and large tumors. The attention mechanism focuses the network's learning on relevant image regions, mitigating the impact of noisy background and improving segmentation accuracy. The network was trained and evaluated on a publicly available dataset of lung CT scans. Experimental results demonstrate that our proposed architecture achieves state-of-the-art segmentation performance, outperforming existing methods in terms of Dice coefficient and Hausdorff distance. Specifically, we observe a significant improvement in segmentation accuracy for smaller tumors and tumors located in challenging anatomical regions.",ai
"--- Accurate and efficient segmentation of anatomical structures in medical imaging is crucial for diagnosis, treatment planning, and disease monitoring. However, the inherent complexity and variability within medical image data, compounded by the presence of noise and artifacts, pose significant challenges for automated segmentation algorithms. This paper introduces a novel multi-scale convolutional neural network (CNN) architecture, termed MedSegNet, designed specifically to address these challenges. MedSegNet incorporates a parallel pathway structure, enabling the network to simultaneously capture both fine-grained details and global contextual information. Furthermore, we introduce a custom loss function that balances pixel-wise accuracy with region-based consistency, promoting topologically correct segmentations. We evaluate MedSegNet on two publicly available datasets: the LIDC-IDRI dataset for lung nodule segmentation and the BraTS dataset for brain tumor segmentation. Experimental results demonstrate that MedSegNet achieves state-of-the-art performance, surpassing existing methods in terms of Dice coefficient, Hausdorff distance, and overall segmentation accuracy. Specifically, we observe improvements of 3.2% in Dice coefficient for lung nodule segmentation and 2.1% for brain tumor segmentation compared to the best-performing baseline models. These results highlight the potential of MedSegNet as a robust and accurate tool for automated medical image segmentation.",ai
"Test-time compute scaling has emerged as a powerful paradigm for enhancing mathematical reasoning in large language models (LLMs) by allocating additional computational resources during inference. However, current methods employ uniform resource distribution across all reasoning sub-problems, creating fundamental bottlenecks where challenging sub-problems receive insufficient attention while routine operations consume disproportionate resources. This uniform allocation creates performance bottlenecks where additional computational resources yield diminishing returns. Inspired by dual-process theory, we propose (Selective Resource Allocation), a framework that selectively allocates computational resources based on sub-problem difficulty. SCALE operates through four stages: (1) problem decomposition into sequential reasoning sub-problems, (2) difficulty assessment of each sub-problem to distinguish between routine operations and computationally challenging sub-problems, (3) selective processing mode assignment between System 1 for simple sub-problems and System 2 for complex ones, and (4) sequential execution with context propagation. By concentrating resources on challenging sub-problems while processing routine operations efficiently, SCALE achieves substantial performance improvements with superior resource utilization. Extensive experiments demonstrate that SCALE significantly outperforms uniform scaling baselines, achieving accuracy improvements of up to 13.75 percentage points (57.50% to 71.25% on AIME25) while reducing computational costs by 33%-53%, representing a major advance in test-time scaling that addresses fundamental limitations of current approaches.",human
"We address the challenge of enhancing the reasoning capabilities of neural networks in complex, multi-hop relational reasoning tasks, specifically focusing on scenarios where explicit symbolic knowledge is available but potentially incomplete or noisy. Current approaches often struggle to effectively integrate symbolic knowledge into neural architectures, leading to suboptimal performance when encountering unseen or ambiguous relational combinations. We propose a novel framework, Neuro-Symbolic Attentive Reasoning (NSAR), which leverages attention mechanisms to dynamically ground neural representations onto symbolic knowledge graphs. NSAR employs a bi-directional attention module that simultaneously attends to both the neural embeddings derived from the input context and the symbolic relationships extracted from the knowledge graph. This allows for a more nuanced integration of symbolic information, where relevant relations are adaptively weighted based on their contextual relevance. The framework incorporates a differentiable reasoning module that iteratively propagates information across the knowledge graph, guided by the attention-weighted relations. Experimental results on the benchmark datasets of PathFinder and Ruletaker demonstrate that NSAR significantly outperforms existing neural and neuro-symbolic methods, achieving state-of-the-art performance in terms of accuracy and generalization ability. Ablation studies confirm the effectiveness of the bi-directional attention module and the differentiable reasoning process. The improved performance highlights the potential of NSAR to bridge the gap between neural and symbolic reasoning, leading to more robust and explainable reasoning systems.",ai
"We address the challenge of sample inefficiency in reinforcement learning (RL) for complex, high-dimensional environments, particularly those with sparse rewards. Traditional RL algorithms often struggle to learn effective policies in such scenarios due to the vast exploration space and infrequent feedback signals. To mitigate this, we introduce a novel framework, Hierarchical Skill Discovery with Intrinsic Motivation (HSDIM), which combines hierarchical reinforcement learning with an intrinsic motivation signal based on state novelty. HSDIM leverages a two-level hierarchy: a higher-level manager learns to select from a repertoire of lower-level skills, while the skills themselves are learned autonomously to maximize their ability to reach novel states. This allows for efficient exploration by focusing on diverse state coverage and reduces the burden on the manager by providing pre-trained, reusable building blocks. We evaluated HSDIM on a suite of challenging continuous control tasks with sparse rewards, including robotic manipulation and navigation in mazes. Our results demonstrate that HSDIM significantly outperforms state-of-the-art RL algorithms, achieving higher success rates and faster learning speeds. Furthermore, we provide an ablation study that elucidates the contribution of each component of HSDIM, highlighting the synergistic effect of hierarchical control and intrinsic motivation for effective exploration and policy learning in sparse reward environments.",ai
"Studying how embeddings are organized in space not only enhances model interpretability but also uncovers factors that drive downstream task performance. In this paper, we present a comprehensive analysis of topological and geometric measures across a wide set of text embedding models and datasets. We find a high degree of redundancy among these measures and observe that individual metrics often fail to sufficiently differentiate embedding spaces. Building on these insights, we introduce Unified Topological Signatures (UTS), a holistic framework for characterizing embedding spaces. We show that UTS can predict model-specific properties and reveal similarities driven by model architecture. Further, we demonstrate the utility of our method by linking topological structure to ranking effectiveness and accurately predicting document retrievability. We find that a holistic, multi-attribute perspective is essential to understanding and leveraging the geometry of text embeddings.",human
"Diffusion based approaches to long form text generation suffer from prohibitive computational cost and memory overhead as sequence length increases. We introduce SA-DiffuSeq, a diffusion framework that integrates sparse attention to fundamentally improve scalability for long document modeling. By selectively allocating attention within the diffusion process, SA-DiffuSeq significantly reduces computational complexity while maintaining semantic coherence and generation quality. A key component of our method is a soft absorbing state tailored to sparse attention dynamics, which stabilizes diffusion trajectories and accelerates sequence reconstruction. This design improves sampling efficiency and enhances precision in long range dependency modeling. Extensive experiments demonstrate that SA-DiffuSeq consistently surpasses state of the art diffusion baselines in both training efficiency and sampling speed, with especially strong gains on extended sequences. These properties make SA-DiffuSeq well suited for demanding long form applications such as scientific writing, large scale code generation, and multi turn long context dialogue. Overall, our results indicate that incorporating structured sparsity into diffusion models is a promising direction for efficient and expressive long text generation.",human
"Authorship analysis has traditionally focused on lexical and stylistic cues within text, while higher-level narrative structure remains underexplored, particularly for low-resource languages such as Urdu. This work proposes a graph-based framework that models Urdu novels as character interaction networks to examine whether authorial style can be inferred from narrative structure alone. Each novel is represented as a graph where nodes correspond to characters and edges denote their co-occurrence within narrative proximity. We systematically compare multiple graph representations, including global structural features, node-level semantic summaries, unsupervised graph embeddings, and supervised graph neural networks. Experiments on a dataset of 52 Urdu novels written by seven authors show that learned graph representations substantially outperform hand-crafted and unsupervised baselines, achieving up to 0.857 accuracy under a strict author-aware evaluation protocol.",human
"Deep neural networks achieve superior performance in semantic segmentation, but are limited to a predefined set of classes, which leads to failures when they encounter unknown objects in open-world scenarios. Recognizing and segmenting these out-of-distribution (OOD) objects is crucial for safety-critical applications such as automated driving. In this work, we present an evidence segmentation framework using a Wasserstein loss, which captures distributional distances while respecting the probability simplex geometry. Combined with Kullback-Leibler regularization and Dice structural consistency terms, our approach leads to improved OOD segmentation performance compared to uncertainty-based approaches.",human
"We address the problem of spurious correlations in natural language processing (NLP) tasks, which often lead to models that perform well on benchmark datasets but fail to generalize to out-of-distribution data. Specifically, we focus on the task of natural language inference (NLI), where models can learn to predict entailment based on lexical overlap or other superficial features rather than genuine semantic relationships. To mitigate this issue, we propose a novel causal intervention framework that leverages backdoor adjustment within a structural causal model (SCM) representing the relationships between premise, hypothesis, and spurious features. Our method identifies and estimates the causal effect of the premise on the hypothesis, effectively removing the influence of confounding variables. This is achieved by strategically intervening on the premise representation using a learned intervention function, guided by identified backdoor paths. We empirically evaluate our approach on several challenging NLI datasets, including HANS and adversarial NLI benchmarks. Results demonstrate that our causal intervention method significantly improves out-of-distribution generalization performance compared to standard training and other debiasing techniques, while maintaining competitive accuracy on in-distribution data. Furthermore, analysis reveals that our method effectively reduces the reliance on spurious features, leading to more robust and semantically grounded NLI models.",ai
"We develop a unified, dynamical-systems narrative of the universe that traces a continuous chain of structure formation from the Big Bang to contemporary human societies and their artificial learning systems. Rather than treating cosmology, astrophysics, geophysics, biology, cognition, and machine intelligence as disjoint domains, we view each as successive regimes of dynamics on ever-richer state spaces, stitched together by phase transitions, symmetry-breaking events, and emergent attractors. Starting from inflationary field dynamics and the growth of primordial perturbations, we describe how gravitational instability sculpts the cosmic web, how dissipative collapse in baryonic matter yields stars and planets, and how planetary-scale geochemical cycles define long-lived nonequilibrium attractors. Within these attractors, we frame the origin of life as the emergence of self-maintaining reaction networks, evolutionary biology as flow on high-dimensional genotype-phenotype-environment manifolds, and brains as adaptive dynamical systems operating near critical surfaces. Human culture and technology-including modern machine learning and artificial intelligence-are then interpreted as symbolic and institutional dynamics that implement and refine engineered learning flows which recursively reshape their own phase space. Throughout, we emphasize recurring mathematical motifs-instability, bifurcation, multiscale coupling, and constrained flows on measure-zero subsets of the accessible state space. Our aim is not to present any new cosmological or biological model, but a cross-scale, theoretical perspective: a way of reading the universe's history as the evolution of dynamics itself, culminating (so far) in biological and artificial systems capable of modeling, predicting, and deliberately perturbing their own future trajectories.",human
"Vertical Federated Learning (VFL) offers a privacy-preserving paradigm for Edge AI scenarios like mobile health diagnostics, where sensitive multimodal data reside on distributed, resource-constrained devices. Yet, standard VFL systems often suffer performance limitations due to simplistic feature fusion. This paper introduces HybridVFL, a novel framework designed to overcome this bottleneck by employing client-side feature disentanglement paired with a server-side cross-modal transformer for context-aware fusion. Through systematic evaluation on the multimodal HAM10000 skin lesion dataset, we demonstrate that HybridVFL significantly outperforms standard federated baselines, validating the criticality of advanced fusion mechanisms in robust, privacy-preserving systems.",human
"We address the problem of coordinating communicative actions in decentralized multi-agent systems operating in environments with sparse and delayed feedback. Existing reinforcement learning approaches often struggle in such settings due to the difficulty in assigning credit to individual agents for collective outcomes, leading to suboptimal policy convergence. To mitigate this, we introduce a novel hierarchical communication framework, Cooperative Message Propagation (CMP). CMP leverages a shared latent communication channel modulated by individual agent policies. Agents learn to encode relevant environmental observations into messages, which are then aggregated and propagated throughout the network. A discriminator, trained adversarially, encourages agents to generate messages that are both informative and distinguishable, promoting diverse roles within the team. We evaluate CMP on a suite of challenging cooperative navigation and resource allocation tasks. Empirical results demonstrate that CMP significantly outperforms state-of-the-art multi-agent reinforcement learning algorithms, exhibiting faster convergence, improved robustness to noise, and enhanced communication efficiency. Furthermore, analysis of the learned communication patterns reveals emergent role specialization among agents, highlighting the framework's ability to facilitate coordinated behavior in complex, decentralized environments. These findings suggest that structured communication protocols, combined with adversarial learning techniques, offer a promising avenue for addressing the challenges of multi-agent coordination.",ai
"**Automated Detection of Pulmonary Embolism using Multi-Scale Convolutional Neural Networks on Computed Tomography Angiograms** Pulmonary embolism (PE) diagnosis via computed tomography angiography (CTA) is a time-consuming and error-prone task for radiologists. The subtle visual characteristics of PE, coupled with the large volume of CTA data, necessitates automated methods for improved detection accuracy and efficiency. This paper presents a novel multi-scale convolutional neural network (MS-CNN) architecture for the automated detection of PE in CTA scans. The proposed MS-CNN leverages a hierarchical feature extraction scheme, integrating information from multiple receptive fields to capture both fine-grained embolus features and coarser anatomical context. Specifically, the network incorporates parallel convolutional pathways with varying kernel sizes, followed by a fusion layer to aggregate multi-scale representations. A comprehensive evaluation was conducted on a large, retrospectively collected dataset of CTA scans, consisting of both positive and negative PE cases. Experimental results demonstrate that the proposed MS-CNN achieves a sensitivity of 88.2% at a specificity of 91.5% for patient-level PE detection, outperforming existing state-of-the-art methods by a significant margin. Furthermore, the model exhibits strong generalization capabilities, maintaining high performance across different scanner models and patient demographics. This study provides a promising framework for the development of clinically viable automated PE detection systems, potentially reducing diagnostic delays and improving patient outcomes.",ai
"Forecasting from partial observations is central to world modeling. Many recent methods represent the world through images, and reduce forecasting to stochastic video generation. Although such methods excel at realism and visual fidelity, predicting pixels is computationally intensive and not directly useful in many applications, as it requires translating RGB into signals useful for decision making. An alternative approach uses features from vision foundation models (VFMs) as world representations, performing deterministic regression to predict future world states. These features can be directly translated into actionable signals such as semantic segmentation and depth, while remaining computationally efficient. However, deterministic regression averages over multiple plausible futures, undermining forecast accuracy by failing to capture uncertainty. To address this crucial limitation, we introduce a generative forecaster that performs autoregressive flow matching in VFM feature space. Our key insight is that generative modeling in this space requires encoding VFM features into a compact latent space suitable for diffusion. We show that this latent space preserves information more effectively than previously used PCA-based alternatives, both for forecasting and other applications, such as image generation. Our latent predictions can be easily decoded into multiple useful and interpretable output modalities: semantic segmentation, depth, surface normals, and even RGB. With matched architecture and compute, our method produces sharper and more accurate predictions than regression across all modalities. Our results suggest that stochastic conditional generation of VFM features offers a promising and scalable foundation for future world models.",human
"This paper introduces a novel machine learning architecture for an efficient estimation of the probabilistic space-time representation of complex traffic scenarios. A detailed representation of the future traffic scenario is of significant importance for autonomous driving and for all active safety systems. In order to predict the future space-time representation of the traffic scenario, first the type of traffic scenario is identified and then the machine learning algorithm maps the current state of the scenario to possible future states. The input to the machine learning algorithms is the current state representation of a traffic scenario, termed as the Augmented Occupancy Grid (AOG). The output is the probabilistic space-time representation which includes uncertainties regarding the behaviour of the traffic participants and is termed as the Predicted Occupancy Grid (POG). The novel architecture consists of two Stacked Denoising Autoencoders (SDAs) and a set of Random Forests. It is then compared with the other two existing architectures that comprise of SDAs and DeconvNet. The architectures are validated with the help of simulations and the comparisons are made both in terms of accuracy and computational time. Also, a brief overview on the applications of POGs in the field of active safety is presented.",human
"Multi-period portfolio optimization is important for real portfolio management, as it accounts for transaction costs, path-dependent risks, and the intertemporal structure of trading decisions that single-period models cannot capture. Classical methods usually follow a two-stage framework: machine learning algorithms are employed to produce forecasts that closely fit the realized returns, and the predicted values are then used in a downstream portfolio optimization problem to determine the asset weights. This separation leads to a fundamental misalignment between predictions and decision outcomes, while also ignoring the impact of transaction costs. To bridge this gap, recent studies have proposed the idea of end-to-end learning, integrating the two stages into a single pipeline. This paper introduces IPMO (Integrated Prediction and Multi-period Portfolio Optimization), a model for multi-period mean-variance portfolio optimization with turnover penalties. The predictor generates multi-period return forecasts that parameterize a differentiable convex optimization layer, which in turn drives learning via portfolio performance. For scalability, we introduce a mirror-descent fixed-point (MDFP) differentiation scheme that avoids factorizing the Karush-Kuhn-Tucker (KKT) systems, which thus yields stable implicit gradients and nearly scale-insensitive runtime as the decision horizon grows. In experiments with real market data and two representative time-series prediction models, the IPMO method consistently outperforms the two-stage benchmarks in risk-adjusted performance net of transaction costs and achieves more coherent allocation paths. Our results show that integrating machine learning prediction with optimization in the multi-period setting improves financial outcomes and remains computationally tractable.",human
"Ensuring the safety and efficiency of AI systems is a central goal of modern research. Formal verification provides guarantees of neural network robustness, while early exits improve inference efficiency by enabling intermediate predictions. Yet verifying networks with early exits introduces new challenges due to their conditional execution paths. In this work, we define a robustness property tailored to early exit architectures and show how off-the-shelf solvers can be used to assess it. We present a baseline algorithm, enhanced with an early stopping strategy and heuristic optimizations that maintain soundness and completeness. Experiments on multiple benchmarks validate our framework's effectiveness and demonstrate the performance gains of the improved algorithm. Alongside the natural inference acceleration provided by early exits, we show that they also enhance verifiability, enabling more queries to be solved in less time compared to standard networks. Together with a robustness analysis, we show how these metrics can help users navigate the inherent trade-off between accuracy and efficiency.",human
"Workplace toxicity is widely recognized as detrimental to organizational culture, yet quantifying its direct impact on operational efficiency remains methodologically challenging due to the ethical and practical difficulties of reproducing conflict in human subjects. This study leverages Large Language Model (LLM) based Multi-Agent Systems to simulate 1-on-1 adversarial debates, creating a controlled ""sociological sandbox"". We employ a Monte Carlo method to simulate hundrets of discussions, measuring the convergence time (defined as the number of arguments required to reach a conclusion) between a baseline control group and treatment groups involving agents with ""toxic"" system prompts. Our results demonstrate a statistically significant increase of approximately 25\% in the duration of conversations involving toxic participants. We propose that this ""latency of toxicity"" serves as a proxy for financial damage in corporate and academic settings. Furthermore, we demonstrate that agent-based modeling provides a reproducible, ethical alternative to human-subject research for measuring the mechanics of social friction.",human
"Telescope bibliographies record the pulse of astronomy research by capturing publication statistics and citation metrics for telescope facilities. Robust and scalable bibliographies ensure that we can measure the scientific impact of our facilities and archives. However, the growing rate of publications threatens to outpace our ability to manually label astronomical literature. We therefore present the Automated Mission Classifier (amc), a tool that uses large language models (LLMs) to identify and categorize telescope references by processing large quantities of paper text. A modified version of amc performs well on the TRACS Kaggle challenge, achieving a macro score of 0.84 on the held-out test set. amc is valuable for other telescopes beyond TRACS; we developed the initial software for identifying papers that featured scientific results by NASA missions. Additionally, we investigate how amc can also be used to interrogate historical datasets and surface potential label errors. Our work demonstrates that LLM-based applications offer powerful and scalable assistance for library sciences.",human
"We address the challenge of emergent communication in cooperative multi-agent systems, specifically focusing on environments requiring nuanced coordination and task decomposition. Prior work often relies on centralized training schemes or predefined communication protocols, which can limit scalability and adaptability to novel scenarios. This paper introduces a decentralized learning framework utilizing a differentiable message passing mechanism coupled with a novel reward shaping function designed to encourage compositional message formation. The agents learn both the content and structure of their communication protocols through interactions with the environment and other agents. We propose a modular recurrent neural network architecture that allows for efficient encoding and decoding of variable-length messages. We evaluate our approach on a set of benchmark multi-agent tasks requiring complex collaboration, including a novel task involving spatial reasoning and resource allocation. Empirical results demonstrate that our framework achieves significantly improved performance compared to baseline methods that rely on fixed communication structures or centralized control. Furthermore, analysis of the learned message patterns reveals that the agents develop compositional languages that exhibit properties such as symbol grounding and role differentiation, suggesting a capacity for complex, adaptive communication strategies. These findings contribute to the development of robust and scalable multi-agent systems capable of solving intricate cooperative problems.",ai
"Software Defect Prediction (SDP) models are central to proactive software quality assurance, yet their effectiveness is often constrained by the quality of available datasets. Prior research has typically examined single issues such as class imbalance or feature irrelevance in isolation, overlooking that real-world data problems frequently co-occur and interact. This study presents, to our knowledge, the first large-scale empirical analysis in SDP that simultaneously examines five co-occurring data quality issues (class imbalance, class overlap, irrelevant features, attribute noise, and outliers) across 374 datasets and five classifiers. We employ Explainable Boosting Machines together with stratified interaction analysis to quantify both direct and conditional effects under default hyperparameter settings, reflecting practical baseline usage. Our results show that co-occurrence is nearly universal: even the least frequent issue (attribute noise) appears alongside others in more than 93% of datasets. Irrelevant features and imbalance are nearly ubiquitous, while class overlap is the most consistently harmful issue. We identify stable tipping points around 0.20 for class overlap, 0.65-0.70 for imbalance, and 0.94 for irrelevance, beyond which most models begin to degrade. We also uncover counterintuitive patterns, such as outliers improving performance when irrelevant features are low, underscoring the importance of context-aware evaluation. Finally, we expose a performance-robustness trade-off: no single learner dominates under all conditions. By jointly analyzing prevalence, co-occurrence, thresholds, and conditional effects, our study directly addresses a persistent gap in SDP research. Hence, moving beyond isolated analyses to provide a holistic, data-aware understanding of how quality issues shape model performance in real-world settings.",human
"This paper addresses the challenge of decision-making under uncertainty in complex environments, a problem frequently encountered in real-world optimization scenarios. Traditional optimization methods often falter when faced with parameter uncertainty, leading to suboptimal or even infeasible solutions. We propose a novel robust optimization framework based on a modified affine decision rule combined with a scenario generation technique leveraging kernel density estimation. This approach allows us to efficiently construct uncertainty sets that capture the underlying probability distribution of uncertain parameters while maintaining computational tractability. The proposed methodology demonstrably improves solution robustness against parameter variations compared to standard affine-based robust optimization, as evidenced by numerical experiments conducted on a stochastic knapsack problem and a power system unit commitment problem. Specifically, we observe a reduction in constraint violation probabilities by up to 35% and an improvement in average objective function value under uncertainty by 12% compared to established benchmarks. These results highlight the efficacy of our method in providing reliable and high-quality solutions in the presence of significant parameter uncertainty, making it a viable tool for robust decision-making in various domains.",ai
"We address the problem of decentralized learning in multi-agent systems (MAS) with heterogeneous agent dynamics and limited communication bandwidth. Specifically, we consider a scenario where agents aim to collaboratively optimize a global objective function, but are constrained by their individual state-space models and intermittent communication links. Current approaches often rely on strong assumptions about agent homogeneity or require extensive information sharing, which can be impractical in many real-world applications. To overcome these limitations, we propose a novel decentralized learning framework leveraging a combination of proximal stochastic gradient descent (ProxSGD) and event-triggered communication. Each agent independently updates its estimate of the global optimum using ProxSGD, incorporating a proximal term to account for its individual dynamics. Communication is triggered only when the local estimate deviates significantly from the last communicated value, thereby reducing bandwidth requirements. We provide a rigorous theoretical analysis of the convergence properties of our algorithm, demonstrating that it converges to a neighborhood of the optimal solution under mild assumptions on the objective function and agent dynamics. Empirical evaluations on benchmark cooperative control tasks demonstrate that our framework achieves comparable or superior performance compared to existing decentralized algorithms, while significantly reducing communication overhead. Our results highlight the potential of event-triggered communication for efficient decentralized learning in complex MAS environments.",ai
"Identifying the graphical structure underlying the observed multivariate data is essential in numerous applications. Current methodologies are predominantly confined to deducing a singular graph under the presumption that the observed data are uniform. However, many contexts involve heterogeneous datasets that feature multiple closely related graphs, typically referred to as multiview graphs. Previous research on multiview graph learning promotes edge-based similarity across layers using pairwise or consensus-based regularizers. However, multiview graphs frequently exhibit a shared node-based architecture across different views, such as common hub nodes. Such commonalities can enhance the precision of learning and provide interpretive insight. In this paper, we propose a co-hub node model, positing that different views share a common group of hub nodes. The associated optimization framework is developed by enforcing structured sparsity on the connections of these co-hub nodes. Moreover, we present a theoretical examination of layer identifiability and determine bounds on estimation error. The proposed methodology is validated using both synthetic graph data and fMRI time series data from multiple subjects to discern several closely related graphs.",human
"We investigate the problem of efficiently reasoning about knowledge and belief in multi-agent systems with resource constraints. Traditional epistemic logics often suffer from computational intractability, particularly when dealing with nested modalities of belief and knowledge across multiple agents. This paper introduces a novel approach combining Answer Set Programming Modulo Theories (ASP Modulo Theories) with prioritized temporal epistemic logic. Our method leverages the declarative nature of ASP Modulo Theories to represent complex epistemic states and the prioritized temporal logic to model evolving beliefs under resource limitations. We formalize resource constraints as linear inequalities embedded within the ASP Modulo Theories encoding. The prioritization scheme guides the reasoning process, favoring more critical beliefs during resource contention. We present a formal semantics and implementation details of our approach. Experimental results on benchmark scenarios involving collaborative planning and strategic negotiation demonstrate a significant improvement in computational efficiency compared to traditional epistemic model checking. Specifically, our approach achieves an average speedup of 2-3 orders of magnitude in complex belief update scenarios, while maintaining soundness and completeness with respect to the prioritized epistemic temporal semantics. This research provides a practical and scalable framework for automated reasoning about knowledge, belief, and resources in multi-agent systems.",ai
"Transformer networks have become a dominant architecture in natural language processing (NLP), demonstrating state-of-the-art performance across a wide range of tasks. However, inherent limitations in the computational complexity of the self-attention mechanism, specifically its quadratic dependence on sequence length, present a significant challenge when processing long documents. This work addresses this problem by investigating a novel adaptation of sparse attention mechanisms within the transformer architecture, focusing on a learned mixture of global and local attention patterns. We introduce a modified transformer layer that integrates a dynamically selected sparse attention mask, allowing the model to prioritize relevant contextual information while reducing computational cost. The effectiveness of the proposed method is evaluated on benchmark long document classification and question answering tasks, including the Long Range Arena (LRA) and TriviaQA. Experimental results demonstrate that our approach achieves comparable or improved performance relative to existing sparse transformer variants, while exhibiting a reduced computational footprint, especially noticeable with sequence lengths exceeding 4096 tokens. Specifically, our model achieves a 5% performance increase on the ListOps task within the LRA benchmark and a 2% improvement in F1 score on TriviaQA compared to a baseline transformer with global attention, indicating the potential for improved efficiency and scalability in long-context NLP applications.",ai
"We investigate the problem of enhancing the reasoning capabilities of large language models (LLMs) in complex multi-hop inference scenarios. Existing LLMs often struggle with tasks requiring chaining multiple pieces of information across extended contexts, leading to inaccurate or incomplete conclusions. We propose a novel framework, termed ""Decomposed Reasoning with Retrieval Augmentation"" (DRRA), which integrates a step-by-step reasoning decomposition strategy with a retrieval-augmented mechanism. DRRA first decomposes the complex reasoning task into a sequence of simpler, interconnected sub-problems. Each sub-problem is then addressed by retrieving relevant contextual information from a knowledge base and generating a corresponding inference step. This iterative process allows the model to explicitly track its reasoning path and leverage external knowledge to mitigate factual inaccuracies. We evaluate DRRA on several challenging reasoning benchmarks, including ReClor and StrategyQA. Experimental results demonstrate that DRRA significantly outperforms existing LLMs, achieving absolute improvements of 8.5% on ReClor and 6.2% on StrategyQA in terms of accuracy. Ablation studies highlight the importance of both the reasoning decomposition and retrieval-augmentation components in DRRA. The findings suggest that explicitly structuring the reasoning process and incorporating external knowledge are crucial for improving the reliability and accuracy of LLMs in complex reasoning tasks.",ai
"This paper addresses the vulnerability of neural text classification models to adversarial attacks generated through minimal, semantically-preserving perturbations. While adversarial training offers a defense, its computational cost remains a significant barrier, particularly for large-scale datasets and complex models. We propose a novel robust optimization framework, coined ""Min-Max Margin Enhancement"" (MMME), which explicitly minimizes the maximum loss within a strategically defined perturbation set while simultaneously maximizing the margin between the predicted class and the closest adversarial example. Unlike traditional adversarial training which relies on generating adversarial examples during each training iteration, MMME leverages a differentiable approximation of the adversarial loss using a first-order Taylor expansion, significantly reducing computational overhead. Further, we introduce a novel perturbation set definition based on token-level semantic similarity scores derived from contextualized word embeddings, ensuring both semantic preservation and efficient computation of the adversarial approximation. Experimental results on three benchmark text classification datasets (AG News, IMDB, and Yelp) demonstrate that MMME achieves comparable or superior robustness against various adversarial attacks, including synonym substitution and character-level perturbations, compared to state-of-the-art adversarial training methods. Crucially, MMME achieves these robustness gains with a reduction in training time by up to 40%, indicating a significant improvement in training efficiency.",ai
"We address the challenge of decision-making under uncertainty in complex environments, focusing on robust optimization techniques for problems exhibiting distributional ambiguity. Specifically, we consider a setting where the true probability distribution governing uncertain parameters is unknown but assumed to belong to a well-defined ambiguity set. Traditional robust optimization often relies on worst-case analysis, leading to overly conservative solutions. This work introduces a novel distributionally robust optimization (DRO) framework that leverages kernel methods to construct data-driven ambiguity sets. These sets are defined based on kernel Maximum Mean Discrepancy (MMD), allowing us to incorporate empirical data and learn a more refined representation of the uncertainty. Our method avoids strong distributional assumptions and exhibits improved performance compared to classical box and ellipsoidal uncertainty sets. Furthermore, we develop a tractable reformulation of the DRO problem, enabling efficient computation of robust optimal solutions. Empirical results on benchmark portfolio optimization and power system dispatch problems demonstrate that our kernel-based DRO approach achieves significant improvements in out-of-sample performance compared to traditional robust optimization techniques and alternative DRO formulations. These improvements are particularly pronounced when the available data is limited or the true distribution deviates significantly from standard parametric assumptions.",ai
"This paper derives `Scaling Laws for Economic Impacts' -- empirical relationships between the training compute of Large Language Models (LLMs) and professional productivity. In a preregistered experiment, over 500 consultants, data analysts, and managers completed professional tasks using one of 13 LLMs. We find that each year of AI model progress reduced task time by 8%, with 56% of gains driven by increased compute and 44% by algorithmic progress. However, productivity gains were significantly larger for non-agentic analytical tasks compared to agentic workflows requiring tool use. These findings suggest continued model scaling could boost U.S. productivity by approximately 20% over the next decade.",human
"**Abstract** Precise and timely diagnosis from medical imaging is paramount for effective patient care. Manual interpretation, however, is often time-consuming and susceptible to inter-observer variability. This work addresses the problem of automated lesion detection and segmentation in computed tomography (CT) scans, focusing on enhancing diagnostic accuracy and efficiency. We propose a novel multi-scale convolutional neural network (CNN) architecture, leveraging a hybrid attention mechanism to selectively emphasize diagnostically relevant features at varying resolutions. The network incorporates both spatial and channel attention modules, enabling it to adaptively learn the importance of different regions and feature maps, respectively. The model is trained on a large-scale dataset of annotated CT scans, encompassing a diverse range of lesion types and anatomical locations. Experimental results demonstrate that our proposed approach achieves state-of-the-art performance in lesion detection and segmentation, surpassing existing methods by a significant margin. Specifically, we report an average Dice score of 0.82 and a mean average precision (mAP) of 0.78 across multiple lesion categories. These findings suggest the potential for our method to serve as a valuable tool for radiologists, facilitating improved diagnostic accuracy and streamlined clinical workflows. Further, the robustness of the model is validated through cross-dataset evaluation, indicating its generalization capability to unseen data.",ai
"We investigate the problem of sample-efficient exploration in sparse reward environments with high-dimensional, continuous state spaces. Traditional reinforcement learning algorithms often struggle in such settings due to the difficulty in discovering rewarding states. To address this challenge, we propose a novel approach that integrates intrinsic motivation based on prediction error with a hierarchical reinforcement learning framework. Specifically, we train a high-level meta-controller to select abstract goals that maximize the prediction error of a lower-level controller tasked with reaching those goals. This hierarchical structure facilitates exploration by guiding the agent towards regions of high uncertainty, thereby increasing the likelihood of encountering sparse rewards. We evaluate our method on a suite of challenging continuous control tasks with sparse rewards, including a simulated robotic manipulation task and a navigation task with deceptive local optima. Our experimental results demonstrate that the proposed approach significantly outperforms several state-of-the-art exploration techniques, achieving higher success rates and faster learning speeds. Moreover, we analyze the emergent behaviors of the meta-controller, revealing a tendency to prioritize exploration of unexplored regions and overcome deceptive local optima, leading to more efficient discovery of the global reward structure.",ai
"We address the challenge of effectively learning node representations in attributed graphs for downstream tasks such as node classification and link prediction, particularly in scenarios characterized by heterophily â€“ where nodes tend to connect with dissimilar nodes. Existing Graph Neural Networks (GNNs) often struggle in such settings due to their inherent reliance on neighborhood aggregation, which can propagate irrelevant or even detrimental information. We introduce a novel Graph Attention Network with Adaptive Neighborhood Selection (GAT-ANS) that mitigates this issue by dynamically adjusting the receptive field for each node based on its local graph structure. GAT-ANS employs an attention mechanism to learn a node-specific similarity function that weights the contributions of neighboring nodes during aggregation. Critically, this mechanism allows for the selection of a more relevant subset of neighbors, effectively reducing the influence of dissimilar nodes. Experimental results on a variety of heterophilic graph datasets, including Cora-ML, Chameleon, and Squirrel, demonstrate that GAT-ANS consistently outperforms state-of-the-art GNN architectures, achieving significant improvements in node classification accuracy. Ablation studies confirm the efficacy of the adaptive neighborhood selection mechanism in enhancing representation learning for heterophilic graphs. Furthermore, visualization of the learned attention weights provides insights into the network's decision-making process and validates its ability to identify and prioritize relevant neighbors.",ai
"We investigate the challenge of representing relational knowledge in a manner that facilitates both efficient reasoning and generalization to unseen entities. Traditional knowledge representation approaches often rely on symbolic representations that struggle to handle uncertainty and scale to large knowledge graphs. We propose a novel framework, Relational Embedding with Contrastive Regularization (RECR), that learns distributed representations of entities and relations while explicitly encouraging separation between similar and dissimilar relationships. RECR leverages a contrastive loss function during training, minimizing the distance between embeddings of entities connected by similar relations and maximizing the distance between entities connected by dissimilar relations. We apply RECR to several benchmark knowledge graph completion datasets, including FB15k-237 and WN18RR. Our experimental results demonstrate that RECR achieves state-of-the-art performance on link prediction tasks, surpassing existing embedding-based models in terms of mean reciprocal rank and Hits@k. Furthermore, we analyze the learned embeddings and show that RECR exhibits improved ability to generalize to unseen entities and predict novel relationships, highlighting its capacity to capture nuanced semantic relationships beyond simple co-occurrence patterns. These findings suggest that contrastive regularization is a promising technique for learning robust and generalizable knowledge representations.",ai
"Enhanced lithological interpretation from well logs plays a key role in geological resource exploration and mapping, as well as in geo-environmental modeling studies. Core and cutting information is useful for making sound interpretations of well logs; however, these are rarely collected at each depth due to high costs. Moreover, well log interpretation using traditional methods is constrained by poor borehole conditions. Traditional statistical methods are mostly linear, often failing to discriminate between lithology and rock facies, particularly when dealing with overlapping well log signals characterized by the structural and compositional variation of rock types. In this study, we develop multiple supervised and unsupervised machine learning algorithms to jointly analyze multivariate well log data from Integrated Ocean Drilling Program (IODP) expeditions 390 and 393 for enhanced lithological interpretations. Among the algorithms, Logistic Regression, Decision Trees, Gradient Boosting, Support Vector Machines (SVM), k-Nearest Neighbors (KNN), and Multi-Layer Perceptron (MLP) neural network models, the Decision Tree and Gradient Boosting models outperformed the others, achieving an accuracy of 0.9950 and an F1-score of 0.9951. While unsupervised machine learning (ML) provides the foundation for cluster information that inherently supports the classification algorithm, supervised ML is applied to devise a data-driven lithology clustering mechanism for IODP datasets. The joint ML-based method developed here has the potential to be further explored for analyzing other well log datasets from the world's oceans.",human
"Continual learning remains a fundamental challenge in machine learning, requiring models to learn from a stream of tasks without forgetting previously acquired knowledge. A major obstacle in this setting is catastrophic forgetting, where performance on earlier tasks degrades as new tasks are learned. In this paper, we introduce PPSEBM, a novel framework that integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS) to effectively address catastrophic forgetting in continual learning for natural language processing tasks. In PPSEBM, progressive parameter selection allocates distinct, task-specific parameters for each new task, while the EBM generates representative pseudo-samples from prior tasks. These generated samples actively inform and guide the parameter selection process, enhancing the model's ability to retain past knowledge while adapting to new tasks. Experimental results on diverse NLP benchmarks demonstrate that PPSEBM outperforms state-of-the-art continual learning methods, offering a promising and robust solution to mitigate catastrophic forgetting.",human
"Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible. Current solutions, such as post-hoc filtering or projection-based methods, often compromise structural novelty or disrupt key pharmacophores by forcing molecules into pre-defined synthetic templates. Herein, we introduce SynCraft, a reasoning-based framework that reframes synthesizability optimization not as a sequence translation task, but as a precise structural editing problem. Leveraging the emergent reasoning capabilities of Large Language Models, SynCraft navigates the ""synthesis cliff"" where minimal structural modifications yield significant gains in synthetic feasibility. By predicting executable sequences of atom-level edits rather than generating SMILES strings directly, SynCraft circumvents the syntactic fragility of LLMs while harnessing their chemical intuition. Extensive benchmarks demonstrate that SynCraft outperforms state-of-the-art baselines in generating synthesizable analogs with high structural fidelity. Furthermore, through interaction-aware prompting, SynCraft successfully replicates expert medicinal chemistry intuition in editing PLK1 inhibitors and rescuing high-scoring but previously discarded RIPK1 candidates in previous molecular generation literatures.",human
